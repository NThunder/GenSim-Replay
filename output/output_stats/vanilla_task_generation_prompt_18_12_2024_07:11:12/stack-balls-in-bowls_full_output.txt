

================= Task and Asset Design!

>>> Prompt: 
You are an AI in robot simulation code and task design. I will provide you some example tasks, code implementation, and some guidelines for how to generate tasks and then you will help me generate a new task. My goal is to design diverse and feasible tasks for tabletop manipulation. I will first ask you to describe the task in natural languages and then will let you write the code for it. 

=========
Here are all the assets. Use only these assets in the task and code design. 
"""
insertion/:
ell.urdf  fixture.urdf

bowl/:
bowl.urdf

box/:
box-template.urdf

stacking/:
block.urdf  stand.urdf

zone/:
zone.obj  zone.urdf

pallet/:
pallet.obj  pallet.urdf

ball/:
ball-template.urdf

cylinder/:
cylinder-template.urdf

bowl/:
bowl.urdf

# assets not for picking
corner/:
corner-template.urdf

line/:
single-green-line-template.urdf

container/:
container-template.urdf
"""
 
=========
Here are some examples of good tasks. Try to learn from these structures but avoid overlapping wiht them.

{"assets-used": ["zone/zone.urdf", "block/small.urdf"],
 "task-description": "Push piles of small objects into a target goal zone marked on the tabletop.",
 "task-name": "sweeping-piles"}

{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "Place all blocks of a specified color in a bowl of specified color.",
 "task-name": "put-block-in-bowl"}
 
{"assets-used": ["insertion/ell.urdf", "insertion/fixture.urdf"],
 "task-description": "pick up the L-shaped red block and place it into the L-shaped fixture.",
 "task-name": "block-insertion"}
 
{"assets-used": ["kitting/kit.urdf", "kitting/object-template.urdf"],
 "task-description": "pick up different objects and arrange them on a board marked with corresponding silhouettes.",
 "task-name": "assembling-kits"}
 
{"assets-used": ["pallet/pallet.urdf", "box/box-template.urdf"],
 "task-description": "pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.",
 "task-name": "palletizing-boxes"}
 
{"assets-used": ["stacking/stand.urdf", "stacking/block.urdf"],
 "task-description": "sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.",
 "task-name": "stack-block-pyramid"}
 
{"assets-used": ["container/container-template.urdf", "box/box-template.urdf"],
 "task-description": "pick up randomly sized boxes and place them tightly into a container.",
 "task-name": "packing-boxes"}
 
{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "pick up the red blocks and place them into the green bowls amidst other objects.",
 "task-name": "place-red-in-green"}
 
{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

=========
Here are some tasks that you have come up with before. Try to learn from these structures but avoid overlapping with these tasks. For instance, `bowl_ball_placement` and `sort_balls_in_bowls` are the same task. `pile_boxes_in_corner` and `stack_blocks_into_pallet` are similar tasks, `align-cylinder-in-corner` and `align-cylinder-corner` are similar.
- sweeping-piles: {'assets-used': ['zone/zone.urdf', 'block/small.urdf'], 'task-description': 'push piles of small objects into a target goal zone marked on the tabletop.', 'task-name': 'sweeping-piles'}
- place-red-in-green: {'assets-used': ['bowl/bowl.urdf', 'stacking/block.urdf'], 'task-description': 'pick up the red blocks and place them into the green bowls amidst other objects.', 'task-name': 'place-red-in-green'}
- align-box-corner: {'assets-used': ['box/box-template.urdf', 'corner/corner-template.urdf'], 'task-description': 'pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..', 'task-name': 'align-box-corner'}
- stack-block-pyramid: {'assets-used': ['stacking/stand.urdf', 'stacking/block.urdf'], 'task-description': 'sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.', 'task-name': 'stack-block-pyramid'}
- palletizing-boxes: {'assets-used': ['pallet/pallet.urdf', 'box/box-template.urdf'], 'task-description': 'pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.', 'task-name': 'palletizing-boxes'}
- assembling-kits: {'assets-used': ['kitting/kit.urdf', 'kitting/object-template.urdf'], 'task-description': 'pick up different objects and arrange them on a board marked with corresponding silhouettes.', 'task-name': 'assembling-kits'}
- packing-boxes: {'assets-used': ['container/container-template.urdf', 'box/box-template.urdf'], 'task-description': 'pick up randomly sized boxes and place them tightly into a container.', 'task-name': 'packing-boxes'}
- manipulating-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'rearrange a deformable rope such that it connects the two endpoints of a 3-sided square.', 'task-name': 'manipulating-rope'}
- align-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'manipulate a deformable rope to connect its end-points between two corners of a 3-sided square.', 'task-name': 'align-rope'}





=========
Here are some bad example task instances with explanations.
{
    "task_name": "sort-color-blocks",
    "task_descriptions": "Pick up differently colored blocks and place them into separate bowls of matching color."
    "assets-used": ["bowl.urdf", "box/box-template.urdf],
}
reasons: not interesting because it overlaps with the current task `put-block-in-bowl`.

{
    "task-name": "guided-ball-maze",
    "task-description": "Navigate a small ball through a maze by tilting the maze board to reach the target zone.",
    "assets-used": ["zone-template.urdf", "square-template.urdf", "ball.urdf", "maze.urdf"],
}
reasons: the language descriptions are too ambiguous. Navigation is also hard to complete. Also maze.urf does not exist.

{
    "task-name": "insert_cylinder_in_sphere",
    "task-description": "Pick up the cylinder and insert it into the sphere with an opening on top.",
    "assets-used": ["cylinder/cylinder-template.urdf", "sphere/sphere-template.urdf"],
}
reasons: this task does not make sense. The sphere does not have an opening on top, and you cannot insert a cylinder into a sphere. Similarly tasks like `insert-ball-into-cylinder` and `cylinder-box-insertion` are invalid.

{
    "task-name": "ball-box-obstacle-course",
    "task-description": "Navigate a ball through an obstacle course created by randomly placed boxes and finally place it inside a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: Navigate the ball is not related to tabletop manipulation tasks.

{
    "task-name": "ball-in-box",
    "task-description": "Use a cable to guide a ball into an open box.",
    "assets-used": ["cable/cable.urdf", "ball/ball-template.urdf", "box/box-template.urdf"]
}
reasons: This task is too hard since it involves interaction of the cable and the ball and cannot be easily completed.

{
    "task-name": "ball-in-container",
    "task-description": "Use the spatula to lift a ball over a wall of boxes and drop it into a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: The only action primitives as pick and place. One cannot use a spatula to lift an object.

{
    "task-name": "line-ball-sorting",
    "task-description": "Move balls of different colors along a single green line, placing each ball in a designated colored box at the end of the line. The challenge includes precision in maintaining the ball on the line and the correct identification of the box color corresponding to each ball.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "line/single-green-line-template.urdf"]
}
reasons: Piling or stacking balls are physically infeasible in the simulation.



=========
Now please describe the new task in natural languages and explain its novelty and challenges. Format the answer in a python dictionary with keys "task-name" and value type string, "task-description" (one specific sentence) and value type string, and "assets-used" and value type list of strings. Note that

- Do not use assets that are not in the list above. 
- Tasks that have more colors and shapes are interesting.
- Be as specific as possible about the number, shape, and color of each asset in the task descriptions. 
- The task need to obey physics and remain feasible.





>>> Answer: 
```python
{
    "task-name": "stack-balls-in-bowl",
    "task-description": "Pick up three balls of different colors (red, green, and blue) and stack them on top of each other inside a white bowl.",
    "assets-used": ["ball/ball-template.urdf", "bowl/bowl.urdf"],
}
```

**Novelty and Challenges:**

This task introduces the challenge of stacking spherical objects, which is inherently less stable than stacking blocks due to the lack of flat surfaces.  It requires precise placement and control of the robot arm to successfully balance the balls within the bowl's confines.  The different colors add a minor element of visual distinction, although not strictly necessary for the core challenge.  It differs from previous tasks by combining the bowl with balls instead of blocks and focusing on the difficulty of stacking balls rather than simply placing them inside the bowl. While seemingly simple, achieving a stable stack of balls within the curved bowl presents a non-trivial manipulation problem.


================= API Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-in-bowl". Here are some APIs that are defined. Please confirm that you understand these APIs.

"""
class Task():
    """Base Task class."""

    def __init__(self):
        self.ee = Suction
        self.mode = 'train'
        self.sixdof = False
        self.primitive = primitives.PickPlace()
        self.oracle_cams = cameras.Oracle.CONFIG

        # Evaluation epsilons (for pose evaluation metric).
        self.pos_eps = 0.01
        self.rot_eps = np.deg2rad(15)

        # Workspace bounds.
        self.pix_size = 0.003125
        self.bounds = np.array([[0.25, 0.75], [-0.5, 0.5], [0, 0.3]])
        self.zone_bounds = np.copy(self.bounds)

        self.goals = []
        self.lang_goals = []
        self.task_completed_desc = "task completed."
        self.progress = 0
        self._rewards = 0
        self.assets_root = None

    def reset(self, env):
        if not self.assets_root:
            raise ValueError('assets_root must be set for task, '
                             'call set_assets_root().')
        self.goals = []
        self.lang_goals = []
        self.progress = 0  # Task progression metric in range [0, 1].
        self._rewards = 0  # Cumulative returned rewards.

    # -------------------------------------------------------------------------
    # Oracle Agent
    # -------------------------------------------------------------------------

    def oracle(self, env):
        """Oracle agent."""
        OracleAgent = collections.namedtuple('OracleAgent', ['act'])

        def act(obs, info):
            """Calculate action."""

            # Oracle uses perfect RGB-D orthographic images and segmentation masks.
            _, hmap, obj_mask = self.get_true_image(env)

            # Unpack next goal step.
            objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]

            # Match objects to targets without replacement.
            if not replace:

                # Modify a copy of the match matrix.
                matches = matches.copy()

                # Ignore already matched objects.
                for i in range(len(objs)):
                    object_id, (symmetry, _) = objs[i]
                    pose = p.getBasePositionAndOrientation(object_id)
                    targets_i = np.argwhere(matches[i, :]).reshape(-1)
                    for j in targets_i:
                        if self.is_match(pose, targs[j], symmetry):
                            matches[i, :] = 0
                            matches[:, j] = 0

            # Get objects to be picked (prioritize farthest from nearest neighbor).
            nn_dists = []
            nn_targets = []
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                xyz, _ = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                if len(targets_i) > 0:
                    targets_xyz = np.float32([targs[j][0] for j in targets_i])
                    dists = np.linalg.norm(
                        targets_xyz - np.float32(xyz).reshape(1, 3), axis=1)
                    nn = np.argmin(dists)
                    nn_dists.append(dists[nn])
                    nn_targets.append(targets_i[nn])

                # Handle ignored objects.
                else:
                    nn_dists.append(0)
                    nn_targets.append(-1)
            order = np.argsort(nn_dists)[::-1]

            # Filter out matched objects.
            order = [i for i in order if nn_dists[i] > 0]

            pick_mask = None
            for pick_i in order:
                pick_mask = np.uint8(obj_mask == objs[pick_i][0])

                # Erode to avoid picking on edges.
                # pick_mask = cv2.erode(pick_mask, np.ones((3, 3), np.uint8))

                if np.sum(pick_mask) > 0:
                    break

            # Trigger task reset if no object is visible.
            if pick_mask is None or np.sum(pick_mask) == 0:
                self.goals = []
                self.lang_goals = []
                print('Object for pick is not visible. Skipping demonstration.')
                return

            # Get picking pose.
            pick_prob = np.float32(pick_mask)
            pick_pix = utils.sample_distribution(pick_prob)
            # For "deterministic" demonstrations on insertion-easy, use this:
            # pick_pix = (160,80)
            pick_pos = utils.pix_to_xyz(pick_pix, hmap,
                                        self.bounds, self.pix_size)
            pick_pose = (np.asarray(pick_pos), np.asarray((0, 0, 0, 1)))

            # Get placing pose.
            targ_pose = targs[nn_targets[pick_i]]
            obj_pose = p.getBasePositionAndOrientation(objs[pick_i][0])
            if not self.sixdof:
                obj_euler = utils.quatXYZW_to_eulerXYZ(obj_pose[1])
                obj_quat = utils.eulerXYZ_to_quatXYZW((0, 0, obj_euler[2]))
                obj_pose = (obj_pose[0], obj_quat)
            world_to_pick = utils.invert(pick_pose)
            obj_to_pick = utils.multiply(world_to_pick, obj_pose)
            pick_to_obj = utils.invert(obj_to_pick)
            place_pose = utils.multiply(targ_pose, pick_to_obj)

            # Rotate end effector?
            if not rotations:
                place_pose = (place_pose[0], (0, 0, 0, 1))

            place_pose = (np.asarray(place_pose[0]), np.asarray(place_pose[1]))

            return {'pose0': pick_pose, 'pose1': place_pose}

        return OracleAgent(act)

    # -------------------------------------------------------------------------
    # Reward Function and Task Completion Metrics
    # -------------------------------------------------------------------------

    def reward(self):
        """Get delta rewards for current timestep.

        Returns:
          A tuple consisting of the scalar (delta) reward, plus `extras`
            dict which has extra task-dependent info from the process of
            computing rewards that gives us finer-grained details. Use
            `extras` for further data analysis.
        """
        reward, info = 0, {}

        # Unpack next goal step.
        objs, matches, targs, _, _, metric, params, max_reward = self.goals[0]

        # Evaluate by matching object poses.
        if metric == 'pose':
            step_reward = 0
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                pose = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                for j in targets_i:
                    target_pose = targs[j]
                    if self.is_match(pose, target_pose, symmetry):
                        step_reward += max_reward / len(objs)
                        print(f"object {i} match with target {j} rew: {step_reward}")
                        break

        # Evaluate by measuring object intersection with zone.
        elif metric == 'zone':
            zone_pts, total_pts = 0, 0
            obj_pts, zones = params
            for zone_idx, (zone_pose, zone_size) in enumerate(zones):

                # Count valid points in zone.
                for obj_idx, obj_id in enumerate(obj_pts):
                    pts = obj_pts[obj_id]
                    obj_pose = p.getBasePositionAndOrientation(obj_id)
                    world_to_zone = utils.invert(zone_pose)
                    obj_to_zone = utils.multiply(world_to_zone, obj_pose)
                    pts = np.float32(utils.apply(obj_to_zone, pts))
                    if len(zone_size) > 1:
                        valid_pts = np.logical_and.reduce([
                            pts[0, :] > -zone_size[0] / 2, pts[0, :] < zone_size[0] / 2,
                            pts[1, :] > -zone_size[1] / 2, pts[1, :] < zone_size[1] / 2,
                            pts[2, :] < self.zone_bounds[2, 1]])

                    # if zone_idx == matches[obj_idx].argmax():
                    zone_pts += np.sum(np.float32(valid_pts))
                    total_pts += pts.shape[1]
            step_reward = max_reward * (zone_pts / total_pts)

        # Get cumulative rewards and return delta.
        reward = self.progress + step_reward - self._rewards
        self._rewards = self.progress + step_reward

        # Move to next goal step if current goal step is complete.
        if np.abs(max_reward - step_reward) < 0.01:
            self.progress += max_reward  # Update task progress.
            self.goals.pop(0)
            if len(self.lang_goals) > 0:
                self.lang_goals.pop(0)

        return reward, info

    def done(self):
        """Check if the task is done or has failed.

        Returns:
          True if the episode should be considered a success, which we
            use for measuring successes, which is particularly helpful for tasks
            where one may get successes on the very last time step, e.g., getting
            the cloth coverage threshold on the last alllowed action.
            However, for bag-items-easy and bag-items-hard (which use the
            'bag-items' metric), it may be necessary to filter out demos that did
            not attain sufficiently high reward in external code. Currently, this
            is done in `main.py` and its ignore_this_demo() method.
        """
        return (len(self.goals) == 0) or (self._rewards > 0.99)
        # return zone_done or defs_done or goal_done

    # -------------------------------------------------------------------------
    # Environment Helper Functions
    # -------------------------------------------------------------------------

    def is_match(self, pose0, pose1, symmetry):
        """Check if pose0 and pose1 match within a threshold."""

        # Get translational error.
        diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
        dist_pos = np.linalg.norm(diff_pos)

        # Get rotational error around z-axis (account for symmetries).
        diff_rot = 0
        if symmetry > 0:
            rot0 = np.array(utils.quatXYZW_to_eulerXYZ(pose0[1]))[2]
            rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]
            diff_rot = np.abs(rot0 - rot1) % symmetry
            if diff_rot > (symmetry / 2):
                diff_rot = symmetry - diff_rot

        return (dist_pos < self.pos_eps) and (diff_rot < self.rot_eps)

    def get_random_pose(self, env, obj_size):
        """Get random collision-free object pose within workspace bounds."""

        # Get erosion size of object in pixels.
        max_size = np.sqrt(obj_size[0] ** 2 + obj_size[1] ** 2)
        erode_size = int(np.round(max_size / self.pix_size))

        _, hmap, obj_mask = self.get_true_image(env)

        # Randomly sample an object pose within free-space pixels.
        free = np.ones(obj_mask.shape, dtype=np.uint8)
        for obj_ids in env.obj_ids.values():
            for obj_id in obj_ids:
                free[obj_mask == obj_id] = 0
        free[0, :], free[:, 0], free[-1, :], free[:, -1] = 0, 0, 0, 0
        free = cv2.erode(free, np.ones((erode_size, erode_size), np.uint8))

        # if np.sum(free) == 0:
        #     return None, None

        if np.sum(free) == 0:
            # avoid returning None, None
            # return None, None
            pix = (obj_mask.shape[0] // 2, obj_mask.shape[1] // 2)
        else:
            pix = utils.sample_distribution(np.float32(free))
        pos = utils.pix_to_xyz(pix, hmap, self.bounds, self.pix_size)
        pos = (pos[0], pos[1], obj_size[2] / 2)
        theta = np.random.rand() * 2 * np.pi
        rot = utils.eulerXYZ_to_quatXYZW((0, 0, theta))
        return pos, rot

    def get_lang_goal(self):
        if len(self.lang_goals) == 0:
            return self.task_completed_desc
        else:
            return self.lang_goals[0]

    def get_reward(self):
        return float(self._rewards)

    # -------------------------------------------------------------------------
    # Helper Functions
    # -------------------------------------------------------------------------

    def fill_template(self, template, replace):
        """Read a file and replace key strings."""
        full_template_path = os.path.join(self.assets_root, template)
        with open(full_template_path, 'r') as file:
            fdata = file.read()
        for field in replace:
            for i in range(len(replace[field])):
                fdata = fdata.replace(f'{field}{i}', str(replace[field][i]))
        alphabet = string.ascii_lowercase + string.digits
        rname = ''.join(random.choices(alphabet, k=16))
        tmpdir = tempfile.gettempdir()
        template_filename = os.path.split(template)[-1]
        fname = os.path.join(tmpdir, f'{template_filename}.{rname}')
        with open(fname, 'w') as file:
            file.write(fdata)
        return fname

    def get_random_size(self, min_x, max_x, min_y, max_y, min_z, max_z):
        """Get random box size."""
        size = np.random.rand(3)
        size[0] = size[0] * (max_x - min_x) + min_x
        size[1] = size[1] * (max_y - min_y) + min_y
        size[2] = size[2] * (max_z - min_z) + min_z
        return tuple(size)

    def color_random_brown(self, obj):
        shade = np.random.rand() + 0.5
        color = np.float32([shade * 156, shade * 117, shade * 95, 255]) / 255
        p.changeVisualShape(obj, -1, rgbaColor=color)

  """""
  
  # Environment Class
  def add_object(self, urdf, pose, category='rigid'):
    """List of (fixed, rigid, or deformable) objects in env."""
    fixed_base = 1 if category == 'fixed' else 0
    obj_id = pybullet_utils.load_urdf(
        p,
        os.path.join(self.assets_root, urdf),
        pose[0],
        pose[1],
        useFixedBase=fixed_base)
    self.obj_ids[category].append(obj_id)
    return obj_id
"""

=========
Note that the objects need to obey physics and not collide with each other, and the object goal poses need to be above the table with lower bound x=0.25, y=-0.5 and upper bound x=0.75, y=0.5. When there are multiple objects for a multi-step pick-and-place task, there are often multiple subgoals. Once the task and environment are generated, an agent with a pick and place primitive will follow the defined goal to accomplish the tasks. 

Additionally, make sure you understand and summarize the ``self.goals`` variables, which has a list of 8-tuple with (objs, matches, targ_poses, replace, rotations, metric, params, step_max_reward, symmetries).
- objs (List of obj_id): object ID.
- matches (Binary Matrix): a binary matrix that denotes which object is matched with which target. This matrix has dimension len(objs) x len(targs).
- targ_poses (List of Poses [(translation, rotation)] ): a list of target poses of tuple (translation, rotation). 
- replace (Boolean): whether each object can match with one unique target. This is important if we have one target and multiple objects. If it's set to be false, then any object matching with the target will satisfy.
- rotations (Boolean): whether the placement action has a rotation degree of freedom. 
- metric (`pose` or `zone`): `pose` or `zone` that the object needs to be transported to. Example: `pose`. 
- params (List of (zone_target, zone_size)): a list of (zone_target, zone_size) for each zone if the metric is `zone`. 
- step_max_reward (float): the total reward of matching all the objects with all the target poses. It is not dependent on the number of objects but dependent on the number of goals. 
- symmetries: the radians that the object is symmetric around z axis.
- language_goal: the low-level language instructions that denote the goal of this step.
 


>>> Answer: 
Yes, I understand the provided APIs and their intended usage. Here's a summary of my understanding:

**Task Class:**

The `Task` class defines the base structure and functionality for a manipulation task within a simulated environment (likely PyBullet). It handles aspects like:

* **Action Execution:**  Uses a `Suction` end-effector (`self.ee`).
* **Goal Management:** Stores task goals in `self.goals` (detailed below) and language goals in `self.lang_goals`.  Tracks progress (`self.progress`) and cumulative rewards (`self._rewards`).
* **Reward Calculation:**  The `reward()` method computes rewards based on goal completion, using different metrics ('pose' or 'zone').
* **Task Completion:** The `done()` method checks if the task is finished (all goals achieved or reward threshold met).
* **Environment Interaction:** Includes helper functions for pose checking (`is_match`), random pose generation (`get_random_pose`), and true image retrieval (`get_true_image`, not shown but mentioned).
* **Oracle Agent:** Provides an `oracle()` method that demonstrates perfect task execution using ground truth information. This is useful for generating expert demonstrations.
* **Helper Functions:**  Offers utility functions for template filling (`fill_template`), random size generation (`get_random_size`), and object coloring (`color_random_brown`).
* **Environment Assets:**  The `assets_root` attribute specifies the directory containing URDF files and other assets.

**Environment Class (Partial):**

The provided snippet of the environment class shows the `add_object` method, which loads objects into the simulation.  It categorizes objects as 'fixed', 'rigid', or 'deformable'.

**Understanding `self.goals`:**

The `self.goals` variable is crucial. Each element in this list represents a sub-goal within the overall task. Each sub-goal is an 8-tuple:

1. **`objs`:** A list of object IDs (integers) involved in this sub-goal.
2. **`matches`:** A binary matrix indicating which object should be matched with which target pose.  Rows correspond to objects, columns to target poses. A '1' at `matches[i, j]` means object `i` should be placed at target pose `j`.
3. **`targs` (or `targ_poses`):** A list of target poses. Each pose is a tuple: `(position, orientation)`.  `position` is a 3D vector, and `orientation` is a quaternion.
4. **`replace`:** A boolean flag. If `False`, each object can only be matched with one unique target. If `True`, multiple objects can be placed at the same target.
5. **`rotations`:** A boolean flag. If `True`, the end-effector's rotation matters during placement. If `False`, only the position is considered.
6. **`metric`:** A string, either 'pose' or 'zone', specifying how the reward is calculated. 'pose' checks if object poses match target poses. 'zone' checks if objects are within specified zones.
7. **`params`:**  Additional parameters depending on the `metric`. For 'zone', it's a list of `(zone_target, zone_size)` tuples.
8. **`step_max_reward`:** The maximum reward achievable for this sub-goal.
9. **`symmetries`:** The rotational symmetry of the object around the z-axis, in radians. This is used in the `is_match` function to account for symmetries when comparing poses.


**Key Considerations for Code Implementation:**

* **Physics and Collision Avoidance:**  Ensure objects interact realistically with physics and avoid collisions.
* **Workspace Bounds:** Respect the specified workspace boundaries when generating object and target poses.
* **Multi-Step Tasks:** Handle multiple sub-goals sequentially, using `self.goals` to guide the agent's actions.
* **Pick and Place Primitive:**  Assume the existence of a `PickPlace` primitive (`self.primitive`) for executing pick and place actions.


By adhering to these guidelines and utilizing the provided APIs, you can create a robust and functional implementation of the "stack-balls-in-bowl" task.


================= Error Book Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-in-bowl". Here are some runtime errors that you do not want to make. Please confirm that you understand these runtime errors.

"""
- environment.py, line 338, in info
    pos, rot = p.getBasePositionAndOrientation(obj_id)
TypeError: an integer is required (got type NoneType)

- task.py, line 118, in act
    objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]
IndexError: list index out of range

- task.py, line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
TypeError: 'float' object is not subscriptable

- task.py", line 315, in is_match
  rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]

- utils.py", line 280, in quatXYZW_to_eulerXYZ
  quaternion_wxyz = np.array([q[3], q[0], q[1], q[2]])
IndexError: tuple index out of range

- pallet_pose = self.get_random_pose(env, pallet_size)
pallet_surface_height = pallet_pose[0][2]
TypeError: 'NoneType' object is not subscriptable

- No such file or directory: './cliport/environments/assets/circle/circle-template.urdf'

- No such file or directory: './cliport/environments/assets/block/block-template.urdf'

- task.py", line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
IndexError: invalid index to scalar variable.

-TypeError: get_random_size() missing 4 required positional arguments: 'min_y', 'max_y', 'min_z', and 'max_z' 

- task.py", line 195, in reward
    obj_pts, zones = params
TypeError: cannot unpack non-iterable NoneType object

-  environment.py", line 230, in step
    reward, info = self.task.reward() if action is not None else (0, {})
  File "task.py", line 200, in reward
    pts = obj_pts[obj_id]
IndexError: arrays used as indices must be of integer (or boolean) type

- generated_task.py", line 41, in reset
    utils.COLORS['green'], utils.COLORS['blue'], utils.COLORS['light blue'],
KeyError: 'light blue'

- environment.py", line 195, in reset
    self.task.reset(self)
  File "<string>", line 38, in reset
TypeError: can only concatenate str (not "list") to str

- environment.py", line 195, in reset
  object_shape = np.random.choice(object_shapes)
  in numpy.random.mtrand.RandomState.choice
ValueError: a must be 1-dimensional

- No such file or directory: 'assets/box-template/box-template.urdf'

- line 38, in reset.py
{'HALF': box_size / 2}
TypeError: unsupported operand type(s) for /: 'tuple' and 'int'. box_size is a tuple not a float.

- line 38, in reset.py
IndexError: tuple index out of range
box_pose = (pallet_pose[0], pallet_pose[1], pallet_pose[2] + np.sum(box_sizes[:i+1]))

- task.py", line 338, in fill_template
    for i in range(len(replace[field])):
TypeError: object of type 'float' has no len().

- task.py", line 325, in get_random_pose
    pos = (pos[0], pos[1], obj_size[2] / 2)
IndexError: tuple index out of range

- task.py", line 206, in reward
    for zone_idx, (zone_pose, zone_size) in enumerate(zones):
TypeError: 'NoneType' object is not iterable

- task.py",
ball_pose = self.get_random_pose(env, ball_size)
ball_pose[0][2] += 0.02
TypeError: 'tuple' object does not support item assignment
"""


You do not want to make mistakes such as
- using assets (urdfs) that do not exist
- use ambiguous language descriptions as goals. For instance, "place the colored blocks into the matching colored bowls" with one goal and sparse reward as the task instead of adding subgoal "place blue block into blue bowl" and give continuous reward. 
- `matches` in the goal has wrong dimensions. It should have the same dimensions as number of objects (N) multiplied by the number of goal poses (M). Usually it is N by M.
- have vector dimension problem such as `np.random.choice(box_size)` or `box_size / 2` where `box_size` is a tuple and not an int
- make too large an object for stacking or make the task objects invisible for picking. 
- accessing index out of bound `pallet_pose[2]` for `pallet_pose`.  `pallet_pose=get_random_pose` returns a tuple (translation, rotation). It does not have 3rd component. Similarly accessing `container_pose[2]` or `box_pose[2]` would cause errors as well. Since it's a tuple, try to modify it in-place will also trigger errors.
- forget to replace str using `fill_template()` for urdfs with template such as `cylinder-template.urdf`. `ball-template.urdf`, `line-template.urf`. 
- use `self.ee = Spatula()` as a function when doing pushing tasks, which is incorrect. It should be `self.ee = Spatula`.
- forget to compute target poses `targ_poses` for matching. Do not use object IDs for poses.
- change colors of complex objects such as `zone`. You can only change color of teomplate primitive such as `cylinder-template`.
- mistakenly use `random_pose` for target pose. Design target poses based on task objectives.
- add only one or fewer language goals which causes language-motion inconsistentcy. Note that the language goals usually are the same number as the pick and place goals.


>>> Answer: 
Yes, I understand the runtime errors listed and the additional points you've made about avoiding mistakes in task generation. I will keep these in mind when writing the code for the "stack-balls-in-bowl" task.  I will pay particular attention to:

* **File Paths and Existence:** Verify that all URDF files exist in the correct locations.
* **Clear Language Goals:**  Provide specific and unambiguous language descriptions for each subgoal, avoiding vague phrasing.
* **Matches Dimensions:** Ensure the `matches` array has the correct dimensions (N x M), reflecting the relationship between objects and target poses.
* **Vector Operations:**  Handle vector and scalar operations correctly, paying attention to the dimensions of variables like `box_size`.  Avoid operations like division or random choice on tuples directly.
* **Object Sizes and Visibility:**  Keep object sizes reasonable for stacking and ensure they are visible for manipulation.
* **Pose Tuple Access:** Access elements of pose tuples (translation, rotation) correctly, remembering they are length 2. Avoid trying to modify tuples in place.
* **Template Filling:** Use `fill_template()` to replace placeholders in URDFs with specific values.
* **Spatula Initialization:** Initialize the spatula correctly using `self.ee = Spatula`, not as a function call.
* **Target Pose Calculation:** Explicitly calculate target poses (`targ_poses`) based on task requirements, not object IDs.
* **Color Changes:** Only change colors of primitive template objects, not complex objects like zones.
* **Random Poses vs. Designed Poses:** Use `random_pose` appropriately and design target poses based on the task's logic.
* **Sufficient Language Goals:** Provide enough language goals to match the number of pick-and-place actions, ensuring language-motion consistency.


By addressing these points, I aim to avoid the listed runtime errors and create a robust and functional "stack-balls-in-bowl" task.


================= Code Generation!

>>> Prompt: 
Now I will provide you some reference code and you can write the code for the task "stack-balls-in-bowl".


"""
import os

import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils


class PackingShapes(Task):
    """pick up randomly sized shapes and place them tightly into a container."""

    def __init__(self):
        super().__init__()
        self.max_steps = 1
        self.homogeneous = False

        self.lang_template = "pack the {obj} in the brown box"
        self.task_completed_desc = "done packing shapes."
        self.additional_reset()


    def reset(self, env):
        super().reset(env)

        # Shape Names:
        shapes = utils.assembling_kit_shapes

        n_objects = 5
        if self.mode == 'train':
            obj_shapes = np.random.choice(self.train_set, n_objects, replace=False)
        else:
            if self.homogeneous:
                obj_shapes = [np.random.choice(self.test_set, replace=False)] * n_objects
            else:
                obj_shapes = np.random.choice(self.test_set, n_objects, replace=False)

        # Shuffle colors to avoid always picking an object of the same color
        colors, color_names = utils.get_colors(mode=self.mode)

        # Add container box.
        zone_size = self.get_random_size(0.1, 0.15, 0.1, 0.15, 0.05, 0.05)
        zone_pose = self.get_random_pose(env, zone_size)
        container_template = 'container/container-template.urdf'
        replace = {'DIM': zone_size, 'HALF': (zone_size[0] / 2, zone_size[1] / 2, zone_size[2] / 2)}
        # IMPORTANT: REPLACE THE TEMPLATE URDF with `fill_template`
        container_urdf = self.fill_template(container_template, replace)
        env.add_object(container_urdf, zone_pose, 'fixed')

        # Add objects.
        objects = []
        template = 'kitting/object-template.urdf'
        for i in range(n_objects):
            shape = obj_shapes[i]

            # x, y, z dimensions for the asset size
            size = (0.08, 0.08, 0.02)
            pose= self.get_random_pose(env, size)
            fname = f'{shape:02d}.obj'
            fname = os.path.join(self.assets_root, 'kitting', fname)
            scale = [0.003, 0.003, 0.001]  # .0005
            replace = {'FNAME': (fname,),
                       'SCALE': scale,
                       'COLOR': colors[i]}

            # IMPORTANT: REPLACE THE TEMPLATE URDF
            urdf = self.fill_template(template, replace)
            block_id = env.add_object(urdf, pose)
            objects.append(block_id)

        # Pick the first shape.
        num_objects_to_pick = 1
        for i in range(num_objects_to_pick):
            # IMPORTANT: Specify (obj_pts, [(zone_pose, zone_size)]) for target `zone`. obj_pts is a dict
            language_goal = self.lang_template.format(obj=shapes[obj_shapes[i]])
            self.add_goal(objs=[objects[i]], matches=np.int32([[1]]), targ_poses=[zone_pose], replace=False,
                rotations=True, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1 / num_objects_to_pick,
                language_goal=language_goal)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p


class PlaceRedInGreen(Task):
    """pick up the red blocks and place them into the green bowls amidst other objects."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "put the red blocks in a green bowl"
        self.task_completed_desc = "done placing blocks in bowls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)
        n_bowls = np.random.randint(1, 4)
        n_blocks = np.random.randint(1, n_bowls + 1)

        # Add bowls.
        # x, y, z dimensions for the asset size
        bowl_size = (0.12, 0.12, 0)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_poses = []
        for _ in range(n_bowls):
            bowl_pose = self.get_random_pose(env, obj_size=bowl_size)
            env.add_object(urdf=bowl_urdf, pose=bowl_pose, category='fixed')
            bowl_poses.append(bowl_pose)

        # Add blocks.
        # x, y, z dimensions for the asset size
        blocks = []
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'
        for _ in range(n_blocks):
            block_pose = self.get_random_pose(env, obj_size=block_size)
            block_id = env.add_object(block_urdf, block_pose)
            blocks.append(block_id)

        # Goal: each red block is in a different green bowl.
        self.add_goal(objs=blocks, matches=np.ones((len(blocks), len(bowl_poses))), targ_poses=bowl_poses, replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1, language_goal=self.lang_template)

        # Colors of distractor objects.
        bowl_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'green']
        block_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'red']

        # Add distractors.
        n_distractors = 0
        while n_distractors < 6:
            is_block = np.random.rand() > 0.5
            urdf = block_urdf if is_block else bowl_urdf
            size = block_size if is_block else bowl_size
            colors = block_colors if is_block else bowl_colors
            pose = self.get_random_pose(env, obj_size=size)
            color = colors[n_distractors % len(colors)]

            obj_id = env.add_object(urdf, pose, color=color)
            n_distractors += 1
"""
"""
import numpy as np
from cliport.tasks import primitives
from cliport.tasks.grippers import Spatula
from cliport.tasks.task import Task
from cliport.utils import utils


class SweepingPiles(Task):
    """Push piles of small objects into a target goal zone marked on the tabletop."""

    def __init__(self):
        super().__init__()
        self.max_steps = 20
        self.lang_template = "push the pile of blocks into the green square"
        self.task_completed_desc = "done sweeping."
        self.primitive = primitives.push
        self.ee = Spatula
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add goal zone.
        zone_size = (0.12, 0.12, 0)
        zone_pose = self.get_random_pose(env, zone_size)
        env.add_object('zone/zone.urdf', zone_pose, 'fixed')

        # Add pile of small blocks with `make_piles` function
        obj_ids = self.make_piles(env)

        # Add goal
        self.add_goal(objs=obj_ids, matches=np.ones((50, 1)), targ_poses=[zone_pose], replace=True,
                rotations=False, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1, language_goal=self.lang_template)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p

class StackBlockPyramid(Task):
    """Build a pyramid of colored blocks in a color sequence"""

    def __init__(self):
        super().__init__()
        self.max_steps = 12
        self.lang_template = "make the {row} row with {blocks}"
        self.task_completed_desc = "done stacking block pyramid."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add base.
        base_size = (0.05, 0.15, 0.005)
        base_urdf = 'stacking/stand.urdf'
        base_pose = self.get_random_pose(env, base_size)
        env.add_object(base_urdf, base_pose, category='fixed')

        # Block colors.
        colors = [
            utils.COLORS['purple'], utils.COLORS['blue'], utils.COLORS['green'],
            utils.COLORS['yellow'], utils.COLORS['orange'], utils.COLORS['red']
        ]

        # Add blocks.
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'

        objs = []
        for i in range(6):
            block_pose = self.get_random_pose(env, block_size)
            block_id = env.add_object(block_urdf, block_pose, color=colors[i])
            objs.append(block_id)

        # IMPORTANT Associate placement locations for goals.
        place_pos = [(0, -0.05, 0.03), (0, 0, 0.03),
                     (0, 0.05, 0.03), (0, -0.025, 0.08),
                     (0, 0.025, 0.08), (0, 0, 0.13)]
        targs = [(utils.apply(base_pose, i), base_pose[1]) for i in place_pos]

        # Goal: blocks are stacked in a pyramid (bottom row: green, blue, purple).
        language_goal = self.lang_template.format(blocks="the green, blue and purple blocks", row="bottom")
        self.add_goal(objs=objs[:3], matches=np.ones((3, 3)), targ_poses=targs[:3], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 2, symmetries=[np.pi/2]*3, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (middle row: yellow, orange).
        language_goal = self.lang_template.format(blocks="the yellow and orange blocks", row="middle")      
        self.add_goal(objs=objs[3:5], matches=np.ones((2, 2)), targ_poses=targs[3:5], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 3, symmetries=[np.pi/2]*2, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (top row: red).
        language_goal = self.lang_template.format(blocks="the red block", row="top")
        self.add_goal(objs=objs[5:], matches=np.ones((1, 1)), targ_poses=targs[5:], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 6, symmetries=[np.pi/2]*1, language_goal=language_goal)
"""



Do not use libraries, functions, and assets that you don't know. For each object, try to describe its color, size, category in the task first before you write the code. You do not need extra helper functions. Comment the code liberally to explain what each piece does and why it's written that way. If you have only one goal, `step_max_reward` in `add_goal` should be 1. Use functions `make_piles` and `make_ropes` for creating piles and cables. To use spatula together with the push primitives, import the libraries 
"""
from cliport.tasks import primitives;
from cliport.tasks.grippers import Spatula
"""
and then use `self.primitive = primitives.push` and `self.ee = Spatula`.
Note that the number of language goals usually match the number of motion goals, since they should correspond to each other.

Now write the code for the task "stack-balls-in-bowl" in python code block starting with ```python.  Reminder: {'task-name': 'stack-balls-in-bowl', 'task-description': 'Pick up three balls of different colors (red, green, and blue) and stack them on top of each other inside a white bowl.', 'assets-used': ['ball/ball-template.urdf', 'bowl/bowl.urdf']} 


>>> Answer: 
```python
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils

class StackBallsInBowl(Task):
    """Pick up three balls of different colors (red, green, and blue) and stack them on top of each other inside a white bowl."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10  # Set maximum steps for task completion
        self.lang_template = "stack the red, green, and blue balls in the white bowl"  # Language goal template
        self.task_completed_desc = "done stacking balls in bowl."  # Description for task completion
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Bowl
        # Color: White
        # Size: Medium
        # Category: Container/Target
        bowl_size = (0.12, 0.12, 0.05)  # Slightly larger to accommodate stacked balls
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_pose = self.get_random_pose(env, bowl_size)
        bowl_id = env.add_object(bowl_urdf, bowl_pose, color=utils.COLORS['white'])

        # Balls
        # Colors: Red, Green, Blue
        # Size: Small
        # Category: Objects to manipulate
        ball_template = 'ball/ball-template.urdf'
        ball_size = (0.04, 0.04, 0.04)
        ball_colors = ['red', 'green', 'blue']
        ball_ids = []

        for color in ball_colors:
            ball_pose = self.get_random_pose(env, ball_size)
            replace = {'DIM': ball_size, 'HALF': (ball_size[0] / 2, ball_size[1] / 2, ball_size[2] / 2)}
            ball_urdf = self.fill_template(ball_template, replace)
            ball_id = env.add_object(ball_urdf, ball_pose, color=utils.COLORS[color])
            ball_ids.append(ball_id)

        # Goal: stack balls in the bowl
        # Target positions for stacked balls inside the bowl.
        stack_height = 0.04  # Height of each ball
        targ_poses = []
        for i in range(len(ball_ids)):
            offset = (0, 0, i * stack_height + 0.02) # Offset for stacking, slight elevation from bowl bottom
            targ_pose = utils.apply(bowl_pose, offset)
            targ_poses.append((targ_pose, bowl_pose[1])) # Include bowl orientation

        # Define goal with pose matching inside the bowl zone.
        self.add_goal(objs=ball_ids, matches=np.ones((len(ball_ids), 1)), targ_poses=targ_poses, 
                      replace=False, rotations=True, metric='pose', params=None, 
                      step_max_reward=1, language_goal=self.lang_template)
```

================= TRIAL: 1

================= TRIAL: 1

================= TRIAL: 1

================= TRIAL: 1

================= Task and Asset Design!

>>> Prompt: 
You are an AI in robot simulation code and task design. I will provide you some example tasks, code implementation, and some guidelines for how to generate tasks and then you will help me generate a new task. My goal is to design diverse and feasible tasks for tabletop manipulation. I will first ask you to describe the task in natural languages and then will let you write the code for it. 

=========
Here are all the assets. Use only these assets in the task and code design. 
"""
insertion/:
ell.urdf  fixture.urdf

bowl/:
bowl.urdf

box/:
box-template.urdf

stacking/:
block.urdf  stand.urdf

zone/:
zone.obj  zone.urdf

pallet/:
pallet.obj  pallet.urdf

ball/:
ball-template.urdf

cylinder/:
cylinder-template.urdf

bowl/:
bowl.urdf

# assets not for picking
corner/:
corner-template.urdf

line/:
single-green-line-template.urdf

container/:
container-template.urdf
"""
 
=========
Here are some examples of good tasks. Try to learn from these structures but avoid overlapping wiht them.

{"assets-used": ["zone/zone.urdf", "block/small.urdf"],
 "task-description": "Push piles of small objects into a target goal zone marked on the tabletop.",
 "task-name": "sweeping-piles"}

{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "Place all blocks of a specified color in a bowl of specified color.",
 "task-name": "put-block-in-bowl"}
 
{"assets-used": ["insertion/ell.urdf", "insertion/fixture.urdf"],
 "task-description": "pick up the L-shaped red block and place it into the L-shaped fixture.",
 "task-name": "block-insertion"}
 
{"assets-used": ["kitting/kit.urdf", "kitting/object-template.urdf"],
 "task-description": "pick up different objects and arrange them on a board marked with corresponding silhouettes.",
 "task-name": "assembling-kits"}
 
{"assets-used": ["pallet/pallet.urdf", "box/box-template.urdf"],
 "task-description": "pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.",
 "task-name": "palletizing-boxes"}
 
{"assets-used": ["stacking/stand.urdf", "stacking/block.urdf"],
 "task-description": "sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.",
 "task-name": "stack-block-pyramid"}
 
{"assets-used": ["container/container-template.urdf", "box/box-template.urdf"],
 "task-description": "pick up randomly sized boxes and place them tightly into a container.",
 "task-name": "packing-boxes"}
 
{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "pick up the red blocks and place them into the green bowls amidst other objects.",
 "task-name": "place-red-in-green"}
 
{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

=========
Here are some tasks that you have come up with before. Try to learn from these structures but avoid overlapping with these tasks. For instance, `bowl_ball_placement` and `sort_balls_in_bowls` are the same task. `pile_boxes_in_corner` and `stack_blocks_into_pallet` are similar tasks, `align-cylinder-in-corner` and `align-cylinder-corner` are similar.
- sweeping-piles: {'assets-used': ['zone/zone.urdf', 'block/small.urdf'], 'task-description': 'push piles of small objects into a target goal zone marked on the tabletop.', 'task-name': 'sweeping-piles'}
- place-red-in-green: {'assets-used': ['bowl/bowl.urdf', 'stacking/block.urdf'], 'task-description': 'pick up the red blocks and place them into the green bowls amidst other objects.', 'task-name': 'place-red-in-green'}
- align-box-corner: {'assets-used': ['box/box-template.urdf', 'corner/corner-template.urdf'], 'task-description': 'pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..', 'task-name': 'align-box-corner'}
- stack-block-pyramid: {'assets-used': ['stacking/stand.urdf', 'stacking/block.urdf'], 'task-description': 'sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.', 'task-name': 'stack-block-pyramid'}
- palletizing-boxes: {'assets-used': ['pallet/pallet.urdf', 'box/box-template.urdf'], 'task-description': 'pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.', 'task-name': 'palletizing-boxes'}
- assembling-kits: {'assets-used': ['kitting/kit.urdf', 'kitting/object-template.urdf'], 'task-description': 'pick up different objects and arrange them on a board marked with corresponding silhouettes.', 'task-name': 'assembling-kits'}
- packing-boxes: {'assets-used': ['container/container-template.urdf', 'box/box-template.urdf'], 'task-description': 'pick up randomly sized boxes and place them tightly into a container.', 'task-name': 'packing-boxes'}
- manipulating-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'rearrange a deformable rope such that it connects the two endpoints of a 3-sided square.', 'task-name': 'manipulating-rope'}
- align-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'manipulate a deformable rope to connect its end-points between two corners of a 3-sided square.', 'task-name': 'align-rope'}





=========
Here are some bad example task instances with explanations.
{
    "task_name": "sort-color-blocks",
    "task_descriptions": "Pick up differently colored blocks and place them into separate bowls of matching color."
    "assets-used": ["bowl.urdf", "box/box-template.urdf],
}
reasons: not interesting because it overlaps with the current task `put-block-in-bowl`.

{
    "task-name": "guided-ball-maze",
    "task-description": "Navigate a small ball through a maze by tilting the maze board to reach the target zone.",
    "assets-used": ["zone-template.urdf", "square-template.urdf", "ball.urdf", "maze.urdf"],
}
reasons: the language descriptions are too ambiguous. Navigation is also hard to complete. Also maze.urf does not exist.

{
    "task-name": "insert_cylinder_in_sphere",
    "task-description": "Pick up the cylinder and insert it into the sphere with an opening on top.",
    "assets-used": ["cylinder/cylinder-template.urdf", "sphere/sphere-template.urdf"],
}
reasons: this task does not make sense. The sphere does not have an opening on top, and you cannot insert a cylinder into a sphere. Similarly tasks like `insert-ball-into-cylinder` and `cylinder-box-insertion` are invalid.

{
    "task-name": "ball-box-obstacle-course",
    "task-description": "Navigate a ball through an obstacle course created by randomly placed boxes and finally place it inside a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: Navigate the ball is not related to tabletop manipulation tasks.

{
    "task-name": "ball-in-box",
    "task-description": "Use a cable to guide a ball into an open box.",
    "assets-used": ["cable/cable.urdf", "ball/ball-template.urdf", "box/box-template.urdf"]
}
reasons: This task is too hard since it involves interaction of the cable and the ball and cannot be easily completed.

{
    "task-name": "ball-in-container",
    "task-description": "Use the spatula to lift a ball over a wall of boxes and drop it into a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: The only action primitives as pick and place. One cannot use a spatula to lift an object.

{
    "task-name": "line-ball-sorting",
    "task-description": "Move balls of different colors along a single green line, placing each ball in a designated colored box at the end of the line. The challenge includes precision in maintaining the ball on the line and the correct identification of the box color corresponding to each ball.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "line/single-green-line-template.urdf"]
}
reasons: Piling or stacking balls are physically infeasible in the simulation.



=========
Now please describe the new task in natural languages and explain its novelty and challenges. Format the answer in a python dictionary with keys "task-name" and value type string, "task-description" (one specific sentence) and value type string, and "assets-used" and value type list of strings. Note that

- Do not use assets that are not in the list above. 
- Tasks that have more colors and shapes are interesting.
- Be as specific as possible about the number, shape, and color of each asset in the task descriptions. 
- The task need to obey physics and remain feasible.





>>> Answer: 
```python
{
    "task-name": "stack-balls-in-bowl",
    "task-description": "Pick up three different colored balls (red, green, and blue) and stack them on top of each other inside a white bowl.",
    "assets-used": ["ball/ball-template.urdf", "bowl/bowl.urdf"]
}
```

**Novelty and Challenges:**

This task introduces the challenge of stacking spherical objects, which is inherently less stable than stacking blocks.  The requirement to stack within the confined space of a bowl further increases the difficulty, demanding precise placement and control. The use of different colored balls adds a minor element of visual distinction, although not strictly necessary for the core challenge.  While stacking two balls might be relatively straightforward, stacking three significantly increases the instability and control demands. This task is novel compared to the examples because it focuses on the dexterity required for manipulating round objects and placing them in a precise arrangement within a container, rather than simply placing objects inside a container or stacking blocks.


================= API Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-in-bowl". Here are some APIs that are defined. Please confirm that you understand these APIs.

"""
class Task():
    """Base Task class."""

    def __init__(self):
        self.ee = Suction
        self.mode = 'train'
        self.sixdof = False
        self.primitive = primitives.PickPlace()
        self.oracle_cams = cameras.Oracle.CONFIG

        # Evaluation epsilons (for pose evaluation metric).
        self.pos_eps = 0.01
        self.rot_eps = np.deg2rad(15)

        # Workspace bounds.
        self.pix_size = 0.003125
        self.bounds = np.array([[0.25, 0.75], [-0.5, 0.5], [0, 0.3]])
        self.zone_bounds = np.copy(self.bounds)

        self.goals = []
        self.lang_goals = []
        self.task_completed_desc = "task completed."
        self.progress = 0
        self._rewards = 0
        self.assets_root = None

    def reset(self, env):
        if not self.assets_root:
            raise ValueError('assets_root must be set for task, '
                             'call set_assets_root().')
        self.goals = []
        self.lang_goals = []
        self.progress = 0  # Task progression metric in range [0, 1].
        self._rewards = 0  # Cumulative returned rewards.

    # -------------------------------------------------------------------------
    # Oracle Agent
    # -------------------------------------------------------------------------

    def oracle(self, env):
        """Oracle agent."""
        OracleAgent = collections.namedtuple('OracleAgent', ['act'])

        def act(obs, info):
            """Calculate action."""

            # Oracle uses perfect RGB-D orthographic images and segmentation masks.
            _, hmap, obj_mask = self.get_true_image(env)

            # Unpack next goal step.
            objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]

            # Match objects to targets without replacement.
            if not replace:

                # Modify a copy of the match matrix.
                matches = matches.copy()

                # Ignore already matched objects.
                for i in range(len(objs)):
                    object_id, (symmetry, _) = objs[i]
                    pose = p.getBasePositionAndOrientation(object_id)
                    targets_i = np.argwhere(matches[i, :]).reshape(-1)
                    for j in targets_i:
                        if self.is_match(pose, targs[j], symmetry):
                            matches[i, :] = 0
                            matches[:, j] = 0

            # Get objects to be picked (prioritize farthest from nearest neighbor).
            nn_dists = []
            nn_targets = []
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                xyz, _ = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                if len(targets_i) > 0:
                    targets_xyz = np.float32([targs[j][0] for j in targets_i])
                    dists = np.linalg.norm(
                        targets_xyz - np.float32(xyz).reshape(1, 3), axis=1)
                    nn = np.argmin(dists)
                    nn_dists.append(dists[nn])
                    nn_targets.append(targets_i[nn])

                # Handle ignored objects.
                else:
                    nn_dists.append(0)
                    nn_targets.append(-1)
            order = np.argsort(nn_dists)[::-1]

            # Filter out matched objects.
            order = [i for i in order if nn_dists[i] > 0]

            pick_mask = None
            for pick_i in order:
                pick_mask = np.uint8(obj_mask == objs[pick_i][0])

                # Erode to avoid picking on edges.
                # pick_mask = cv2.erode(pick_mask, np.ones((3, 3), np.uint8))

                if np.sum(pick_mask) > 0:
                    break

            # Trigger task reset if no object is visible.
            if pick_mask is None or np.sum(pick_mask) == 0:
                self.goals = []
                self.lang_goals = []
                print('Object for pick is not visible. Skipping demonstration.')
                return

            # Get picking pose.
            pick_prob = np.float32(pick_mask)
            pick_pix = utils.sample_distribution(pick_prob)
            # For "deterministic" demonstrations on insertion-easy, use this:
            # pick_pix = (160,80)
            pick_pos = utils.pix_to_xyz(pick_pix, hmap,
                                        self.bounds, self.pix_size)
            pick_pose = (np.asarray(pick_pos), np.asarray((0, 0, 0, 1)))

            # Get placing pose.
            targ_pose = targs[nn_targets[pick_i]]
            obj_pose = p.getBasePositionAndOrientation(objs[pick_i][0])
            if not self.sixdof:
                obj_euler = utils.quatXYZW_to_eulerXYZ(obj_pose[1])
                obj_quat = utils.eulerXYZ_to_quatXYZW((0, 0, obj_euler[2]))
                obj_pose = (obj_pose[0], obj_quat)
            world_to_pick = utils.invert(pick_pose)
            obj_to_pick = utils.multiply(world_to_pick, obj_pose)
            pick_to_obj = utils.invert(obj_to_pick)
            place_pose = utils.multiply(targ_pose, pick_to_obj)

            # Rotate end effector?
            if not rotations:
                place_pose = (place_pose[0], (0, 0, 0, 1))

            place_pose = (np.asarray(place_pose[0]), np.asarray(place_pose[1]))

            return {'pose0': pick_pose, 'pose1': place_pose}

        return OracleAgent(act)

    # -------------------------------------------------------------------------
    # Reward Function and Task Completion Metrics
    # -------------------------------------------------------------------------

    def reward(self):
        """Get delta rewards for current timestep.

        Returns:
          A tuple consisting of the scalar (delta) reward, plus `extras`
            dict which has extra task-dependent info from the process of
            computing rewards that gives us finer-grained details. Use
            `extras` for further data analysis.
        """
        reward, info = 0, {}

        # Unpack next goal step.
        objs, matches, targs, _, _, metric, params, max_reward = self.goals[0]

        # Evaluate by matching object poses.
        if metric == 'pose':
            step_reward = 0
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                pose = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                for j in targets_i:
                    target_pose = targs[j]
                    if self.is_match(pose, target_pose, symmetry):
                        step_reward += max_reward / len(objs)
                        print(f"object {i} match with target {j} rew: {step_reward}")
                        break

        # Evaluate by measuring object intersection with zone.
        elif metric == 'zone':
            zone_pts, total_pts = 0, 0
            obj_pts, zones = params
            for zone_idx, (zone_pose, zone_size) in enumerate(zones):

                # Count valid points in zone.
                for obj_idx, obj_id in enumerate(obj_pts):
                    pts = obj_pts[obj_id]
                    obj_pose = p.getBasePositionAndOrientation(obj_id)
                    world_to_zone = utils.invert(zone_pose)
                    obj_to_zone = utils.multiply(world_to_zone, obj_pose)
                    pts = np.float32(utils.apply(obj_to_zone, pts))
                    if len(zone_size) > 1:
                        valid_pts = np.logical_and.reduce([
                            pts[0, :] > -zone_size[0] / 2, pts[0, :] < zone_size[0] / 2,
                            pts[1, :] > -zone_size[1] / 2, pts[1, :] < zone_size[1] / 2,
                            pts[2, :] < self.zone_bounds[2, 1]])

                    # if zone_idx == matches[obj_idx].argmax():
                    zone_pts += np.sum(np.float32(valid_pts))
                    total_pts += pts.shape[1]
            step_reward = max_reward * (zone_pts / total_pts)

        # Get cumulative rewards and return delta.
        reward = self.progress + step_reward - self._rewards
        self._rewards = self.progress + step_reward

        # Move to next goal step if current goal step is complete.
        if np.abs(max_reward - step_reward) < 0.01:
            self.progress += max_reward  # Update task progress.
            self.goals.pop(0)
            if len(self.lang_goals) > 0:
                self.lang_goals.pop(0)

        return reward, info

    def done(self):
        """Check if the task is done or has failed.

        Returns:
          True if the episode should be considered a success, which we
            use for measuring successes, which is particularly helpful for tasks
            where one may get successes on the very last time step, e.g., getting
            the cloth coverage threshold on the last alllowed action.
            However, for bag-items-easy and bag-items-hard (which use the
            'bag-items' metric), it may be necessary to filter out demos that did
            not attain sufficiently high reward in external code. Currently, this
            is done in `main.py` and its ignore_this_demo() method.
        """
        return (len(self.goals) == 0) or (self._rewards > 0.99)
        # return zone_done or defs_done or goal_done

    # -------------------------------------------------------------------------
    # Environment Helper Functions
    # -------------------------------------------------------------------------

    def is_match(self, pose0, pose1, symmetry):
        """Check if pose0 and pose1 match within a threshold."""

        # Get translational error.
        diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
        dist_pos = np.linalg.norm(diff_pos)

        # Get rotational error around z-axis (account for symmetries).
        diff_rot = 0
        if symmetry > 0:
            rot0 = np.array(utils.quatXYZW_to_eulerXYZ(pose0[1]))[2]
            rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]
            diff_rot = np.abs(rot0 - rot1) % symmetry
            if diff_rot > (symmetry / 2):
                diff_rot = symmetry - diff_rot

        return (dist_pos < self.pos_eps) and (diff_rot < self.rot_eps)

    def get_random_pose(self, env, obj_size):
        """Get random collision-free object pose within workspace bounds."""

        # Get erosion size of object in pixels.
        max_size = np.sqrt(obj_size[0] ** 2 + obj_size[1] ** 2)
        erode_size = int(np.round(max_size / self.pix_size))

        _, hmap, obj_mask = self.get_true_image(env)

        # Randomly sample an object pose within free-space pixels.
        free = np.ones(obj_mask.shape, dtype=np.uint8)
        for obj_ids in env.obj_ids.values():
            for obj_id in obj_ids:
                free[obj_mask == obj_id] = 0
        free[0, :], free[:, 0], free[-1, :], free[:, -1] = 0, 0, 0, 0
        free = cv2.erode(free, np.ones((erode_size, erode_size), np.uint8))

        # if np.sum(free) == 0:
        #     return None, None

        if np.sum(free) == 0:
            # avoid returning None, None
            # return None, None
            pix = (obj_mask.shape[0] // 2, obj_mask.shape[1] // 2)
        else:
            pix = utils.sample_distribution(np.float32(free))
        pos = utils.pix_to_xyz(pix, hmap, self.bounds, self.pix_size)
        pos = (pos[0], pos[1], obj_size[2] / 2)
        theta = np.random.rand() * 2 * np.pi
        rot = utils.eulerXYZ_to_quatXYZW((0, 0, theta))
        return pos, rot

    def get_lang_goal(self):
        if len(self.lang_goals) == 0:
            return self.task_completed_desc
        else:
            return self.lang_goals[0]

    def get_reward(self):
        return float(self._rewards)

    # -------------------------------------------------------------------------
    # Helper Functions
    # -------------------------------------------------------------------------

    def fill_template(self, template, replace):
        """Read a file and replace key strings."""
        full_template_path = os.path.join(self.assets_root, template)
        with open(full_template_path, 'r') as file:
            fdata = file.read()
        for field in replace:
            for i in range(len(replace[field])):
                fdata = fdata.replace(f'{field}{i}', str(replace[field][i]))
        alphabet = string.ascii_lowercase + string.digits
        rname = ''.join(random.choices(alphabet, k=16))
        tmpdir = tempfile.gettempdir()
        template_filename = os.path.split(template)[-1]
        fname = os.path.join(tmpdir, f'{template_filename}.{rname}')
        with open(fname, 'w') as file:
            file.write(fdata)
        return fname

    def get_random_size(self, min_x, max_x, min_y, max_y, min_z, max_z):
        """Get random box size."""
        size = np.random.rand(3)
        size[0] = size[0] * (max_x - min_x) + min_x
        size[1] = size[1] * (max_y - min_y) + min_y
        size[2] = size[2] * (max_z - min_z) + min_z
        return tuple(size)

    def color_random_brown(self, obj):
        shade = np.random.rand() + 0.5
        color = np.float32([shade * 156, shade * 117, shade * 95, 255]) / 255
        p.changeVisualShape(obj, -1, rgbaColor=color)

  """""
  
  # Environment Class
  def add_object(self, urdf, pose, category='rigid'):
    """List of (fixed, rigid, or deformable) objects in env."""
    fixed_base = 1 if category == 'fixed' else 0
    obj_id = pybullet_utils.load_urdf(
        p,
        os.path.join(self.assets_root, urdf),
        pose[0],
        pose[1],
        useFixedBase=fixed_base)
    self.obj_ids[category].append(obj_id)
    return obj_id
"""

=========
Note that the objects need to obey physics and not collide with each other, and the object goal poses need to be above the table with lower bound x=0.25, y=-0.5 and upper bound x=0.75, y=0.5. When there are multiple objects for a multi-step pick-and-place task, there are often multiple subgoals. Once the task and environment are generated, an agent with a pick and place primitive will follow the defined goal to accomplish the tasks. 

Additionally, make sure you understand and summarize the ``self.goals`` variables, which has a list of 8-tuple with (objs, matches, targ_poses, replace, rotations, metric, params, step_max_reward, symmetries).
- objs (List of obj_id): object ID.
- matches (Binary Matrix): a binary matrix that denotes which object is matched with which target. This matrix has dimension len(objs) x len(targs).
- targ_poses (List of Poses [(translation, rotation)] ): a list of target poses of tuple (translation, rotation). 
- replace (Boolean): whether each object can match with one unique target. This is important if we have one target and multiple objects. If it's set to be false, then any object matching with the target will satisfy.
- rotations (Boolean): whether the placement action has a rotation degree of freedom. 
- metric (`pose` or `zone`): `pose` or `zone` that the object needs to be transported to. Example: `pose`. 
- params (List of (zone_target, zone_size)): a list of (zone_target, zone_size) for each zone if the metric is `zone`. 
- step_max_reward (float): the total reward of matching all the objects with all the target poses. It is not dependent on the number of objects but dependent on the number of goals. 
- symmetries: the radians that the object is symmetric around z axis.
- language_goal: the low-level language instructions that denote the goal of this step.
 


>>> Answer: 
Yes, I understand the provided APIs and their intended usage. Here's a summary of my understanding:

**Task Class:**

The `Task` class defines the base structure and functionality for a manipulation task.  It handles reward calculation, task completion checks, oracle agent actions, and helper functions for environment interaction.

* **Initialization (`__init__`)**: Sets up default values for the suction end-effector, training mode, workspace bounds, evaluation metrics, and other task parameters.  Importantly, it initializes `self.goals` (and `self.lang_goals`) to empty lists.  These lists will hold the specific goal definitions for the task.
* **Reset (`reset`)**: Clears the goal lists, progress, and rewards, preparing the task for a new episode.  It also checks that `assets_root` has been set.
* **Oracle (`oracle`)**: Provides an oracle agent that uses perfect information (RGB-D, segmentation masks) to demonstrate optimal actions. The oracle agent iterates through the `self.goals` list, selecting objects to pick and placing them at their corresponding target poses.  It handles object matching, prioritizes objects based on distance to targets, and accounts for object symmetries and rotations.
* **Reward (`reward`)**: Calculates the reward for the current timestep based on the current goal in `self.goals`.  It supports two metrics: 'pose' (matching object poses to target poses) and 'zone' (measuring object intersection with a target zone).  The reward is the delta progress towards the goal.
* **Done (`done`)**: Checks if the task is complete (all goals achieved) or if the maximum reward has been reached.
* **Helper Functions**: Includes functions for checking pose matching (`is_match`), generating random poses (`get_random_pose`), getting language goals (`get_lang_goal`), getting the current reward (`get_reward`), filling templates (`fill_template`), getting random sizes (`get_random_size`), and coloring objects brown (`color_random_brown`).
* **Environment Interaction**: The `Task` class interacts with the environment (not fully provided but implied) through functions like `get_true_image` (to get perfect sensor information) and PyBullet functions like `p.getBasePositionAndOrientation` and `p.changeVisualShape`.

**Environment Class (Partial):**

The provided snippet of the environment class shows the `add_object` function, which loads a URDF into the PyBullet simulation.

**Understanding `self.goals`:**

The `self.goals` variable is crucial. It's a list of 8-tuples, each defining a sub-goal within the overall task.  Here's a breakdown of each element in the tuple:

1. **`objs`**: A list of object IDs (integers) representing the objects involved in this sub-goal.
2. **`matches`**: A binary matrix indicating which object should be matched with which target pose.  Rows correspond to objects, columns to target poses. A '1' at `matches[i, j]` means object `i` should be placed at target pose `j`.
3. **`targs` (or `targ_poses`):** A list of target poses, each a tuple of (position, orientation quaternion).  These are the desired locations and orientations for the objects.
4. **`replace`**: A boolean flag.  If `True`, an object can be matched to multiple targets. If `False`, each object can only be matched to a single unique target.
5. **`rotations`**: A boolean flag. If `True`, the end-effector orientation during placement matters. If `False`, only the position is considered.
6. **`metric`**: A string, either 'pose' or 'zone', specifying how the reward is calculated for this sub-goal.
7. **`params`**:  Additional parameters depending on the `metric`. For 'zone', it's a list of (zone_target, zone_size) tuples.
8. **`step_max_reward`**: The maximum reward achievable for this sub-goal.  The total task reward is the sum of the `step_max_reward` values for all sub-goals.
9. **`symmetries`**: The rotational symmetry of the object around the z-axis, in radians. This is used in the `is_match` function to account for symmetries when comparing object and target poses.


**Key Considerations for "stack-balls-in-bowl":**

* **Physics and Collision Avoidance**: The code needs to ensure that objects interact realistically with physics and avoid collisions, both during manipulation and in their final placed positions.
* **Workspace Bounds**: Object placement must respect the specified workspace bounds.
* **Multi-Step Tasks**: For stacking multiple objects, `self.goals` will likely contain multiple sub-goals, each representing a single pick-and-place action.
* **Pick and Place Primitive**: The agent will use a predefined pick and place primitive to interact with the environment.  The oracle agent demonstrates how this primitive should be used.


By understanding these APIs and the structure of `self.goals`, I can now effectively write code for the "stack-balls-in-bowl" task.


================= Error Book Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-in-bowl". Here are some runtime errors that you do not want to make. Please confirm that you understand these runtime errors.

"""
- environment.py, line 338, in info
    pos, rot = p.getBasePositionAndOrientation(obj_id)
TypeError: an integer is required (got type NoneType)

- task.py, line 118, in act
    objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]
IndexError: list index out of range

- task.py, line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
TypeError: 'float' object is not subscriptable

- task.py", line 315, in is_match
  rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]

- utils.py", line 280, in quatXYZW_to_eulerXYZ
  quaternion_wxyz = np.array([q[3], q[0], q[1], q[2]])
IndexError: tuple index out of range

- pallet_pose = self.get_random_pose(env, pallet_size)
pallet_surface_height = pallet_pose[0][2]
TypeError: 'NoneType' object is not subscriptable

- No such file or directory: './cliport/environments/assets/circle/circle-template.urdf'

- No such file or directory: './cliport/environments/assets/block/block-template.urdf'

- task.py", line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
IndexError: invalid index to scalar variable.

-TypeError: get_random_size() missing 4 required positional arguments: 'min_y', 'max_y', 'min_z', and 'max_z' 

- task.py", line 195, in reward
    obj_pts, zones = params
TypeError: cannot unpack non-iterable NoneType object

-  environment.py", line 230, in step
    reward, info = self.task.reward() if action is not None else (0, {})
  File "task.py", line 200, in reward
    pts = obj_pts[obj_id]
IndexError: arrays used as indices must be of integer (or boolean) type

- generated_task.py", line 41, in reset
    utils.COLORS['green'], utils.COLORS['blue'], utils.COLORS['light blue'],
KeyError: 'light blue'

- environment.py", line 195, in reset
    self.task.reset(self)
  File "<string>", line 38, in reset
TypeError: can only concatenate str (not "list") to str

- environment.py", line 195, in reset
  object_shape = np.random.choice(object_shapes)
  in numpy.random.mtrand.RandomState.choice
ValueError: a must be 1-dimensional

- No such file or directory: 'assets/box-template/box-template.urdf'

- line 38, in reset.py
{'HALF': box_size / 2}
TypeError: unsupported operand type(s) for /: 'tuple' and 'int'. box_size is a tuple not a float.

- line 38, in reset.py
IndexError: tuple index out of range
box_pose = (pallet_pose[0], pallet_pose[1], pallet_pose[2] + np.sum(box_sizes[:i+1]))

- task.py", line 338, in fill_template
    for i in range(len(replace[field])):
TypeError: object of type 'float' has no len().

- task.py", line 325, in get_random_pose
    pos = (pos[0], pos[1], obj_size[2] / 2)
IndexError: tuple index out of range

- task.py", line 206, in reward
    for zone_idx, (zone_pose, zone_size) in enumerate(zones):
TypeError: 'NoneType' object is not iterable

- task.py",
ball_pose = self.get_random_pose(env, ball_size)
ball_pose[0][2] += 0.02
TypeError: 'tuple' object does not support item assignment
"""


You do not want to make mistakes such as
- using assets (urdfs) that do not exist
- use ambiguous language descriptions as goals. For instance, "place the colored blocks into the matching colored bowls" with one goal and sparse reward as the task instead of adding subgoal "place blue block into blue bowl" and give continuous reward. 
- `matches` in the goal has wrong dimensions. It should have the same dimensions as number of objects (N) multiplied by the number of goal poses (M). Usually it is N by M.
- have vector dimension problem such as `np.random.choice(box_size)` or `box_size / 2` where `box_size` is a tuple and not an int
- make too large an object for stacking or make the task objects invisible for picking. 
- accessing index out of bound `pallet_pose[2]` for `pallet_pose`.  `pallet_pose=get_random_pose` returns a tuple (translation, rotation). It does not have 3rd component. Similarly accessing `container_pose[2]` or `box_pose[2]` would cause errors as well. Since it's a tuple, try to modify it in-place will also trigger errors.
- forget to replace str using `fill_template()` for urdfs with template such as `cylinder-template.urdf`. `ball-template.urdf`, `line-template.urf`. 
- use `self.ee = Spatula()` as a function when doing pushing tasks, which is incorrect. It should be `self.ee = Spatula`.
- forget to compute target poses `targ_poses` for matching. Do not use object IDs for poses.
- change colors of complex objects such as `zone`. You can only change color of teomplate primitive such as `cylinder-template`.
- mistakenly use `random_pose` for target pose. Design target poses based on task objectives.
- add only one or fewer language goals which causes language-motion inconsistentcy. Note that the language goals usually are the same number as the pick and place goals.


>>> Answer: 
Yes, I understand the runtime errors listed and the additional points you've made about avoiding mistakes in task generation. I will be mindful of these issues when writing the code for the "stack-balls-in-bowl" task.  I will pay particular attention to:

* **File Paths and Existence:** Verify that all URDF files exist in the correct locations.
* **Clear Language Goals:**  Provide specific and unambiguous language descriptions for each subgoal, avoiding vague phrasing.
* **Matches Dimensions:** Ensure the `matches` array has the correct dimensions (N x M), reflecting the number of objects and target poses.
* **Vector Dimensions and Operations:**  Handle tuple and array operations correctly, avoiding operations like division or random choice on tuples directly.  Convert to numpy arrays when necessary.
* **Object Sizes and Visibility:** Keep object sizes reasonable for stacking and ensure they are visible for manipulation.
* **Pose Tuple Access:** Access elements of pose tuples (translation, rotation) correctly, remembering they are length 2. Avoid in-place modification.
* **Template Filling:** Use `fill_template()` to replace placeholders in URDFs with specific values.
* **Spatula Instantiation:** Use `self.ee = Spatula()` for spatula tasks, not as a function call.
* **Target Pose Calculation:** Explicitly calculate `targ_poses` based on task objectives, not object IDs.
* **Color Changes:** Only change colors of primitive template objects, not complex objects like zones.
* **Random Poses vs. Designed Poses:** Use `random_pose` appropriately and design target poses based on the task goals.
* **Sufficient Language Goals:** Provide enough language goals to match the number of pick-and-place actions, ensuring language-motion consistency.


By addressing these points, I aim to avoid the listed runtime errors and create a robust and functional "stack-balls-in-bowl" task.


================= Code Generation!

>>> Prompt: 
Now I will provide you some reference code and you can write the code for the task "stack-balls-in-bowl".


"""
import os

import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils


class PackingShapes(Task):
    """pick up randomly sized shapes and place them tightly into a container."""

    def __init__(self):
        super().__init__()
        self.max_steps = 1
        self.homogeneous = False

        self.lang_template = "pack the {obj} in the brown box"
        self.task_completed_desc = "done packing shapes."
        self.additional_reset()


    def reset(self, env):
        super().reset(env)

        # Shape Names:
        shapes = utils.assembling_kit_shapes

        n_objects = 5
        if self.mode == 'train':
            obj_shapes = np.random.choice(self.train_set, n_objects, replace=False)
        else:
            if self.homogeneous:
                obj_shapes = [np.random.choice(self.test_set, replace=False)] * n_objects
            else:
                obj_shapes = np.random.choice(self.test_set, n_objects, replace=False)

        # Shuffle colors to avoid always picking an object of the same color
        colors, color_names = utils.get_colors(mode=self.mode)

        # Add container box.
        zone_size = self.get_random_size(0.1, 0.15, 0.1, 0.15, 0.05, 0.05)
        zone_pose = self.get_random_pose(env, zone_size)
        container_template = 'container/container-template.urdf'
        replace = {'DIM': zone_size, 'HALF': (zone_size[0] / 2, zone_size[1] / 2, zone_size[2] / 2)}
        # IMPORTANT: REPLACE THE TEMPLATE URDF with `fill_template`
        container_urdf = self.fill_template(container_template, replace)
        env.add_object(container_urdf, zone_pose, 'fixed')

        # Add objects.
        objects = []
        template = 'kitting/object-template.urdf'
        for i in range(n_objects):
            shape = obj_shapes[i]

            # x, y, z dimensions for the asset size
            size = (0.08, 0.08, 0.02)
            pose= self.get_random_pose(env, size)
            fname = f'{shape:02d}.obj'
            fname = os.path.join(self.assets_root, 'kitting', fname)
            scale = [0.003, 0.003, 0.001]  # .0005
            replace = {'FNAME': (fname,),
                       'SCALE': scale,
                       'COLOR': colors[i]}

            # IMPORTANT: REPLACE THE TEMPLATE URDF
            urdf = self.fill_template(template, replace)
            block_id = env.add_object(urdf, pose)
            objects.append(block_id)

        # Pick the first shape.
        num_objects_to_pick = 1
        for i in range(num_objects_to_pick):
            # IMPORTANT: Specify (obj_pts, [(zone_pose, zone_size)]) for target `zone`. obj_pts is a dict
            language_goal = self.lang_template.format(obj=shapes[obj_shapes[i]])
            self.add_goal(objs=[objects[i]], matches=np.int32([[1]]), targ_poses=[zone_pose], replace=False,
                rotations=True, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1 / num_objects_to_pick,
                language_goal=language_goal)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p


class PlaceRedInGreen(Task):
    """pick up the red blocks and place them into the green bowls amidst other objects."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "put the red blocks in a green bowl"
        self.task_completed_desc = "done placing blocks in bowls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)
        n_bowls = np.random.randint(1, 4)
        n_blocks = np.random.randint(1, n_bowls + 1)

        # Add bowls.
        # x, y, z dimensions for the asset size
        bowl_size = (0.12, 0.12, 0)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_poses = []
        for _ in range(n_bowls):
            bowl_pose = self.get_random_pose(env, obj_size=bowl_size)
            env.add_object(urdf=bowl_urdf, pose=bowl_pose, category='fixed')
            bowl_poses.append(bowl_pose)

        # Add blocks.
        # x, y, z dimensions for the asset size
        blocks = []
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'
        for _ in range(n_blocks):
            block_pose = self.get_random_pose(env, obj_size=block_size)
            block_id = env.add_object(block_urdf, block_pose)
            blocks.append(block_id)

        # Goal: each red block is in a different green bowl.
        self.add_goal(objs=blocks, matches=np.ones((len(blocks), len(bowl_poses))), targ_poses=bowl_poses, replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1, language_goal=self.lang_template)

        # Colors of distractor objects.
        bowl_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'green']
        block_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'red']

        # Add distractors.
        n_distractors = 0
        while n_distractors < 6:
            is_block = np.random.rand() > 0.5
            urdf = block_urdf if is_block else bowl_urdf
            size = block_size if is_block else bowl_size
            colors = block_colors if is_block else bowl_colors
            pose = self.get_random_pose(env, obj_size=size)
            color = colors[n_distractors % len(colors)]

            obj_id = env.add_object(urdf, pose, color=color)
            n_distractors += 1
"""
"""
import numpy as np
from cliport.tasks import primitives
from cliport.tasks.grippers import Spatula
from cliport.tasks.task import Task
from cliport.utils import utils


class SweepingPiles(Task):
    """Push piles of small objects into a target goal zone marked on the tabletop."""

    def __init__(self):
        super().__init__()
        self.max_steps = 20
        self.lang_template = "push the pile of blocks into the green square"
        self.task_completed_desc = "done sweeping."
        self.primitive = primitives.push
        self.ee = Spatula
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add goal zone.
        zone_size = (0.12, 0.12, 0)
        zone_pose = self.get_random_pose(env, zone_size)
        env.add_object('zone/zone.urdf', zone_pose, 'fixed')

        # Add pile of small blocks with `make_piles` function
        obj_ids = self.make_piles(env)

        # Add goal
        self.add_goal(objs=obj_ids, matches=np.ones((50, 1)), targ_poses=[zone_pose], replace=True,
                rotations=False, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1, language_goal=self.lang_template)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p

class StackBlockPyramid(Task):
    """Build a pyramid of colored blocks in a color sequence"""

    def __init__(self):
        super().__init__()
        self.max_steps = 12
        self.lang_template = "make the {row} row with {blocks}"
        self.task_completed_desc = "done stacking block pyramid."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add base.
        base_size = (0.05, 0.15, 0.005)
        base_urdf = 'stacking/stand.urdf'
        base_pose = self.get_random_pose(env, base_size)
        env.add_object(base_urdf, base_pose, category='fixed')

        # Block colors.
        colors = [
            utils.COLORS['purple'], utils.COLORS['blue'], utils.COLORS['green'],
            utils.COLORS['yellow'], utils.COLORS['orange'], utils.COLORS['red']
        ]

        # Add blocks.
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'

        objs = []
        for i in range(6):
            block_pose = self.get_random_pose(env, block_size)
            block_id = env.add_object(block_urdf, block_pose, color=colors[i])
            objs.append(block_id)

        # IMPORTANT Associate placement locations for goals.
        place_pos = [(0, -0.05, 0.03), (0, 0, 0.03),
                     (0, 0.05, 0.03), (0, -0.025, 0.08),
                     (0, 0.025, 0.08), (0, 0, 0.13)]
        targs = [(utils.apply(base_pose, i), base_pose[1]) for i in place_pos]

        # Goal: blocks are stacked in a pyramid (bottom row: green, blue, purple).
        language_goal = self.lang_template.format(blocks="the green, blue and purple blocks", row="bottom")
        self.add_goal(objs=objs[:3], matches=np.ones((3, 3)), targ_poses=targs[:3], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 2, symmetries=[np.pi/2]*3, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (middle row: yellow, orange).
        language_goal = self.lang_template.format(blocks="the yellow and orange blocks", row="middle")      
        self.add_goal(objs=objs[3:5], matches=np.ones((2, 2)), targ_poses=targs[3:5], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 3, symmetries=[np.pi/2]*2, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (top row: red).
        language_goal = self.lang_template.format(blocks="the red block", row="top")
        self.add_goal(objs=objs[5:], matches=np.ones((1, 1)), targ_poses=targs[5:], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 6, symmetries=[np.pi/2]*1, language_goal=language_goal)
"""



Do not use libraries, functions, and assets that you don't know. For each object, try to describe its color, size, category in the task first before you write the code. You do not need extra helper functions. Comment the code liberally to explain what each piece does and why it's written that way. If you have only one goal, `step_max_reward` in `add_goal` should be 1. Use functions `make_piles` and `make_ropes` for creating piles and cables. To use spatula together with the push primitives, import the libraries 
"""
from cliport.tasks import primitives;
from cliport.tasks.grippers import Spatula
"""
and then use `self.primitive = primitives.push` and `self.ee = Spatula`.
Note that the number of language goals usually match the number of motion goals, since they should correspond to each other.

Now write the code for the task "stack-balls-in-bowl" in python code block starting with ```python.  Reminder: {'task-name': 'stack-balls-in-bowl', 'task-description': 'Pick up three different colored balls (red, green, and blue) and stack them on top of each other inside a white bowl.', 'assets-used': ['ball/ball-template.urdf', 'bowl/bowl.urdf']} 


>>> Answer: 
```python
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils

class StackBallsInBowl(Task):
    """Pick up three different colored balls (red, green, and blue) and stack them on top of each other inside a white bowl."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "stack the red, green, and blue balls in the white bowl"
        self.task_completed_desc = "done stacking balls in bowl."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Bowl
        # Size: medium (0.12, 0.12, 0)
        # Color: white
        # Category: fixed (cannot be moved)
        bowl_size = (0.12, 0.12, 0)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_pose = self.get_random_pose(env, bowl_size)
        bowl_id = env.add_object(bowl_urdf, bowl_pose, 'fixed', color=utils.COLORS['white'])

        # Balls
        # Size: small (0.04, 0.04, 0.04)
        # Colors: red, green, blue
        # Category: object (can be moved)
        ball_size = (0.04, 0.04, 0.04)
        ball_urdf = 'ball/ball-template.urdf'
        colors = ['red', 'green', 'blue']
        ball_ids = []

        for color in colors:
            ball_pose = self.get_random_pose(env, ball_size)
            ball_id = env.add_object(ball_urdf, ball_pose, color=utils.COLORS[color])
            ball_ids.append(ball_id)

        # Goal: stack balls in the bowl. The target poses are stacked vertically within the bowl.
        # We use place_pos to define relative positions of the balls with respect to the bowl pose.
        place_pos = [(0, 0, 0.04), (0, 0, 0.08), (0, 0, 0.12)] # Positions relative to the bowl
        targ_poses = [(utils.apply(bowl_pose, i), bowl_pose[1]) for i in place_pos]

        # Define matches matrix. Since we want a specific order (red, green, then blue),
        # the matches matrix is an identity matrix.
        matches = np.eye(3)

        self.add_goal(objs=ball_ids, matches=matches, targ_poses=targ_poses, replace=False,
                      rotations=True, metric='pose', params=None, step_max_reward=1,
                      language_goal=self.lang_template) # step_max_reward is 1 because there's only one goal
```

================= TRIAL: 2

================= TRIAL: 2

================= TRIAL: 2

================= TRIAL: 2

================= Task and Asset Design!

>>> Prompt: 
You are an AI in robot simulation code and task design. I will provide you some example tasks, code implementation, and some guidelines for how to generate tasks and then you will help me generate a new task. My goal is to design diverse and feasible tasks for tabletop manipulation. I will first ask you to describe the task in natural languages and then will let you write the code for it. 

=========
Here are all the assets. Use only these assets in the task and code design. 
"""
insertion/:
ell.urdf  fixture.urdf

bowl/:
bowl.urdf

box/:
box-template.urdf

stacking/:
block.urdf  stand.urdf

zone/:
zone.obj  zone.urdf

pallet/:
pallet.obj  pallet.urdf

ball/:
ball-template.urdf

cylinder/:
cylinder-template.urdf

bowl/:
bowl.urdf

# assets not for picking
corner/:
corner-template.urdf

line/:
single-green-line-template.urdf

container/:
container-template.urdf
"""
 
=========
Here are some examples of good tasks. Try to learn from these structures but avoid overlapping wiht them.

{"assets-used": ["zone/zone.urdf", "block/small.urdf"],
 "task-description": "Push piles of small objects into a target goal zone marked on the tabletop.",
 "task-name": "sweeping-piles"}

{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "Place all blocks of a specified color in a bowl of specified color.",
 "task-name": "put-block-in-bowl"}
 
{"assets-used": ["insertion/ell.urdf", "insertion/fixture.urdf"],
 "task-description": "pick up the L-shaped red block and place it into the L-shaped fixture.",
 "task-name": "block-insertion"}
 
{"assets-used": ["kitting/kit.urdf", "kitting/object-template.urdf"],
 "task-description": "pick up different objects and arrange them on a board marked with corresponding silhouettes.",
 "task-name": "assembling-kits"}
 
{"assets-used": ["pallet/pallet.urdf", "box/box-template.urdf"],
 "task-description": "pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.",
 "task-name": "palletizing-boxes"}
 
{"assets-used": ["stacking/stand.urdf", "stacking/block.urdf"],
 "task-description": "sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.",
 "task-name": "stack-block-pyramid"}
 
{"assets-used": ["container/container-template.urdf", "box/box-template.urdf"],
 "task-description": "pick up randomly sized boxes and place them tightly into a container.",
 "task-name": "packing-boxes"}
 
{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "pick up the red blocks and place them into the green bowls amidst other objects.",
 "task-name": "place-red-in-green"}
 
{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

=========
Here are some tasks that you have come up with before. Try to learn from these structures but avoid overlapping with these tasks. For instance, `bowl_ball_placement` and `sort_balls_in_bowls` are the same task. `pile_boxes_in_corner` and `stack_blocks_into_pallet` are similar tasks, `align-cylinder-in-corner` and `align-cylinder-corner` are similar.
- sweeping-piles: {'assets-used': ['zone/zone.urdf', 'block/small.urdf'], 'task-description': 'push piles of small objects into a target goal zone marked on the tabletop.', 'task-name': 'sweeping-piles'}
- place-red-in-green: {'assets-used': ['bowl/bowl.urdf', 'stacking/block.urdf'], 'task-description': 'pick up the red blocks and place them into the green bowls amidst other objects.', 'task-name': 'place-red-in-green'}
- align-box-corner: {'assets-used': ['box/box-template.urdf', 'corner/corner-template.urdf'], 'task-description': 'pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..', 'task-name': 'align-box-corner'}
- stack-block-pyramid: {'assets-used': ['stacking/stand.urdf', 'stacking/block.urdf'], 'task-description': 'sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.', 'task-name': 'stack-block-pyramid'}
- palletizing-boxes: {'assets-used': ['pallet/pallet.urdf', 'box/box-template.urdf'], 'task-description': 'pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.', 'task-name': 'palletizing-boxes'}
- assembling-kits: {'assets-used': ['kitting/kit.urdf', 'kitting/object-template.urdf'], 'task-description': 'pick up different objects and arrange them on a board marked with corresponding silhouettes.', 'task-name': 'assembling-kits'}
- packing-boxes: {'assets-used': ['container/container-template.urdf', 'box/box-template.urdf'], 'task-description': 'pick up randomly sized boxes and place them tightly into a container.', 'task-name': 'packing-boxes'}
- manipulating-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'rearrange a deformable rope such that it connects the two endpoints of a 3-sided square.', 'task-name': 'manipulating-rope'}
- align-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'manipulate a deformable rope to connect its end-points between two corners of a 3-sided square.', 'task-name': 'align-rope'}





=========
Here are some bad example task instances with explanations.
{
    "task_name": "sort-color-blocks",
    "task_descriptions": "Pick up differently colored blocks and place them into separate bowls of matching color."
    "assets-used": ["bowl.urdf", "box/box-template.urdf],
}
reasons: not interesting because it overlaps with the current task `put-block-in-bowl`.

{
    "task-name": "guided-ball-maze",
    "task-description": "Navigate a small ball through a maze by tilting the maze board to reach the target zone.",
    "assets-used": ["zone-template.urdf", "square-template.urdf", "ball.urdf", "maze.urdf"],
}
reasons: the language descriptions are too ambiguous. Navigation is also hard to complete. Also maze.urf does not exist.

{
    "task-name": "insert_cylinder_in_sphere",
    "task-description": "Pick up the cylinder and insert it into the sphere with an opening on top.",
    "assets-used": ["cylinder/cylinder-template.urdf", "sphere/sphere-template.urdf"],
}
reasons: this task does not make sense. The sphere does not have an opening on top, and you cannot insert a cylinder into a sphere. Similarly tasks like `insert-ball-into-cylinder` and `cylinder-box-insertion` are invalid.

{
    "task-name": "ball-box-obstacle-course",
    "task-description": "Navigate a ball through an obstacle course created by randomly placed boxes and finally place it inside a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: Navigate the ball is not related to tabletop manipulation tasks.

{
    "task-name": "ball-in-box",
    "task-description": "Use a cable to guide a ball into an open box.",
    "assets-used": ["cable/cable.urdf", "ball/ball-template.urdf", "box/box-template.urdf"]
}
reasons: This task is too hard since it involves interaction of the cable and the ball and cannot be easily completed.

{
    "task-name": "ball-in-container",
    "task-description": "Use the spatula to lift a ball over a wall of boxes and drop it into a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: The only action primitives as pick and place. One cannot use a spatula to lift an object.

{
    "task-name": "line-ball-sorting",
    "task-description": "Move balls of different colors along a single green line, placing each ball in a designated colored box at the end of the line. The challenge includes precision in maintaining the ball on the line and the correct identification of the box color corresponding to each ball.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "line/single-green-line-template.urdf"]
}
reasons: Piling or stacking balls are physically infeasible in the simulation.



=========
Now please describe the new task in natural languages and explain its novelty and challenges. Format the answer in a python dictionary with keys "task-name" and value type string, "task-description" (one specific sentence) and value type string, and "assets-used" and value type list of strings. Note that

- Do not use assets that are not in the list above. 
- Tasks that have more colors and shapes are interesting.
- Be as specific as possible about the number, shape, and color of each asset in the task descriptions. 
- The task need to obey physics and remain feasible.





>>> Answer: 
```python
{
    "task-name": "stack-balls-in-bowl",
    "task-description": "Pick up three different colored balls (red, green, and blue) and stack them inside a yellow bowl.",
    "assets-used": ["ball/ball-template.urdf", "bowl/bowl.urdf"],
}
```

**Novelty:** While involving familiar pick-and-place actions, this task introduces the challenge of stacking balls, which are inherently unstable, within a bowl. This differs from stacking blocks, as balls require more precise placement and control to maintain balance. The use of different colored balls and the bowl adds a visual element that can be used for variations or increased difficulty (e.g., stacking in a specific color order).

**Challenges:**

* **Stacking Stability:**  The primary challenge lies in achieving and maintaining the balance of the balls within the bowl.  Slight inaccuracies in placement can lead to the stack collapsing.
* **Precision:**  Precise manipulation is crucial for picking up and placing the balls accurately within the bowl's confined space.
* **Grasping Spherical Objects:**  Grasping balls can be more challenging than grasping objects with flat surfaces. The robot needs to adapt its grip to the spherical shape. 
* **Physics-Based Interactions:**  The task relies heavily on realistic physics simulation, making it a good test for robot control algorithms in a dynamic environment. 


================= API Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-in-bowl". Here are some APIs that are defined. Please confirm that you understand these APIs.

"""
class Task():
    """Base Task class."""

    def __init__(self):
        self.ee = Suction
        self.mode = 'train'
        self.sixdof = False
        self.primitive = primitives.PickPlace()
        self.oracle_cams = cameras.Oracle.CONFIG

        # Evaluation epsilons (for pose evaluation metric).
        self.pos_eps = 0.01
        self.rot_eps = np.deg2rad(15)

        # Workspace bounds.
        self.pix_size = 0.003125
        self.bounds = np.array([[0.25, 0.75], [-0.5, 0.5], [0, 0.3]])
        self.zone_bounds = np.copy(self.bounds)

        self.goals = []
        self.lang_goals = []
        self.task_completed_desc = "task completed."
        self.progress = 0
        self._rewards = 0
        self.assets_root = None

    def reset(self, env):
        if not self.assets_root:
            raise ValueError('assets_root must be set for task, '
                             'call set_assets_root().')
        self.goals = []
        self.lang_goals = []
        self.progress = 0  # Task progression metric in range [0, 1].
        self._rewards = 0  # Cumulative returned rewards.

    # -------------------------------------------------------------------------
    # Oracle Agent
    # -------------------------------------------------------------------------

    def oracle(self, env):
        """Oracle agent."""
        OracleAgent = collections.namedtuple('OracleAgent', ['act'])

        def act(obs, info):
            """Calculate action."""

            # Oracle uses perfect RGB-D orthographic images and segmentation masks.
            _, hmap, obj_mask = self.get_true_image(env)

            # Unpack next goal step.
            objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]

            # Match objects to targets without replacement.
            if not replace:

                # Modify a copy of the match matrix.
                matches = matches.copy()

                # Ignore already matched objects.
                for i in range(len(objs)):
                    object_id, (symmetry, _) = objs[i]
                    pose = p.getBasePositionAndOrientation(object_id)
                    targets_i = np.argwhere(matches[i, :]).reshape(-1)
                    for j in targets_i:
                        if self.is_match(pose, targs[j], symmetry):
                            matches[i, :] = 0
                            matches[:, j] = 0

            # Get objects to be picked (prioritize farthest from nearest neighbor).
            nn_dists = []
            nn_targets = []
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                xyz, _ = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                if len(targets_i) > 0:
                    targets_xyz = np.float32([targs[j][0] for j in targets_i])
                    dists = np.linalg.norm(
                        targets_xyz - np.float32(xyz).reshape(1, 3), axis=1)
                    nn = np.argmin(dists)
                    nn_dists.append(dists[nn])
                    nn_targets.append(targets_i[nn])

                # Handle ignored objects.
                else:
                    nn_dists.append(0)
                    nn_targets.append(-1)
            order = np.argsort(nn_dists)[::-1]

            # Filter out matched objects.
            order = [i for i in order if nn_dists[i] > 0]

            pick_mask = None
            for pick_i in order:
                pick_mask = np.uint8(obj_mask == objs[pick_i][0])

                # Erode to avoid picking on edges.
                # pick_mask = cv2.erode(pick_mask, np.ones((3, 3), np.uint8))

                if np.sum(pick_mask) > 0:
                    break

            # Trigger task reset if no object is visible.
            if pick_mask is None or np.sum(pick_mask) == 0:
                self.goals = []
                self.lang_goals = []
                print('Object for pick is not visible. Skipping demonstration.')
                return

            # Get picking pose.
            pick_prob = np.float32(pick_mask)
            pick_pix = utils.sample_distribution(pick_prob)
            # For "deterministic" demonstrations on insertion-easy, use this:
            # pick_pix = (160,80)
            pick_pos = utils.pix_to_xyz(pick_pix, hmap,
                                        self.bounds, self.pix_size)
            pick_pose = (np.asarray(pick_pos), np.asarray((0, 0, 0, 1)))

            # Get placing pose.
            targ_pose = targs[nn_targets[pick_i]]
            obj_pose = p.getBasePositionAndOrientation(objs[pick_i][0])
            if not self.sixdof:
                obj_euler = utils.quatXYZW_to_eulerXYZ(obj_pose[1])
                obj_quat = utils.eulerXYZ_to_quatXYZW((0, 0, obj_euler[2]))
                obj_pose = (obj_pose[0], obj_quat)
            world_to_pick = utils.invert(pick_pose)
            obj_to_pick = utils.multiply(world_to_pick, obj_pose)
            pick_to_obj = utils.invert(obj_to_pick)
            place_pose = utils.multiply(targ_pose, pick_to_obj)

            # Rotate end effector?
            if not rotations:
                place_pose = (place_pose[0], (0, 0, 0, 1))

            place_pose = (np.asarray(place_pose[0]), np.asarray(place_pose[1]))

            return {'pose0': pick_pose, 'pose1': place_pose}

        return OracleAgent(act)

    # -------------------------------------------------------------------------
    # Reward Function and Task Completion Metrics
    # -------------------------------------------------------------------------

    def reward(self):
        """Get delta rewards for current timestep.

        Returns:
          A tuple consisting of the scalar (delta) reward, plus `extras`
            dict which has extra task-dependent info from the process of
            computing rewards that gives us finer-grained details. Use
            `extras` for further data analysis.
        """
        reward, info = 0, {}

        # Unpack next goal step.
        objs, matches, targs, _, _, metric, params, max_reward = self.goals[0]

        # Evaluate by matching object poses.
        if metric == 'pose':
            step_reward = 0
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                pose = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                for j in targets_i:
                    target_pose = targs[j]
                    if self.is_match(pose, target_pose, symmetry):
                        step_reward += max_reward / len(objs)
                        print(f"object {i} match with target {j} rew: {step_reward}")
                        break

        # Evaluate by measuring object intersection with zone.
        elif metric == 'zone':
            zone_pts, total_pts = 0, 0
            obj_pts, zones = params
            for zone_idx, (zone_pose, zone_size) in enumerate(zones):

                # Count valid points in zone.
                for obj_idx, obj_id in enumerate(obj_pts):
                    pts = obj_pts[obj_id]
                    obj_pose = p.getBasePositionAndOrientation(obj_id)
                    world_to_zone = utils.invert(zone_pose)
                    obj_to_zone = utils.multiply(world_to_zone, obj_pose)
                    pts = np.float32(utils.apply(obj_to_zone, pts))
                    if len(zone_size) > 1:
                        valid_pts = np.logical_and.reduce([
                            pts[0, :] > -zone_size[0] / 2, pts[0, :] < zone_size[0] / 2,
                            pts[1, :] > -zone_size[1] / 2, pts[1, :] < zone_size[1] / 2,
                            pts[2, :] < self.zone_bounds[2, 1]])

                    # if zone_idx == matches[obj_idx].argmax():
                    zone_pts += np.sum(np.float32(valid_pts))
                    total_pts += pts.shape[1]
            step_reward = max_reward * (zone_pts / total_pts)

        # Get cumulative rewards and return delta.
        reward = self.progress + step_reward - self._rewards
        self._rewards = self.progress + step_reward

        # Move to next goal step if current goal step is complete.
        if np.abs(max_reward - step_reward) < 0.01:
            self.progress += max_reward  # Update task progress.
            self.goals.pop(0)
            if len(self.lang_goals) > 0:
                self.lang_goals.pop(0)

        return reward, info

    def done(self):
        """Check if the task is done or has failed.

        Returns:
          True if the episode should be considered a success, which we
            use for measuring successes, which is particularly helpful for tasks
            where one may get successes on the very last time step, e.g., getting
            the cloth coverage threshold on the last alllowed action.
            However, for bag-items-easy and bag-items-hard (which use the
            'bag-items' metric), it may be necessary to filter out demos that did
            not attain sufficiently high reward in external code. Currently, this
            is done in `main.py` and its ignore_this_demo() method.
        """
        return (len(self.goals) == 0) or (self._rewards > 0.99)
        # return zone_done or defs_done or goal_done

    # -------------------------------------------------------------------------
    # Environment Helper Functions
    # -------------------------------------------------------------------------

    def is_match(self, pose0, pose1, symmetry):
        """Check if pose0 and pose1 match within a threshold."""

        # Get translational error.
        diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
        dist_pos = np.linalg.norm(diff_pos)

        # Get rotational error around z-axis (account for symmetries).
        diff_rot = 0
        if symmetry > 0:
            rot0 = np.array(utils.quatXYZW_to_eulerXYZ(pose0[1]))[2]
            rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]
            diff_rot = np.abs(rot0 - rot1) % symmetry
            if diff_rot > (symmetry / 2):
                diff_rot = symmetry - diff_rot

        return (dist_pos < self.pos_eps) and (diff_rot < self.rot_eps)

    def get_random_pose(self, env, obj_size):
        """Get random collision-free object pose within workspace bounds."""

        # Get erosion size of object in pixels.
        max_size = np.sqrt(obj_size[0] ** 2 + obj_size[1] ** 2)
        erode_size = int(np.round(max_size / self.pix_size))

        _, hmap, obj_mask = self.get_true_image(env)

        # Randomly sample an object pose within free-space pixels.
        free = np.ones(obj_mask.shape, dtype=np.uint8)
        for obj_ids in env.obj_ids.values():
            for obj_id in obj_ids:
                free[obj_mask == obj_id] = 0
        free[0, :], free[:, 0], free[-1, :], free[:, -1] = 0, 0, 0, 0
        free = cv2.erode(free, np.ones((erode_size, erode_size), np.uint8))

        # if np.sum(free) == 0:
        #     return None, None

        if np.sum(free) == 0:
            # avoid returning None, None
            # return None, None
            pix = (obj_mask.shape[0] // 2, obj_mask.shape[1] // 2)
        else:
            pix = utils.sample_distribution(np.float32(free))
        pos = utils.pix_to_xyz(pix, hmap, self.bounds, self.pix_size)
        pos = (pos[0], pos[1], obj_size[2] / 2)
        theta = np.random.rand() * 2 * np.pi
        rot = utils.eulerXYZ_to_quatXYZW((0, 0, theta))
        return pos, rot

    def get_lang_goal(self):
        if len(self.lang_goals) == 0:
            return self.task_completed_desc
        else:
            return self.lang_goals[0]

    def get_reward(self):
        return float(self._rewards)

    # -------------------------------------------------------------------------
    # Helper Functions
    # -------------------------------------------------------------------------

    def fill_template(self, template, replace):
        """Read a file and replace key strings."""
        full_template_path = os.path.join(self.assets_root, template)
        with open(full_template_path, 'r') as file:
            fdata = file.read()
        for field in replace:
            for i in range(len(replace[field])):
                fdata = fdata.replace(f'{field}{i}', str(replace[field][i]))
        alphabet = string.ascii_lowercase + string.digits
        rname = ''.join(random.choices(alphabet, k=16))
        tmpdir = tempfile.gettempdir()
        template_filename = os.path.split(template)[-1]
        fname = os.path.join(tmpdir, f'{template_filename}.{rname}')
        with open(fname, 'w') as file:
            file.write(fdata)
        return fname

    def get_random_size(self, min_x, max_x, min_y, max_y, min_z, max_z):
        """Get random box size."""
        size = np.random.rand(3)
        size[0] = size[0] * (max_x - min_x) + min_x
        size[1] = size[1] * (max_y - min_y) + min_y
        size[2] = size[2] * (max_z - min_z) + min_z
        return tuple(size)

    def color_random_brown(self, obj):
        shade = np.random.rand() + 0.5
        color = np.float32([shade * 156, shade * 117, shade * 95, 255]) / 255
        p.changeVisualShape(obj, -1, rgbaColor=color)

  """""
  
  # Environment Class
  def add_object(self, urdf, pose, category='rigid'):
    """List of (fixed, rigid, or deformable) objects in env."""
    fixed_base = 1 if category == 'fixed' else 0
    obj_id = pybullet_utils.load_urdf(
        p,
        os.path.join(self.assets_root, urdf),
        pose[0],
        pose[1],
        useFixedBase=fixed_base)
    self.obj_ids[category].append(obj_id)
    return obj_id
"""

=========
Note that the objects need to obey physics and not collide with each other, and the object goal poses need to be above the table with lower bound x=0.25, y=-0.5 and upper bound x=0.75, y=0.5. When there are multiple objects for a multi-step pick-and-place task, there are often multiple subgoals. Once the task and environment are generated, an agent with a pick and place primitive will follow the defined goal to accomplish the tasks. 

Additionally, make sure you understand and summarize the ``self.goals`` variables, which has a list of 8-tuple with (objs, matches, targ_poses, replace, rotations, metric, params, step_max_reward, symmetries).
- objs (List of obj_id): object ID.
- matches (Binary Matrix): a binary matrix that denotes which object is matched with which target. This matrix has dimension len(objs) x len(targs).
- targ_poses (List of Poses [(translation, rotation)] ): a list of target poses of tuple (translation, rotation). 
- replace (Boolean): whether each object can match with one unique target. This is important if we have one target and multiple objects. If it's set to be false, then any object matching with the target will satisfy.
- rotations (Boolean): whether the placement action has a rotation degree of freedom. 
- metric (`pose` or `zone`): `pose` or `zone` that the object needs to be transported to. Example: `pose`. 
- params (List of (zone_target, zone_size)): a list of (zone_target, zone_size) for each zone if the metric is `zone`. 
- step_max_reward (float): the total reward of matching all the objects with all the target poses. It is not dependent on the number of objects but dependent on the number of goals. 
- symmetries: the radians that the object is symmetric around z axis.
- language_goal: the low-level language instructions that denote the goal of this step.
 


>>> Answer: 
Yes, I understand the provided APIs and their intended usage. Here's a summary of my understanding:

**Task Class:**

The `Task` class defines the base structure and logic for a manipulation task.  It handles reward calculation, task completion checks, oracle agent actions, and helper functions for environment interaction.

* **Initialization (`__init__`)**: Sets up default parameters like workspace bounds, evaluation epsilons, the pick-and-place primitive, and initializes empty goal lists.  Importantly, it requires the `assets_root` to be set later, which specifies the directory containing asset URDFs.

* **Reset (`reset`)**: Clears the goal lists and progress metrics, preparing for a new episode.  Crucially, it checks if `assets_root` has been set.

* **Oracle Agent (`oracle`)**: Provides an "expert" agent that uses ground truth information (perfect segmentation and depth) to demonstrate optimal actions.  It selects an object farthest from its matched target, calculates pick and place poses, and accounts for object symmetries and optional rotations.  If no pickable object is visible, it resets the goals.

* **Reward (`reward`)**: Calculates the reward for the current timestep based on the defined metric ('pose' or 'zone').  It compares object poses to target poses (for 'pose' metric) or calculates the intersection of object points with designated zones (for 'zone' metric).  It returns the delta reward (change in reward from the previous timestep) and an info dictionary.

* **Done (`done`)**: Checks if the task is complete (all goals achieved) or if the accumulated reward is close to the maximum possible reward.

* **Helper Functions**: Includes functions for checking pose similarity (`is_match`), generating random poses (`get_random_pose`), getting language goals (`get_lang_goal`), getting cumulative reward (`get_reward`), filling templates for URDF files (`fill_template`), generating random object sizes (`get_random_size`), and applying random brown coloring to objects (`color_random_brown`).  These functions assist in task setup and evaluation.

* **Environment Interaction**: The provided snippet from the Environment class shows how objects are added to the PyBullet simulation using the `add_object` method.  It specifies the URDF path, pose, and object category ('fixed', 'rigid', or 'deformable').


**Understanding `self.goals`:**

The `self.goals` variable is a list of 8-tuples, each representing a subgoal within the task.  Each tuple contains the following information:

1. **`objs`**: A list of object IDs involved in the current subgoal.  Each element is a tuple containing the object ID and a tuple of (symmetry, _) where symmetry is the rotational symmetry of the object around the z-axis in radians.

2. **`matches`**: A binary matrix indicating which objects should be matched with which target poses.  Rows correspond to objects, columns to targets. A value of 1 indicates a match.

3. **`targs`**: A list of target poses, each represented as a tuple of (position, orientation quaternion).

4. **`replace`**: A boolean flag. If `False`, each object can only be matched with one unique target.  If `True`, multiple objects can match the same target.

5. **`rotations`**: A boolean flag indicating whether the end-effector should be rotated during placement.

6. **`metric`**: A string specifying the reward metric ('pose' or 'zone').

7. **`params`**:  If `metric` is 'zone', this contains a list of tuples, each containing a zone pose (position, orientation quaternion) and zone size (x, y, z dimensions). If `metric` is 'pose', this is empty.

8. **`step_max_reward`**: The maximum reward achievable for completing the current subgoal.

9. **`symmetries`**: The rotational symmetry of the object around the z-axis in radians.

10. **`language_goal`**: The low-level language instruction describing the current subgoal. This is stored in `self.lang_goals` which is synchronized with `self.goals`.


**Key Considerations for "stack-balls-in-bowl" Task:**

* **Physics and Collision Avoidance**:  Objects must interact realistically within the physics engine and avoid collisions during manipulation.

* **Goal Pose Constraints**: Target poses for the balls must be within the specified workspace bounds and above the table.

* **Multi-Step Subgoals**: For stacking multiple balls, the `self.goals` list will contain multiple subgoals, each representing a single pick-and-place action.

* **Agent and Primitive**: The provided `PickPlace` primitive will be used by the agent to execute the pick-and-place actions according to the defined goals.


By understanding these APIs and considerations, I can now effectively write code for the "stack-balls-in-bowl" task.


================= Error Book Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-in-bowl". Here are some runtime errors that you do not want to make. Please confirm that you understand these runtime errors.

"""
- environment.py, line 338, in info
    pos, rot = p.getBasePositionAndOrientation(obj_id)
TypeError: an integer is required (got type NoneType)

- task.py, line 118, in act
    objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]
IndexError: list index out of range

- task.py, line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
TypeError: 'float' object is not subscriptable

- task.py", line 315, in is_match
  rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]

- utils.py", line 280, in quatXYZW_to_eulerXYZ
  quaternion_wxyz = np.array([q[3], q[0], q[1], q[2]])
IndexError: tuple index out of range

- pallet_pose = self.get_random_pose(env, pallet_size)
pallet_surface_height = pallet_pose[0][2]
TypeError: 'NoneType' object is not subscriptable

- No such file or directory: './cliport/environments/assets/circle/circle-template.urdf'

- No such file or directory: './cliport/environments/assets/block/block-template.urdf'

- task.py", line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
IndexError: invalid index to scalar variable.

-TypeError: get_random_size() missing 4 required positional arguments: 'min_y', 'max_y', 'min_z', and 'max_z' 

- task.py", line 195, in reward
    obj_pts, zones = params
TypeError: cannot unpack non-iterable NoneType object

-  environment.py", line 230, in step
    reward, info = self.task.reward() if action is not None else (0, {})
  File "task.py", line 200, in reward
    pts = obj_pts[obj_id]
IndexError: arrays used as indices must be of integer (or boolean) type

- generated_task.py", line 41, in reset
    utils.COLORS['green'], utils.COLORS['blue'], utils.COLORS['light blue'],
KeyError: 'light blue'

- environment.py", line 195, in reset
    self.task.reset(self)
  File "<string>", line 38, in reset
TypeError: can only concatenate str (not "list") to str

- environment.py", line 195, in reset
  object_shape = np.random.choice(object_shapes)
  in numpy.random.mtrand.RandomState.choice
ValueError: a must be 1-dimensional

- No such file or directory: 'assets/box-template/box-template.urdf'

- line 38, in reset.py
{'HALF': box_size / 2}
TypeError: unsupported operand type(s) for /: 'tuple' and 'int'. box_size is a tuple not a float.

- line 38, in reset.py
IndexError: tuple index out of range
box_pose = (pallet_pose[0], pallet_pose[1], pallet_pose[2] + np.sum(box_sizes[:i+1]))

- task.py", line 338, in fill_template
    for i in range(len(replace[field])):
TypeError: object of type 'float' has no len().

- task.py", line 325, in get_random_pose
    pos = (pos[0], pos[1], obj_size[2] / 2)
IndexError: tuple index out of range

- task.py", line 206, in reward
    for zone_idx, (zone_pose, zone_size) in enumerate(zones):
TypeError: 'NoneType' object is not iterable

- task.py",
ball_pose = self.get_random_pose(env, ball_size)
ball_pose[0][2] += 0.02
TypeError: 'tuple' object does not support item assignment
"""


You do not want to make mistakes such as
- using assets (urdfs) that do not exist
- use ambiguous language descriptions as goals. For instance, "place the colored blocks into the matching colored bowls" with one goal and sparse reward as the task instead of adding subgoal "place blue block into blue bowl" and give continuous reward. 
- `matches` in the goal has wrong dimensions. It should have the same dimensions as number of objects (N) multiplied by the number of goal poses (M). Usually it is N by M.
- have vector dimension problem such as `np.random.choice(box_size)` or `box_size / 2` where `box_size` is a tuple and not an int
- make too large an object for stacking or make the task objects invisible for picking. 
- accessing index out of bound `pallet_pose[2]` for `pallet_pose`.  `pallet_pose=get_random_pose` returns a tuple (translation, rotation). It does not have 3rd component. Similarly accessing `container_pose[2]` or `box_pose[2]` would cause errors as well. Since it's a tuple, try to modify it in-place will also trigger errors.
- forget to replace str using `fill_template()` for urdfs with template such as `cylinder-template.urdf`. `ball-template.urdf`, `line-template.urf`. 
- use `self.ee = Spatula()` as a function when doing pushing tasks, which is incorrect. It should be `self.ee = Spatula`.
- forget to compute target poses `targ_poses` for matching. Do not use object IDs for poses.
- change colors of complex objects such as `zone`. You can only change color of teomplate primitive such as `cylinder-template`.
- mistakenly use `random_pose` for target pose. Design target poses based on task objectives.
- add only one or fewer language goals which causes language-motion inconsistentcy. Note that the language goals usually are the same number as the pick and place goals.


>>> Answer: 
Yes, I understand the runtime errors listed and the additional points you've made about avoiding mistakes in task generation. I will keep these in mind when writing the code for the "stack-balls-in-bowl" task.  I will pay particular attention to:

* **File Paths and Existence:** Verify that all URDF files exist in the correct locations.
* **Clear Language Goals:**  Provide specific and unambiguous language descriptions for each subgoal, avoiding vague phrasing.
* **`matches` Dimensions:** Ensure the `matches` array has the correct dimensions (N x M), reflecting the relationship between objects and target poses.
* **Vector Operations:** Handle vector and scalar operations correctly, avoiding operations like division or random choice on tuples.  I will unpack tuples into individual components when necessary.
* **Object Sizes and Visibility:**  Keep object sizes reasonable for stacking and ensure they are visible for manipulation.
* **Pose Tuple Access:** Access pose tuples (translation, rotation) correctly, using indices 0 and 1 for translation and rotation, respectively. Avoid trying to modify tuples in place.
* **Template Filling:** Use `fill_template()` to replace placeholders in URDF files with specific values.
* **Spatula Initialization:** Initialize the spatula correctly using `self.ee = Spatula`, not as a function call.
* **Target Pose Calculation:** Explicitly calculate target poses (`targ_poses`) based on task requirements, not object IDs.
* **Color Changes:** Only change colors of primitive template objects, not complex objects like zones.
* **Random vs. Designed Poses:** Use `random_pose` appropriately and design target poses based on the task's objectives.
* **Sufficient Language Goals:** Provide enough language goals to match the number of pick-and-place actions, ensuring language-motion consistency.


By addressing these points, I aim to avoid the listed runtime errors and create a robust and functional "stack-balls-in-bowl" task.


================= Code Generation!

>>> Prompt: 
Now I will provide you some reference code and you can write the code for the task "stack-balls-in-bowl".


"""
import os

import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils


class PackingShapes(Task):
    """pick up randomly sized shapes and place them tightly into a container."""

    def __init__(self):
        super().__init__()
        self.max_steps = 1
        self.homogeneous = False

        self.lang_template = "pack the {obj} in the brown box"
        self.task_completed_desc = "done packing shapes."
        self.additional_reset()


    def reset(self, env):
        super().reset(env)

        # Shape Names:
        shapes = utils.assembling_kit_shapes

        n_objects = 5
        if self.mode == 'train':
            obj_shapes = np.random.choice(self.train_set, n_objects, replace=False)
        else:
            if self.homogeneous:
                obj_shapes = [np.random.choice(self.test_set, replace=False)] * n_objects
            else:
                obj_shapes = np.random.choice(self.test_set, n_objects, replace=False)

        # Shuffle colors to avoid always picking an object of the same color
        colors, color_names = utils.get_colors(mode=self.mode)

        # Add container box.
        zone_size = self.get_random_size(0.1, 0.15, 0.1, 0.15, 0.05, 0.05)
        zone_pose = self.get_random_pose(env, zone_size)
        container_template = 'container/container-template.urdf'
        replace = {'DIM': zone_size, 'HALF': (zone_size[0] / 2, zone_size[1] / 2, zone_size[2] / 2)}
        # IMPORTANT: REPLACE THE TEMPLATE URDF with `fill_template`
        container_urdf = self.fill_template(container_template, replace)
        env.add_object(container_urdf, zone_pose, 'fixed')

        # Add objects.
        objects = []
        template = 'kitting/object-template.urdf'
        for i in range(n_objects):
            shape = obj_shapes[i]

            # x, y, z dimensions for the asset size
            size = (0.08, 0.08, 0.02)
            pose= self.get_random_pose(env, size)
            fname = f'{shape:02d}.obj'
            fname = os.path.join(self.assets_root, 'kitting', fname)
            scale = [0.003, 0.003, 0.001]  # .0005
            replace = {'FNAME': (fname,),
                       'SCALE': scale,
                       'COLOR': colors[i]}

            # IMPORTANT: REPLACE THE TEMPLATE URDF
            urdf = self.fill_template(template, replace)
            block_id = env.add_object(urdf, pose)
            objects.append(block_id)

        # Pick the first shape.
        num_objects_to_pick = 1
        for i in range(num_objects_to_pick):
            # IMPORTANT: Specify (obj_pts, [(zone_pose, zone_size)]) for target `zone`. obj_pts is a dict
            language_goal = self.lang_template.format(obj=shapes[obj_shapes[i]])
            self.add_goal(objs=[objects[i]], matches=np.int32([[1]]), targ_poses=[zone_pose], replace=False,
                rotations=True, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1 / num_objects_to_pick,
                language_goal=language_goal)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p


class PlaceRedInGreen(Task):
    """pick up the red blocks and place them into the green bowls amidst other objects."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "put the red blocks in a green bowl"
        self.task_completed_desc = "done placing blocks in bowls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)
        n_bowls = np.random.randint(1, 4)
        n_blocks = np.random.randint(1, n_bowls + 1)

        # Add bowls.
        # x, y, z dimensions for the asset size
        bowl_size = (0.12, 0.12, 0)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_poses = []
        for _ in range(n_bowls):
            bowl_pose = self.get_random_pose(env, obj_size=bowl_size)
            env.add_object(urdf=bowl_urdf, pose=bowl_pose, category='fixed')
            bowl_poses.append(bowl_pose)

        # Add blocks.
        # x, y, z dimensions for the asset size
        blocks = []
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'
        for _ in range(n_blocks):
            block_pose = self.get_random_pose(env, obj_size=block_size)
            block_id = env.add_object(block_urdf, block_pose)
            blocks.append(block_id)

        # Goal: each red block is in a different green bowl.
        self.add_goal(objs=blocks, matches=np.ones((len(blocks), len(bowl_poses))), targ_poses=bowl_poses, replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1, language_goal=self.lang_template)

        # Colors of distractor objects.
        bowl_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'green']
        block_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'red']

        # Add distractors.
        n_distractors = 0
        while n_distractors < 6:
            is_block = np.random.rand() > 0.5
            urdf = block_urdf if is_block else bowl_urdf
            size = block_size if is_block else bowl_size
            colors = block_colors if is_block else bowl_colors
            pose = self.get_random_pose(env, obj_size=size)
            color = colors[n_distractors % len(colors)]

            obj_id = env.add_object(urdf, pose, color=color)
            n_distractors += 1
"""
"""
import numpy as np
from cliport.tasks import primitives
from cliport.tasks.grippers import Spatula
from cliport.tasks.task import Task
from cliport.utils import utils


class SweepingPiles(Task):
    """Push piles of small objects into a target goal zone marked on the tabletop."""

    def __init__(self):
        super().__init__()
        self.max_steps = 20
        self.lang_template = "push the pile of blocks into the green square"
        self.task_completed_desc = "done sweeping."
        self.primitive = primitives.push
        self.ee = Spatula
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add goal zone.
        zone_size = (0.12, 0.12, 0)
        zone_pose = self.get_random_pose(env, zone_size)
        env.add_object('zone/zone.urdf', zone_pose, 'fixed')

        # Add pile of small blocks with `make_piles` function
        obj_ids = self.make_piles(env)

        # Add goal
        self.add_goal(objs=obj_ids, matches=np.ones((50, 1)), targ_poses=[zone_pose], replace=True,
                rotations=False, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1, language_goal=self.lang_template)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p

class StackBlockPyramid(Task):
    """Build a pyramid of colored blocks in a color sequence"""

    def __init__(self):
        super().__init__()
        self.max_steps = 12
        self.lang_template = "make the {row} row with {blocks}"
        self.task_completed_desc = "done stacking block pyramid."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add base.
        base_size = (0.05, 0.15, 0.005)
        base_urdf = 'stacking/stand.urdf'
        base_pose = self.get_random_pose(env, base_size)
        env.add_object(base_urdf, base_pose, category='fixed')

        # Block colors.
        colors = [
            utils.COLORS['purple'], utils.COLORS['blue'], utils.COLORS['green'],
            utils.COLORS['yellow'], utils.COLORS['orange'], utils.COLORS['red']
        ]

        # Add blocks.
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'

        objs = []
        for i in range(6):
            block_pose = self.get_random_pose(env, block_size)
            block_id = env.add_object(block_urdf, block_pose, color=colors[i])
            objs.append(block_id)

        # IMPORTANT Associate placement locations for goals.
        place_pos = [(0, -0.05, 0.03), (0, 0, 0.03),
                     (0, 0.05, 0.03), (0, -0.025, 0.08),
                     (0, 0.025, 0.08), (0, 0, 0.13)]
        targs = [(utils.apply(base_pose, i), base_pose[1]) for i in place_pos]

        # Goal: blocks are stacked in a pyramid (bottom row: green, blue, purple).
        language_goal = self.lang_template.format(blocks="the green, blue and purple blocks", row="bottom")
        self.add_goal(objs=objs[:3], matches=np.ones((3, 3)), targ_poses=targs[:3], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 2, symmetries=[np.pi/2]*3, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (middle row: yellow, orange).
        language_goal = self.lang_template.format(blocks="the yellow and orange blocks", row="middle")      
        self.add_goal(objs=objs[3:5], matches=np.ones((2, 2)), targ_poses=targs[3:5], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 3, symmetries=[np.pi/2]*2, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (top row: red).
        language_goal = self.lang_template.format(blocks="the red block", row="top")
        self.add_goal(objs=objs[5:], matches=np.ones((1, 1)), targ_poses=targs[5:], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 6, symmetries=[np.pi/2]*1, language_goal=language_goal)
"""



Do not use libraries, functions, and assets that you don't know. For each object, try to describe its color, size, category in the task first before you write the code. You do not need extra helper functions. Comment the code liberally to explain what each piece does and why it's written that way. If you have only one goal, `step_max_reward` in `add_goal` should be 1. Use functions `make_piles` and `make_ropes` for creating piles and cables. To use spatula together with the push primitives, import the libraries 
"""
from cliport.tasks import primitives;
from cliport.tasks.grippers import Spatula
"""
and then use `self.primitive = primitives.push` and `self.ee = Spatula`.
Note that the number of language goals usually match the number of motion goals, since they should correspond to each other.

Now write the code for the task "stack-balls-in-bowl" in python code block starting with ```python.  Reminder: {'task-name': 'stack-balls-in-bowl', 'task-description': 'Pick up three different colored balls (red, green, and blue) and stack them inside a yellow bowl.', 'assets-used': ['ball/ball-template.urdf', 'bowl/bowl.urdf']} 


>>> Answer: 
```python
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils

class StackBallsInBowl(Task):
    """Pick up three different colored balls (red, green, and blue) and stack them inside a yellow bowl."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10  # Set maximum steps for task completion
        self.lang_template = "stack the red, green, and blue balls in the yellow bowl"  # Language goal template
        self.task_completed_desc = "done stacking balls in bowl."  # Description for task completion
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Bowl
        # - Yellow color
        # - Size: (0.12, 0.12, 0)
        # - Category: fixed (cannot be moved by the robot)
        bowl_size = (0.12, 0.12, 0)
        bowl_pose = self.get_random_pose(env, bowl_size)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_id = env.add_object(bowl_urdf, bowl_pose, 'fixed', color=utils.COLORS['yellow'])

        # Balls
        # - Colors: red, green, blue
        # - Size: (0.04, 0.04, 0.04)
        # - Category: object (can be manipulated)
        ball_size = (0.04, 0.04, 0.04)
        ball_urdf = 'ball/ball-template.urdf'
        ball_colors = ['red', 'green', 'blue']
        ball_ids = []

        for color in ball_colors:
            ball_pose = self.get_random_pose(env, ball_size)
            ball_id = env.add_object(ball_urdf, ball_pose, color=utils.COLORS[color])
            ball_ids.append(ball_id)

        # Goal: stack balls in the bowl
        # - objs: list of ball IDs
        # - matches: a matrix indicating which balls should be in the bowl (all of them)
        # - targ_poses: the pose of the bowl
        # - replace: False (balls should not replace each other)
        # - rotations: True (orientation of balls matters)
        # - metric: pose (balls should be close to the bowl's pose)
        # - params: None (no additional parameters needed)
        # - step_max_reward: 1 (single goal)
        # - language_goal: the language description of the goal
        self.add_goal(objs=ball_ids, matches=np.ones((3, 1)), targ_poses=[bowl_pose], replace=False,
                      rotations=True, metric='pose', params=None, step_max_reward=1,
                      language_goal=self.lang_template)
```

================= TRIAL: 3

================= TRIAL: 3

================= TRIAL: 3

================= TRIAL: 3

================= Task and Asset Design!

>>> Prompt: 
You are an AI in robot simulation code and task design. I will provide you some example tasks, code implementation, and some guidelines for how to generate tasks and then you will help me generate a new task. My goal is to design diverse and feasible tasks for tabletop manipulation. I will first ask you to describe the task in natural languages and then will let you write the code for it. 

=========
Here are all the assets. Use only these assets in the task and code design. 
"""
insertion/:
ell.urdf  fixture.urdf

bowl/:
bowl.urdf

box/:
box-template.urdf

stacking/:
block.urdf  stand.urdf

zone/:
zone.obj  zone.urdf

pallet/:
pallet.obj  pallet.urdf

ball/:
ball-template.urdf

cylinder/:
cylinder-template.urdf

bowl/:
bowl.urdf

# assets not for picking
corner/:
corner-template.urdf

line/:
single-green-line-template.urdf

container/:
container-template.urdf
"""
 
=========
Here are some examples of good tasks. Try to learn from these structures but avoid overlapping wiht them.

{"assets-used": ["zone/zone.urdf", "block/small.urdf"],
 "task-description": "Push piles of small objects into a target goal zone marked on the tabletop.",
 "task-name": "sweeping-piles"}

{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "Place all blocks of a specified color in a bowl of specified color.",
 "task-name": "put-block-in-bowl"}
 
{"assets-used": ["insertion/ell.urdf", "insertion/fixture.urdf"],
 "task-description": "pick up the L-shaped red block and place it into the L-shaped fixture.",
 "task-name": "block-insertion"}
 
{"assets-used": ["kitting/kit.urdf", "kitting/object-template.urdf"],
 "task-description": "pick up different objects and arrange them on a board marked with corresponding silhouettes.",
 "task-name": "assembling-kits"}
 
{"assets-used": ["pallet/pallet.urdf", "box/box-template.urdf"],
 "task-description": "pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.",
 "task-name": "palletizing-boxes"}
 
{"assets-used": ["stacking/stand.urdf", "stacking/block.urdf"],
 "task-description": "sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.",
 "task-name": "stack-block-pyramid"}
 
{"assets-used": ["container/container-template.urdf", "box/box-template.urdf"],
 "task-description": "pick up randomly sized boxes and place them tightly into a container.",
 "task-name": "packing-boxes"}
 
{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "pick up the red blocks and place them into the green bowls amidst other objects.",
 "task-name": "place-red-in-green"}
 
{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

=========
Here are some tasks that you have come up with before. Try to learn from these structures but avoid overlapping with these tasks. For instance, `bowl_ball_placement` and `sort_balls_in_bowls` are the same task. `pile_boxes_in_corner` and `stack_blocks_into_pallet` are similar tasks, `align-cylinder-in-corner` and `align-cylinder-corner` are similar.
- sweeping-piles: {'assets-used': ['zone/zone.urdf', 'block/small.urdf'], 'task-description': 'push piles of small objects into a target goal zone marked on the tabletop.', 'task-name': 'sweeping-piles'}
- place-red-in-green: {'assets-used': ['bowl/bowl.urdf', 'stacking/block.urdf'], 'task-description': 'pick up the red blocks and place them into the green bowls amidst other objects.', 'task-name': 'place-red-in-green'}
- align-box-corner: {'assets-used': ['box/box-template.urdf', 'corner/corner-template.urdf'], 'task-description': 'pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..', 'task-name': 'align-box-corner'}
- stack-block-pyramid: {'assets-used': ['stacking/stand.urdf', 'stacking/block.urdf'], 'task-description': 'sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.', 'task-name': 'stack-block-pyramid'}
- palletizing-boxes: {'assets-used': ['pallet/pallet.urdf', 'box/box-template.urdf'], 'task-description': 'pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.', 'task-name': 'palletizing-boxes'}
- assembling-kits: {'assets-used': ['kitting/kit.urdf', 'kitting/object-template.urdf'], 'task-description': 'pick up different objects and arrange them on a board marked with corresponding silhouettes.', 'task-name': 'assembling-kits'}
- packing-boxes: {'assets-used': ['container/container-template.urdf', 'box/box-template.urdf'], 'task-description': 'pick up randomly sized boxes and place them tightly into a container.', 'task-name': 'packing-boxes'}
- manipulating-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'rearrange a deformable rope such that it connects the two endpoints of a 3-sided square.', 'task-name': 'manipulating-rope'}
- align-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'manipulate a deformable rope to connect its end-points between two corners of a 3-sided square.', 'task-name': 'align-rope'}





=========
Here are some bad example task instances with explanations.
{
    "task_name": "sort-color-blocks",
    "task_descriptions": "Pick up differently colored blocks and place them into separate bowls of matching color."
    "assets-used": ["bowl.urdf", "box/box-template.urdf],
}
reasons: not interesting because it overlaps with the current task `put-block-in-bowl`.

{
    "task-name": "guided-ball-maze",
    "task-description": "Navigate a small ball through a maze by tilting the maze board to reach the target zone.",
    "assets-used": ["zone-template.urdf", "square-template.urdf", "ball.urdf", "maze.urdf"],
}
reasons: the language descriptions are too ambiguous. Navigation is also hard to complete. Also maze.urf does not exist.

{
    "task-name": "insert_cylinder_in_sphere",
    "task-description": "Pick up the cylinder and insert it into the sphere with an opening on top.",
    "assets-used": ["cylinder/cylinder-template.urdf", "sphere/sphere-template.urdf"],
}
reasons: this task does not make sense. The sphere does not have an opening on top, and you cannot insert a cylinder into a sphere. Similarly tasks like `insert-ball-into-cylinder` and `cylinder-box-insertion` are invalid.

{
    "task-name": "ball-box-obstacle-course",
    "task-description": "Navigate a ball through an obstacle course created by randomly placed boxes and finally place it inside a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: Navigate the ball is not related to tabletop manipulation tasks.

{
    "task-name": "ball-in-box",
    "task-description": "Use a cable to guide a ball into an open box.",
    "assets-used": ["cable/cable.urdf", "ball/ball-template.urdf", "box/box-template.urdf"]
}
reasons: This task is too hard since it involves interaction of the cable and the ball and cannot be easily completed.

{
    "task-name": "ball-in-container",
    "task-description": "Use the spatula to lift a ball over a wall of boxes and drop it into a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: The only action primitives as pick and place. One cannot use a spatula to lift an object.

{
    "task-name": "line-ball-sorting",
    "task-description": "Move balls of different colors along a single green line, placing each ball in a designated colored box at the end of the line. The challenge includes precision in maintaining the ball on the line and the correct identification of the box color corresponding to each ball.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "line/single-green-line-template.urdf"]
}
reasons: Piling or stacking balls are physically infeasible in the simulation.



=========
Now please describe the new task in natural languages and explain its novelty and challenges. Format the answer in a python dictionary with keys "task-name" and value type string, "task-description" (one specific sentence) and value type string, and "assets-used" and value type list of strings. Note that

- Do not use assets that are not in the list above. 
- Tasks that have more colors and shapes are interesting.
- Be as specific as possible about the number, shape, and color of each asset in the task descriptions. 
- The task need to obey physics and remain feasible.





>>> Answer: 
```python
{
    "task-name": "stack-balls-on-cylinder",
    "task-description": "Stack three differently colored balls (red, green, and blue) vertically on top of a large upright cylinder.",
    "assets-used": ["ball/ball-template.urdf", "cylinder/cylinder-template.urdf"]
}
```

**Novelty and Challenges:**

This task introduces the challenge of stacking rounded objects, which is inherently less stable than stacking blocks.  The cylindrical base further increases the instability, requiring precise placement and control from the robot.  While simple in concept, the task requires a good understanding of physics and control to achieve a stable stack.  It differs from previous examples by focusing on the delicate balance required for ball stacking and the added complexity of the cylindrical base.  It also introduces color as a minor element (though not functionally necessary), potentially opening avenues for more complex color-based tasks in the future.


================= API Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-on-cylinder". Here are some APIs that are defined. Please confirm that you understand these APIs.

"""
class Task():
    """Base Task class."""

    def __init__(self):
        self.ee = Suction
        self.mode = 'train'
        self.sixdof = False
        self.primitive = primitives.PickPlace()
        self.oracle_cams = cameras.Oracle.CONFIG

        # Evaluation epsilons (for pose evaluation metric).
        self.pos_eps = 0.01
        self.rot_eps = np.deg2rad(15)

        # Workspace bounds.
        self.pix_size = 0.003125
        self.bounds = np.array([[0.25, 0.75], [-0.5, 0.5], [0, 0.3]])
        self.zone_bounds = np.copy(self.bounds)

        self.goals = []
        self.lang_goals = []
        self.task_completed_desc = "task completed."
        self.progress = 0
        self._rewards = 0
        self.assets_root = None

    def reset(self, env):
        if not self.assets_root:
            raise ValueError('assets_root must be set for task, '
                             'call set_assets_root().')
        self.goals = []
        self.lang_goals = []
        self.progress = 0  # Task progression metric in range [0, 1].
        self._rewards = 0  # Cumulative returned rewards.

    # -------------------------------------------------------------------------
    # Oracle Agent
    # -------------------------------------------------------------------------

    def oracle(self, env):
        """Oracle agent."""
        OracleAgent = collections.namedtuple('OracleAgent', ['act'])

        def act(obs, info):
            """Calculate action."""

            # Oracle uses perfect RGB-D orthographic images and segmentation masks.
            _, hmap, obj_mask = self.get_true_image(env)

            # Unpack next goal step.
            objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]

            # Match objects to targets without replacement.
            if not replace:

                # Modify a copy of the match matrix.
                matches = matches.copy()

                # Ignore already matched objects.
                for i in range(len(objs)):
                    object_id, (symmetry, _) = objs[i]
                    pose = p.getBasePositionAndOrientation(object_id)
                    targets_i = np.argwhere(matches[i, :]).reshape(-1)
                    for j in targets_i:
                        if self.is_match(pose, targs[j], symmetry):
                            matches[i, :] = 0
                            matches[:, j] = 0

            # Get objects to be picked (prioritize farthest from nearest neighbor).
            nn_dists = []
            nn_targets = []
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                xyz, _ = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                if len(targets_i) > 0:
                    targets_xyz = np.float32([targs[j][0] for j in targets_i])
                    dists = np.linalg.norm(
                        targets_xyz - np.float32(xyz).reshape(1, 3), axis=1)
                    nn = np.argmin(dists)
                    nn_dists.append(dists[nn])
                    nn_targets.append(targets_i[nn])

                # Handle ignored objects.
                else:
                    nn_dists.append(0)
                    nn_targets.append(-1)
            order = np.argsort(nn_dists)[::-1]

            # Filter out matched objects.
            order = [i for i in order if nn_dists[i] > 0]

            pick_mask = None
            for pick_i in order:
                pick_mask = np.uint8(obj_mask == objs[pick_i][0])

                # Erode to avoid picking on edges.
                # pick_mask = cv2.erode(pick_mask, np.ones((3, 3), np.uint8))

                if np.sum(pick_mask) > 0:
                    break

            # Trigger task reset if no object is visible.
            if pick_mask is None or np.sum(pick_mask) == 0:
                self.goals = []
                self.lang_goals = []
                print('Object for pick is not visible. Skipping demonstration.')
                return

            # Get picking pose.
            pick_prob = np.float32(pick_mask)
            pick_pix = utils.sample_distribution(pick_prob)
            # For "deterministic" demonstrations on insertion-easy, use this:
            # pick_pix = (160,80)
            pick_pos = utils.pix_to_xyz(pick_pix, hmap,
                                        self.bounds, self.pix_size)
            pick_pose = (np.asarray(pick_pos), np.asarray((0, 0, 0, 1)))

            # Get placing pose.
            targ_pose = targs[nn_targets[pick_i]]
            obj_pose = p.getBasePositionAndOrientation(objs[pick_i][0])
            if not self.sixdof:
                obj_euler = utils.quatXYZW_to_eulerXYZ(obj_pose[1])
                obj_quat = utils.eulerXYZ_to_quatXYZW((0, 0, obj_euler[2]))
                obj_pose = (obj_pose[0], obj_quat)
            world_to_pick = utils.invert(pick_pose)
            obj_to_pick = utils.multiply(world_to_pick, obj_pose)
            pick_to_obj = utils.invert(obj_to_pick)
            place_pose = utils.multiply(targ_pose, pick_to_obj)

            # Rotate end effector?
            if not rotations:
                place_pose = (place_pose[0], (0, 0, 0, 1))

            place_pose = (np.asarray(place_pose[0]), np.asarray(place_pose[1]))

            return {'pose0': pick_pose, 'pose1': place_pose}

        return OracleAgent(act)

    # -------------------------------------------------------------------------
    # Reward Function and Task Completion Metrics
    # -------------------------------------------------------------------------

    def reward(self):
        """Get delta rewards for current timestep.

        Returns:
          A tuple consisting of the scalar (delta) reward, plus `extras`
            dict which has extra task-dependent info from the process of
            computing rewards that gives us finer-grained details. Use
            `extras` for further data analysis.
        """
        reward, info = 0, {}

        # Unpack next goal step.
        objs, matches, targs, _, _, metric, params, max_reward = self.goals[0]

        # Evaluate by matching object poses.
        if metric == 'pose':
            step_reward = 0
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                pose = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                for j in targets_i:
                    target_pose = targs[j]
                    if self.is_match(pose, target_pose, symmetry):
                        step_reward += max_reward / len(objs)
                        print(f"object {i} match with target {j} rew: {step_reward}")
                        break

        # Evaluate by measuring object intersection with zone.
        elif metric == 'zone':
            zone_pts, total_pts = 0, 0
            obj_pts, zones = params
            for zone_idx, (zone_pose, zone_size) in enumerate(zones):

                # Count valid points in zone.
                for obj_idx, obj_id in enumerate(obj_pts):
                    pts = obj_pts[obj_id]
                    obj_pose = p.getBasePositionAndOrientation(obj_id)
                    world_to_zone = utils.invert(zone_pose)
                    obj_to_zone = utils.multiply(world_to_zone, obj_pose)
                    pts = np.float32(utils.apply(obj_to_zone, pts))
                    if len(zone_size) > 1:
                        valid_pts = np.logical_and.reduce([
                            pts[0, :] > -zone_size[0] / 2, pts[0, :] < zone_size[0] / 2,
                            pts[1, :] > -zone_size[1] / 2, pts[1, :] < zone_size[1] / 2,
                            pts[2, :] < self.zone_bounds[2, 1]])

                    # if zone_idx == matches[obj_idx].argmax():
                    zone_pts += np.sum(np.float32(valid_pts))
                    total_pts += pts.shape[1]
            step_reward = max_reward * (zone_pts / total_pts)

        # Get cumulative rewards and return delta.
        reward = self.progress + step_reward - self._rewards
        self._rewards = self.progress + step_reward

        # Move to next goal step if current goal step is complete.
        if np.abs(max_reward - step_reward) < 0.01:
            self.progress += max_reward  # Update task progress.
            self.goals.pop(0)
            if len(self.lang_goals) > 0:
                self.lang_goals.pop(0)

        return reward, info

    def done(self):
        """Check if the task is done or has failed.

        Returns:
          True if the episode should be considered a success, which we
            use for measuring successes, which is particularly helpful for tasks
            where one may get successes on the very last time step, e.g., getting
            the cloth coverage threshold on the last alllowed action.
            However, for bag-items-easy and bag-items-hard (which use the
            'bag-items' metric), it may be necessary to filter out demos that did
            not attain sufficiently high reward in external code. Currently, this
            is done in `main.py` and its ignore_this_demo() method.
        """
        return (len(self.goals) == 0) or (self._rewards > 0.99)
        # return zone_done or defs_done or goal_done

    # -------------------------------------------------------------------------
    # Environment Helper Functions
    # -------------------------------------------------------------------------

    def is_match(self, pose0, pose1, symmetry):
        """Check if pose0 and pose1 match within a threshold."""

        # Get translational error.
        diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
        dist_pos = np.linalg.norm(diff_pos)

        # Get rotational error around z-axis (account for symmetries).
        diff_rot = 0
        if symmetry > 0:
            rot0 = np.array(utils.quatXYZW_to_eulerXYZ(pose0[1]))[2]
            rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]
            diff_rot = np.abs(rot0 - rot1) % symmetry
            if diff_rot > (symmetry / 2):
                diff_rot = symmetry - diff_rot

        return (dist_pos < self.pos_eps) and (diff_rot < self.rot_eps)

    def get_random_pose(self, env, obj_size):
        """Get random collision-free object pose within workspace bounds."""

        # Get erosion size of object in pixels.
        max_size = np.sqrt(obj_size[0] ** 2 + obj_size[1] ** 2)
        erode_size = int(np.round(max_size / self.pix_size))

        _, hmap, obj_mask = self.get_true_image(env)

        # Randomly sample an object pose within free-space pixels.
        free = np.ones(obj_mask.shape, dtype=np.uint8)
        for obj_ids in env.obj_ids.values():
            for obj_id in obj_ids:
                free[obj_mask == obj_id] = 0
        free[0, :], free[:, 0], free[-1, :], free[:, -1] = 0, 0, 0, 0
        free = cv2.erode(free, np.ones((erode_size, erode_size), np.uint8))

        # if np.sum(free) == 0:
        #     return None, None

        if np.sum(free) == 0:
            # avoid returning None, None
            # return None, None
            pix = (obj_mask.shape[0] // 2, obj_mask.shape[1] // 2)
        else:
            pix = utils.sample_distribution(np.float32(free))
        pos = utils.pix_to_xyz(pix, hmap, self.bounds, self.pix_size)
        pos = (pos[0], pos[1], obj_size[2] / 2)
        theta = np.random.rand() * 2 * np.pi
        rot = utils.eulerXYZ_to_quatXYZW((0, 0, theta))
        return pos, rot

    def get_lang_goal(self):
        if len(self.lang_goals) == 0:
            return self.task_completed_desc
        else:
            return self.lang_goals[0]

    def get_reward(self):
        return float(self._rewards)

    # -------------------------------------------------------------------------
    # Helper Functions
    # -------------------------------------------------------------------------

    def fill_template(self, template, replace):
        """Read a file and replace key strings."""
        full_template_path = os.path.join(self.assets_root, template)
        with open(full_template_path, 'r') as file:
            fdata = file.read()
        for field in replace:
            for i in range(len(replace[field])):
                fdata = fdata.replace(f'{field}{i}', str(replace[field][i]))
        alphabet = string.ascii_lowercase + string.digits
        rname = ''.join(random.choices(alphabet, k=16))
        tmpdir = tempfile.gettempdir()
        template_filename = os.path.split(template)[-1]
        fname = os.path.join(tmpdir, f'{template_filename}.{rname}')
        with open(fname, 'w') as file:
            file.write(fdata)
        return fname

    def get_random_size(self, min_x, max_x, min_y, max_y, min_z, max_z):
        """Get random box size."""
        size = np.random.rand(3)
        size[0] = size[0] * (max_x - min_x) + min_x
        size[1] = size[1] * (max_y - min_y) + min_y
        size[2] = size[2] * (max_z - min_z) + min_z
        return tuple(size)

    def color_random_brown(self, obj):
        shade = np.random.rand() + 0.5
        color = np.float32([shade * 156, shade * 117, shade * 95, 255]) / 255
        p.changeVisualShape(obj, -1, rgbaColor=color)

  """""
  
  # Environment Class
  def add_object(self, urdf, pose, category='rigid'):
    """List of (fixed, rigid, or deformable) objects in env."""
    fixed_base = 1 if category == 'fixed' else 0
    obj_id = pybullet_utils.load_urdf(
        p,
        os.path.join(self.assets_root, urdf),
        pose[0],
        pose[1],
        useFixedBase=fixed_base)
    self.obj_ids[category].append(obj_id)
    return obj_id
"""

=========
Note that the objects need to obey physics and not collide with each other, and the object goal poses need to be above the table with lower bound x=0.25, y=-0.5 and upper bound x=0.75, y=0.5. When there are multiple objects for a multi-step pick-and-place task, there are often multiple subgoals. Once the task and environment are generated, an agent with a pick and place primitive will follow the defined goal to accomplish the tasks. 

Additionally, make sure you understand and summarize the ``self.goals`` variables, which has a list of 8-tuple with (objs, matches, targ_poses, replace, rotations, metric, params, step_max_reward, symmetries).
- objs (List of obj_id): object ID.
- matches (Binary Matrix): a binary matrix that denotes which object is matched with which target. This matrix has dimension len(objs) x len(targs).
- targ_poses (List of Poses [(translation, rotation)] ): a list of target poses of tuple (translation, rotation). 
- replace (Boolean): whether each object can match with one unique target. This is important if we have one target and multiple objects. If it's set to be false, then any object matching with the target will satisfy.
- rotations (Boolean): whether the placement action has a rotation degree of freedom. 
- metric (`pose` or `zone`): `pose` or `zone` that the object needs to be transported to. Example: `pose`. 
- params (List of (zone_target, zone_size)): a list of (zone_target, zone_size) for each zone if the metric is `zone`. 
- step_max_reward (float): the total reward of matching all the objects with all the target poses. It is not dependent on the number of objects but dependent on the number of goals. 
- symmetries: the radians that the object is symmetric around z axis.
- language_goal: the low-level language instructions that denote the goal of this step.
 


>>> Answer: 
Yes, I understand the provided APIs and their intended usage. Here's a summary of my understanding:

**Task Class:**

The `Task` class defines the base structure for a manipulation task, providing methods for resetting the environment, calculating rewards, checking for task completion, and generating oracle actions.  It also includes helper functions for pose manipulation, collision checking, and template filling.

**Key Components and Understanding:**

* **Environment Interaction:** The `Task` class interacts with a physics simulator (likely PyBullet, based on the `p` alias and usage of functions like `p.getBasePositionAndOrientation`). It manages the addition of objects (`add_object`) and tracks their IDs (`self.obj_ids`).

* **Goal Representation (`self.goals`):** This is the core of the task definition. Each element in `self.goals` represents a sub-goal within the overall task.  The 8-tuple structure defines the objects involved, their target poses, matching constraints, the success metric, and the reward associated with achieving the sub-goal.  Let's break down the tuple:
    * `objs`:  A list of object IDs that are part of this sub-goal.
    * `matches`: A binary matrix indicating which object should be placed at which target pose.  Rows correspond to objects, columns to targets. A '1' at `matches[i, j]` means object `i` should go to target pose `j`.
    * `targ_poses`: A list of target poses, each represented as a (position, orientation) tuple.
    * `replace`:  A boolean flag. If `False`, each object can only match with one unique target.  If `True`, multiple objects can be placed at the same target.
    * `rotations`: A boolean flag. If `True`, the orientation of the placed object is considered in the reward calculation. If `False`, only the position matters.
    * `metric`:  The metric used to evaluate success.  `pose` means the object's pose must match the target pose within a tolerance. `zone` means the object must be within a specified zone.
    * `params`:  Additional parameters for the metric. If `metric` is `zone`, this contains a list of (zone_pose, zone_size) tuples.
    * `step_max_reward`: The maximum reward obtainable for completing this sub-goal.

* **Oracle Agent (`oracle`):**  Provides a demonstration policy. It uses perfect information (RGB-D images and segmentation masks) to select pick and place actions. The oracle prioritizes picking objects farthest from their nearest target.

* **Reward Function (`reward`):** Calculates the reward for the current time step based on the current goal and the chosen metric (`pose` or `zone`).  It returns a delta reward (change in reward from the previous step) and an `info` dictionary for additional analysis.

* **Task Completion (`done`):**  Checks if the task is complete (all sub-goals achieved) or if the accumulated reward is close to the maximum possible reward.

* **Helper Functions:**  These functions assist with various aspects of the task, such as:
    * `is_match`: Checks if two poses are within a specified tolerance.
    * `get_random_pose`: Generates a random, collision-free pose within the workspace.
    * `get_lang_goal`: Returns the language description of the current goal.
    * `get_reward`: Returns the current cumulative reward.
    * `fill_template`:  Replaces placeholders in a template file.
    * `get_random_size`: Generates a random object size within specified bounds.
    * `color_random_brown`:  Assigns a random shade of brown to an object.


**Environment Constraints:**

I understand the constraints on object placement: they must obey physics, avoid collisions, and be placed within the specified workspace bounds (x: 0.25-0.75, y: -0.5-0.5, z: > 0).

**Multi-Step Tasks:**

I understand that multi-step tasks involve multiple sub-goals, each represented by an element in `self.goals`.  The agent must complete these sub-goals sequentially to achieve the overall task objective.

I'm ready to write code based on these APIs and constraints.  Please provide the specific task you'd like me to implement.


================= Error Book Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-on-cylinder". Here are some runtime errors that you do not want to make. Please confirm that you understand these runtime errors.

"""
- environment.py, line 338, in info
    pos, rot = p.getBasePositionAndOrientation(obj_id)
TypeError: an integer is required (got type NoneType)

- task.py, line 118, in act
    objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]
IndexError: list index out of range

- task.py, line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
TypeError: 'float' object is not subscriptable

- task.py", line 315, in is_match
  rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]

- utils.py", line 280, in quatXYZW_to_eulerXYZ
  quaternion_wxyz = np.array([q[3], q[0], q[1], q[2]])
IndexError: tuple index out of range

- pallet_pose = self.get_random_pose(env, pallet_size)
pallet_surface_height = pallet_pose[0][2]
TypeError: 'NoneType' object is not subscriptable

- No such file or directory: './cliport/environments/assets/circle/circle-template.urdf'

- No such file or directory: './cliport/environments/assets/block/block-template.urdf'

- task.py", line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
IndexError: invalid index to scalar variable.

-TypeError: get_random_size() missing 4 required positional arguments: 'min_y', 'max_y', 'min_z', and 'max_z' 

- task.py", line 195, in reward
    obj_pts, zones = params
TypeError: cannot unpack non-iterable NoneType object

-  environment.py", line 230, in step
    reward, info = self.task.reward() if action is not None else (0, {})
  File "task.py", line 200, in reward
    pts = obj_pts[obj_id]
IndexError: arrays used as indices must be of integer (or boolean) type

- generated_task.py", line 41, in reset
    utils.COLORS['green'], utils.COLORS['blue'], utils.COLORS['light blue'],
KeyError: 'light blue'

- environment.py", line 195, in reset
    self.task.reset(self)
  File "<string>", line 38, in reset
TypeError: can only concatenate str (not "list") to str

- environment.py", line 195, in reset
  object_shape = np.random.choice(object_shapes)
  in numpy.random.mtrand.RandomState.choice
ValueError: a must be 1-dimensional

- No such file or directory: 'assets/box-template/box-template.urdf'

- line 38, in reset.py
{'HALF': box_size / 2}
TypeError: unsupported operand type(s) for /: 'tuple' and 'int'. box_size is a tuple not a float.

- line 38, in reset.py
IndexError: tuple index out of range
box_pose = (pallet_pose[0], pallet_pose[1], pallet_pose[2] + np.sum(box_sizes[:i+1]))

- task.py", line 338, in fill_template
    for i in range(len(replace[field])):
TypeError: object of type 'float' has no len().

- task.py", line 325, in get_random_pose
    pos = (pos[0], pos[1], obj_size[2] / 2)
IndexError: tuple index out of range

- task.py", line 206, in reward
    for zone_idx, (zone_pose, zone_size) in enumerate(zones):
TypeError: 'NoneType' object is not iterable

- task.py",
ball_pose = self.get_random_pose(env, ball_size)
ball_pose[0][2] += 0.02
TypeError: 'tuple' object does not support item assignment
"""


You do not want to make mistakes such as
- using assets (urdfs) that do not exist
- use ambiguous language descriptions as goals. For instance, "place the colored blocks into the matching colored bowls" with one goal and sparse reward as the task instead of adding subgoal "place blue block into blue bowl" and give continuous reward. 
- `matches` in the goal has wrong dimensions. It should have the same dimensions as number of objects (N) multiplied by the number of goal poses (M). Usually it is N by M.
- have vector dimension problem such as `np.random.choice(box_size)` or `box_size / 2` where `box_size` is a tuple and not an int
- make too large an object for stacking or make the task objects invisible for picking. 
- accessing index out of bound `pallet_pose[2]` for `pallet_pose`.  `pallet_pose=get_random_pose` returns a tuple (translation, rotation). It does not have 3rd component. Similarly accessing `container_pose[2]` or `box_pose[2]` would cause errors as well. Since it's a tuple, try to modify it in-place will also trigger errors.
- forget to replace str using `fill_template()` for urdfs with template such as `cylinder-template.urdf`. `ball-template.urdf`, `line-template.urf`. 
- use `self.ee = Spatula()` as a function when doing pushing tasks, which is incorrect. It should be `self.ee = Spatula`.
- forget to compute target poses `targ_poses` for matching. Do not use object IDs for poses.
- change colors of complex objects such as `zone`. You can only change color of teomplate primitive such as `cylinder-template`.
- mistakenly use `random_pose` for target pose. Design target poses based on task objectives.
- add only one or fewer language goals which causes language-motion inconsistentcy. Note that the language goals usually are the same number as the pick and place goals.


>>> Answer: 
Yes, I understand the runtime errors listed and the additional points you've made about avoiding mistakes in task generation. I will be mindful of these issues when writing the code for the "stack-balls-on-cylinder" task.  I will pay particular attention to:

* **File Paths:** Ensuring all URDF files exist and paths are correct.
* **Clear Goals:** Defining specific, unambiguous language goals and subgoals with appropriate rewards.
* **Matches Dimensions:** Ensuring the `matches` array has the correct dimensions (N x M).
* **Vector Operations:** Handling vector and scalar operations correctly, especially with object sizes (using indexing for tuples).
* **Object Sizes and Visibility:** Keeping object sizes reasonable for stacking and ensuring they are visible for picking.
* **Pose Access:** Accessing pose components correctly, remembering that `get_random_pose` returns a (position, rotation) tuple.  And not modifying tuples in-place.
* **Template Filling:** Using `fill_template()` to replace placeholders in URDF templates.
* **End-Effector Initialization:** Correctly initializing the end-effector (e.g., `self.ee = Spatula`).
* **Target Pose Calculation:** Explicitly calculating target poses (`targ_poses`) based on task objectives.
* **Object Colors:** Only changing colors of primitive template objects.
* **Random Poses vs. Target Poses:** Using `random_pose` appropriately and designing specific target poses for the task.
* **Sufficient Language Goals:** Providing enough language goals to match the pick-and-place actions, ensuring language-motion consistency.


I will double-check these points before running the code to minimize the risk of encountering these errors.


================= Code Generation!

>>> Prompt: 
Now I will provide you some reference code and you can write the code for the task "stack-balls-on-cylinder".


"""
import os

import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils


class PackingShapes(Task):
    """pick up randomly sized shapes and place them tightly into a container."""

    def __init__(self):
        super().__init__()
        self.max_steps = 1
        self.homogeneous = False

        self.lang_template = "pack the {obj} in the brown box"
        self.task_completed_desc = "done packing shapes."
        self.additional_reset()


    def reset(self, env):
        super().reset(env)

        # Shape Names:
        shapes = utils.assembling_kit_shapes

        n_objects = 5
        if self.mode == 'train':
            obj_shapes = np.random.choice(self.train_set, n_objects, replace=False)
        else:
            if self.homogeneous:
                obj_shapes = [np.random.choice(self.test_set, replace=False)] * n_objects
            else:
                obj_shapes = np.random.choice(self.test_set, n_objects, replace=False)

        # Shuffle colors to avoid always picking an object of the same color
        colors, color_names = utils.get_colors(mode=self.mode)

        # Add container box.
        zone_size = self.get_random_size(0.1, 0.15, 0.1, 0.15, 0.05, 0.05)
        zone_pose = self.get_random_pose(env, zone_size)
        container_template = 'container/container-template.urdf'
        replace = {'DIM': zone_size, 'HALF': (zone_size[0] / 2, zone_size[1] / 2, zone_size[2] / 2)}
        # IMPORTANT: REPLACE THE TEMPLATE URDF with `fill_template`
        container_urdf = self.fill_template(container_template, replace)
        env.add_object(container_urdf, zone_pose, 'fixed')

        # Add objects.
        objects = []
        template = 'kitting/object-template.urdf'
        for i in range(n_objects):
            shape = obj_shapes[i]

            # x, y, z dimensions for the asset size
            size = (0.08, 0.08, 0.02)
            pose= self.get_random_pose(env, size)
            fname = f'{shape:02d}.obj'
            fname = os.path.join(self.assets_root, 'kitting', fname)
            scale = [0.003, 0.003, 0.001]  # .0005
            replace = {'FNAME': (fname,),
                       'SCALE': scale,
                       'COLOR': colors[i]}

            # IMPORTANT: REPLACE THE TEMPLATE URDF
            urdf = self.fill_template(template, replace)
            block_id = env.add_object(urdf, pose)
            objects.append(block_id)

        # Pick the first shape.
        num_objects_to_pick = 1
        for i in range(num_objects_to_pick):
            # IMPORTANT: Specify (obj_pts, [(zone_pose, zone_size)]) for target `zone`. obj_pts is a dict
            language_goal = self.lang_template.format(obj=shapes[obj_shapes[i]])
            self.add_goal(objs=[objects[i]], matches=np.int32([[1]]), targ_poses=[zone_pose], replace=False,
                rotations=True, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1 / num_objects_to_pick,
                language_goal=language_goal)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p


class PlaceRedInGreen(Task):
    """pick up the red blocks and place them into the green bowls amidst other objects."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "put the red blocks in a green bowl"
        self.task_completed_desc = "done placing blocks in bowls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)
        n_bowls = np.random.randint(1, 4)
        n_blocks = np.random.randint(1, n_bowls + 1)

        # Add bowls.
        # x, y, z dimensions for the asset size
        bowl_size = (0.12, 0.12, 0)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_poses = []
        for _ in range(n_bowls):
            bowl_pose = self.get_random_pose(env, obj_size=bowl_size)
            env.add_object(urdf=bowl_urdf, pose=bowl_pose, category='fixed')
            bowl_poses.append(bowl_pose)

        # Add blocks.
        # x, y, z dimensions for the asset size
        blocks = []
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'
        for _ in range(n_blocks):
            block_pose = self.get_random_pose(env, obj_size=block_size)
            block_id = env.add_object(block_urdf, block_pose)
            blocks.append(block_id)

        # Goal: each red block is in a different green bowl.
        self.add_goal(objs=blocks, matches=np.ones((len(blocks), len(bowl_poses))), targ_poses=bowl_poses, replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1, language_goal=self.lang_template)

        # Colors of distractor objects.
        bowl_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'green']
        block_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'red']

        # Add distractors.
        n_distractors = 0
        while n_distractors < 6:
            is_block = np.random.rand() > 0.5
            urdf = block_urdf if is_block else bowl_urdf
            size = block_size if is_block else bowl_size
            colors = block_colors if is_block else bowl_colors
            pose = self.get_random_pose(env, obj_size=size)
            color = colors[n_distractors % len(colors)]

            obj_id = env.add_object(urdf, pose, color=color)
            n_distractors += 1
"""
"""
import numpy as np
from cliport.tasks import primitives
from cliport.tasks.grippers import Spatula
from cliport.tasks.task import Task
from cliport.utils import utils


class SweepingPiles(Task):
    """Push piles of small objects into a target goal zone marked on the tabletop."""

    def __init__(self):
        super().__init__()
        self.max_steps = 20
        self.lang_template = "push the pile of blocks into the green square"
        self.task_completed_desc = "done sweeping."
        self.primitive = primitives.push
        self.ee = Spatula
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add goal zone.
        zone_size = (0.12, 0.12, 0)
        zone_pose = self.get_random_pose(env, zone_size)
        env.add_object('zone/zone.urdf', zone_pose, 'fixed')

        # Add pile of small blocks with `make_piles` function
        obj_ids = self.make_piles(env)

        # Add goal
        self.add_goal(objs=obj_ids, matches=np.ones((50, 1)), targ_poses=[zone_pose], replace=True,
                rotations=False, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1, language_goal=self.lang_template)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p

class StackBlockPyramid(Task):
    """Build a pyramid of colored blocks in a color sequence"""

    def __init__(self):
        super().__init__()
        self.max_steps = 12
        self.lang_template = "make the {row} row with {blocks}"
        self.task_completed_desc = "done stacking block pyramid."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add base.
        base_size = (0.05, 0.15, 0.005)
        base_urdf = 'stacking/stand.urdf'
        base_pose = self.get_random_pose(env, base_size)
        env.add_object(base_urdf, base_pose, category='fixed')

        # Block colors.
        colors = [
            utils.COLORS['purple'], utils.COLORS['blue'], utils.COLORS['green'],
            utils.COLORS['yellow'], utils.COLORS['orange'], utils.COLORS['red']
        ]

        # Add blocks.
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'

        objs = []
        for i in range(6):
            block_pose = self.get_random_pose(env, block_size)
            block_id = env.add_object(block_urdf, block_pose, color=colors[i])
            objs.append(block_id)

        # IMPORTANT Associate placement locations for goals.
        place_pos = [(0, -0.05, 0.03), (0, 0, 0.03),
                     (0, 0.05, 0.03), (0, -0.025, 0.08),
                     (0, 0.025, 0.08), (0, 0, 0.13)]
        targs = [(utils.apply(base_pose, i), base_pose[1]) for i in place_pos]

        # Goal: blocks are stacked in a pyramid (bottom row: green, blue, purple).
        language_goal = self.lang_template.format(blocks="the green, blue and purple blocks", row="bottom")
        self.add_goal(objs=objs[:3], matches=np.ones((3, 3)), targ_poses=targs[:3], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 2, symmetries=[np.pi/2]*3, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (middle row: yellow, orange).
        language_goal = self.lang_template.format(blocks="the yellow and orange blocks", row="middle")      
        self.add_goal(objs=objs[3:5], matches=np.ones((2, 2)), targ_poses=targs[3:5], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 3, symmetries=[np.pi/2]*2, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (top row: red).
        language_goal = self.lang_template.format(blocks="the red block", row="top")
        self.add_goal(objs=objs[5:], matches=np.ones((1, 1)), targ_poses=targs[5:], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 6, symmetries=[np.pi/2]*1, language_goal=language_goal)
"""



Do not use libraries, functions, and assets that you don't know. For each object, try to describe its color, size, category in the task first before you write the code. You do not need extra helper functions. Comment the code liberally to explain what each piece does and why it's written that way. If you have only one goal, `step_max_reward` in `add_goal` should be 1. Use functions `make_piles` and `make_ropes` for creating piles and cables. To use spatula together with the push primitives, import the libraries 
"""
from cliport.tasks import primitives;
from cliport.tasks.grippers import Spatula
"""
and then use `self.primitive = primitives.push` and `self.ee = Spatula`.
Note that the number of language goals usually match the number of motion goals, since they should correspond to each other.

Now write the code for the task "stack-balls-on-cylinder" in python code block starting with ```python.  Reminder: {'task-name': 'stack-balls-on-cylinder', 'task-description': 'Stack three differently colored balls (red, green, and blue) vertically on top of a large upright cylinder.', 'assets-used': ['ball/ball-template.urdf', 'cylinder/cylinder-template.urdf']} 


>>> Answer: 
```python
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils

class StackBallsOnCylinder(Task):
    """Stack three differently colored balls (red, green, and blue) vertically on top of a large upright cylinder."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "stack the {color} ball on the {target}"
        self.task_completed_desc = "done stacking balls on cylinder."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Cylinder: Large, upright, fixed. Grey color.
        cylinder_size = (0.1, 0.1, 0.2)  # Radius, radius, height
        cylinder_pose = self.get_random_pose(env, cylinder_size)
        cylinder_urdf = 'cylinder/cylinder-template.urdf'
        replace = {'DIM': cylinder_size, 'HALF': (cylinder_size[0], cylinder_size[1], cylinder_size[2] / 2)}
        cylinder_urdf = self.fill_template(cylinder_urdf, replace)
        env.add_object(cylinder_urdf, cylinder_pose, 'fixed', color=utils.COLORS['grey'])

        # Balls: Small, red, green, blue.  Movable.
        ball_size = (0.04, 0.04, 0.04)
        ball_urdf = 'ball/ball-template.urdf'
        colors = ['red', 'green', 'blue']
        ball_ids = []

        for color in colors:
            ball_pose = self.get_random_pose(env, ball_size)
            replace = {'DIM': ball_size, 'HALF': (ball_size[0] / 2, ball_size[1] / 2, ball_size[2] / 2)}
            ball_urdf = self.fill_template(ball_urdf, replace)
            ball_id = env.add_object(ball_urdf, ball_pose, color=utils.COLORS[color])
            ball_ids.append(ball_id)

        # Target poses for the balls on the cylinder.
        target_poses = []
        for i in range(3):
            target_pose = (cylinder_pose[0], cylinder_pose[1] + (0, 0, cylinder_size[2] / 2 + ball_size[2] / 2 + i * ball_size[2])), cylinder_pose[2])
            target_poses.append(target_pose)

        # Goal: Stack the balls in the specified order (red, then green, then blue).
        # Matches matrix is all ones because each ball has a specific target location.
        matches = np.eye(3)
        
        for i, ball_id in enumerate(ball_ids):
            language_goal = self.lang_template.format(color=colors[i], target="cylinder" if i == 0 else f"{colors[i-1]} ball")
            self.add_goal(objs=[ball_id], matches=matches[i:i+1], targ_poses=[target_poses[i]], replace=False,
                          rotations=True, metric='pose', params=None, step_max_reward=1/3, language_goal=language_goal) # 1/3 because 3 goals

```

================= Task and Asset Design!

>>> Prompt: 
You are an AI in robot simulation code and task design. I will provide you some example tasks, code implementation, and some guidelines for how to generate tasks and then you will help me generate a new task. My goal is to design diverse and feasible tasks for tabletop manipulation. I will first ask you to describe the task in natural languages and then will let you write the code for it. 

=========
Here are all the assets. Use only these assets in the task and code design. 
"""
insertion/:
ell.urdf  fixture.urdf

bowl/:
bowl.urdf

box/:
box-template.urdf

stacking/:
block.urdf  stand.urdf

zone/:
zone.obj  zone.urdf

pallet/:
pallet.obj  pallet.urdf

ball/:
ball-template.urdf

cylinder/:
cylinder-template.urdf

bowl/:
bowl.urdf

# assets not for picking
corner/:
corner-template.urdf

line/:
single-green-line-template.urdf

container/:
container-template.urdf
"""
 
=========
Here are some examples of good tasks. Try to learn from these structures but avoid overlapping wiht them.

{"assets-used": ["zone/zone.urdf", "block/small.urdf"],
 "task-description": "Push piles of small objects into a target goal zone marked on the tabletop.",
 "task-name": "sweeping-piles"}

{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "Place all blocks of a specified color in a bowl of specified color.",
 "task-name": "put-block-in-bowl"}
 
{"assets-used": ["insertion/ell.urdf", "insertion/fixture.urdf"],
 "task-description": "pick up the L-shaped red block and place it into the L-shaped fixture.",
 "task-name": "block-insertion"}
 
{"assets-used": ["kitting/kit.urdf", "kitting/object-template.urdf"],
 "task-description": "pick up different objects and arrange them on a board marked with corresponding silhouettes.",
 "task-name": "assembling-kits"}
 
{"assets-used": ["pallet/pallet.urdf", "box/box-template.urdf"],
 "task-description": "pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.",
 "task-name": "palletizing-boxes"}
 
{"assets-used": ["stacking/stand.urdf", "stacking/block.urdf"],
 "task-description": "sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.",
 "task-name": "stack-block-pyramid"}
 
{"assets-used": ["container/container-template.urdf", "box/box-template.urdf"],
 "task-description": "pick up randomly sized boxes and place them tightly into a container.",
 "task-name": "packing-boxes"}
 
{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "pick up the red blocks and place them into the green bowls amidst other objects.",
 "task-name": "place-red-in-green"}
 
{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

=========
Here are some tasks that you have come up with before. Try to learn from these structures but avoid overlapping with these tasks. For instance, `bowl_ball_placement` and `sort_balls_in_bowls` are the same task. `pile_boxes_in_corner` and `stack_blocks_into_pallet` are similar tasks, `align-cylinder-in-corner` and `align-cylinder-corner` are similar.
- sweeping-piles: {'assets-used': ['zone/zone.urdf', 'block/small.urdf'], 'task-description': 'push piles of small objects into a target goal zone marked on the tabletop.', 'task-name': 'sweeping-piles'}
- place-red-in-green: {'assets-used': ['bowl/bowl.urdf', 'stacking/block.urdf'], 'task-description': 'pick up the red blocks and place them into the green bowls amidst other objects.', 'task-name': 'place-red-in-green'}
- align-box-corner: {'assets-used': ['box/box-template.urdf', 'corner/corner-template.urdf'], 'task-description': 'pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..', 'task-name': 'align-box-corner'}
- stack-block-pyramid: {'assets-used': ['stacking/stand.urdf', 'stacking/block.urdf'], 'task-description': 'sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.', 'task-name': 'stack-block-pyramid'}
- palletizing-boxes: {'assets-used': ['pallet/pallet.urdf', 'box/box-template.urdf'], 'task-description': 'pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.', 'task-name': 'palletizing-boxes'}
- assembling-kits: {'assets-used': ['kitting/kit.urdf', 'kitting/object-template.urdf'], 'task-description': 'pick up different objects and arrange them on a board marked with corresponding silhouettes.', 'task-name': 'assembling-kits'}
- packing-boxes: {'assets-used': ['container/container-template.urdf', 'box/box-template.urdf'], 'task-description': 'pick up randomly sized boxes and place them tightly into a container.', 'task-name': 'packing-boxes'}
- manipulating-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'rearrange a deformable rope such that it connects the two endpoints of a 3-sided square.', 'task-name': 'manipulating-rope'}
- align-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'manipulate a deformable rope to connect its end-points between two corners of a 3-sided square.', 'task-name': 'align-rope'}





=========
Here are some bad example task instances with explanations.
{
    "task_name": "sort-color-blocks",
    "task_descriptions": "Pick up differently colored blocks and place them into separate bowls of matching color."
    "assets-used": ["bowl.urdf", "box/box-template.urdf],
}
reasons: not interesting because it overlaps with the current task `put-block-in-bowl`.

{
    "task-name": "guided-ball-maze",
    "task-description": "Navigate a small ball through a maze by tilting the maze board to reach the target zone.",
    "assets-used": ["zone-template.urdf", "square-template.urdf", "ball.urdf", "maze.urdf"],
}
reasons: the language descriptions are too ambiguous. Navigation is also hard to complete. Also maze.urf does not exist.

{
    "task-name": "insert_cylinder_in_sphere",
    "task-description": "Pick up the cylinder and insert it into the sphere with an opening on top.",
    "assets-used": ["cylinder/cylinder-template.urdf", "sphere/sphere-template.urdf"],
}
reasons: this task does not make sense. The sphere does not have an opening on top, and you cannot insert a cylinder into a sphere. Similarly tasks like `insert-ball-into-cylinder` and `cylinder-box-insertion` are invalid.

{
    "task-name": "ball-box-obstacle-course",
    "task-description": "Navigate a ball through an obstacle course created by randomly placed boxes and finally place it inside a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: Navigate the ball is not related to tabletop manipulation tasks.

{
    "task-name": "ball-in-box",
    "task-description": "Use a cable to guide a ball into an open box.",
    "assets-used": ["cable/cable.urdf", "ball/ball-template.urdf", "box/box-template.urdf"]
}
reasons: This task is too hard since it involves interaction of the cable and the ball and cannot be easily completed.

{
    "task-name": "ball-in-container",
    "task-description": "Use the spatula to lift a ball over a wall of boxes and drop it into a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: The only action primitives as pick and place. One cannot use a spatula to lift an object.

{
    "task-name": "line-ball-sorting",
    "task-description": "Move balls of different colors along a single green line, placing each ball in a designated colored box at the end of the line. The challenge includes precision in maintaining the ball on the line and the correct identification of the box color corresponding to each ball.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "line/single-green-line-template.urdf"]
}
reasons: Piling or stacking balls are physically infeasible in the simulation.



=========
Now please describe the new task in natural languages and explain its novelty and challenges. Format the answer in a python dictionary with keys "task-name" and value type string, "task-description" (one specific sentence) and value type string, and "assets-used" and value type list of strings. Note that

- Do not use assets that are not in the list above. 
- Tasks that have more colors and shapes are interesting.
- Be as specific as possible about the number, shape, and color of each asset in the task descriptions. 
- The task need to obey physics and remain feasible.





>>> Answer: 
```python
{
    "task-name": "stack-balls-on-cylinder",
    "task-description": "Stack three different colored balls (red, green, blue) on top of a cylinder.",
    "assets-used": ["ball/ball-template.urdf", "cylinder/cylinder-template.urdf"],
}
```

**Novelty:** This task introduces the challenge of stacking spherical objects, which are inherently unstable, onto another object.  While stacking blocks is common, stacking balls requires more precise manipulation due to their tendency to roll.  This differentiates it from tasks involving block stacking or placing objects into containers.

**Challenges:**  The primary challenge lies in the precise placement of each ball onto the cylinder and the subsequent balls on top of each other.  Maintaining balance and preventing the balls from rolling off requires careful control of the robot's end-effector. The curved surfaces of both the balls and the cylinder make the stacking more difficult compared to flat surfaces.  The task also involves a degree of sequential planning, as each ball must be placed strategically to support the next.


================= API Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-on-cylinder". Here are some APIs that are defined. Please confirm that you understand these APIs.

"""
class Task():
    """Base Task class."""

    def __init__(self):
        self.ee = Suction
        self.mode = 'train'
        self.sixdof = False
        self.primitive = primitives.PickPlace()
        self.oracle_cams = cameras.Oracle.CONFIG

        # Evaluation epsilons (for pose evaluation metric).
        self.pos_eps = 0.01
        self.rot_eps = np.deg2rad(15)

        # Workspace bounds.
        self.pix_size = 0.003125
        self.bounds = np.array([[0.25, 0.75], [-0.5, 0.5], [0, 0.3]])
        self.zone_bounds = np.copy(self.bounds)

        self.goals = []
        self.lang_goals = []
        self.task_completed_desc = "task completed."
        self.progress = 0
        self._rewards = 0
        self.assets_root = None

    def reset(self, env):
        if not self.assets_root:
            raise ValueError('assets_root must be set for task, '
                             'call set_assets_root().')
        self.goals = []
        self.lang_goals = []
        self.progress = 0  # Task progression metric in range [0, 1].
        self._rewards = 0  # Cumulative returned rewards.

    # -------------------------------------------------------------------------
    # Oracle Agent
    # -------------------------------------------------------------------------

    def oracle(self, env):
        """Oracle agent."""
        OracleAgent = collections.namedtuple('OracleAgent', ['act'])

        def act(obs, info):
            """Calculate action."""

            # Oracle uses perfect RGB-D orthographic images and segmentation masks.
            _, hmap, obj_mask = self.get_true_image(env)

            # Unpack next goal step.
            objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]

            # Match objects to targets without replacement.
            if not replace:

                # Modify a copy of the match matrix.
                matches = matches.copy()

                # Ignore already matched objects.
                for i in range(len(objs)):
                    object_id, (symmetry, _) = objs[i]
                    pose = p.getBasePositionAndOrientation(object_id)
                    targets_i = np.argwhere(matches[i, :]).reshape(-1)
                    for j in targets_i:
                        if self.is_match(pose, targs[j], symmetry):
                            matches[i, :] = 0
                            matches[:, j] = 0

            # Get objects to be picked (prioritize farthest from nearest neighbor).
            nn_dists = []
            nn_targets = []
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                xyz, _ = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                if len(targets_i) > 0:
                    targets_xyz = np.float32([targs[j][0] for j in targets_i])
                    dists = np.linalg.norm(
                        targets_xyz - np.float32(xyz).reshape(1, 3), axis=1)
                    nn = np.argmin(dists)
                    nn_dists.append(dists[nn])
                    nn_targets.append(targets_i[nn])

                # Handle ignored objects.
                else:
                    nn_dists.append(0)
                    nn_targets.append(-1)
            order = np.argsort(nn_dists)[::-1]

            # Filter out matched objects.
            order = [i for i in order if nn_dists[i] > 0]

            pick_mask = None
            for pick_i in order:
                pick_mask = np.uint8(obj_mask == objs[pick_i][0])

                # Erode to avoid picking on edges.
                # pick_mask = cv2.erode(pick_mask, np.ones((3, 3), np.uint8))

                if np.sum(pick_mask) > 0:
                    break

            # Trigger task reset if no object is visible.
            if pick_mask is None or np.sum(pick_mask) == 0:
                self.goals = []
                self.lang_goals = []
                print('Object for pick is not visible. Skipping demonstration.')
                return

            # Get picking pose.
            pick_prob = np.float32(pick_mask)
            pick_pix = utils.sample_distribution(pick_prob)
            # For "deterministic" demonstrations on insertion-easy, use this:
            # pick_pix = (160,80)
            pick_pos = utils.pix_to_xyz(pick_pix, hmap,
                                        self.bounds, self.pix_size)
            pick_pose = (np.asarray(pick_pos), np.asarray((0, 0, 0, 1)))

            # Get placing pose.
            targ_pose = targs[nn_targets[pick_i]]
            obj_pose = p.getBasePositionAndOrientation(objs[pick_i][0])
            if not self.sixdof:
                obj_euler = utils.quatXYZW_to_eulerXYZ(obj_pose[1])
                obj_quat = utils.eulerXYZ_to_quatXYZW((0, 0, obj_euler[2]))
                obj_pose = (obj_pose[0], obj_quat)
            world_to_pick = utils.invert(pick_pose)
            obj_to_pick = utils.multiply(world_to_pick, obj_pose)
            pick_to_obj = utils.invert(obj_to_pick)
            place_pose = utils.multiply(targ_pose, pick_to_obj)

            # Rotate end effector?
            if not rotations:
                place_pose = (place_pose[0], (0, 0, 0, 1))

            place_pose = (np.asarray(place_pose[0]), np.asarray(place_pose[1]))

            return {'pose0': pick_pose, 'pose1': place_pose}

        return OracleAgent(act)

    # -------------------------------------------------------------------------
    # Reward Function and Task Completion Metrics
    # -------------------------------------------------------------------------

    def reward(self):
        """Get delta rewards for current timestep.

        Returns:
          A tuple consisting of the scalar (delta) reward, plus `extras`
            dict which has extra task-dependent info from the process of
            computing rewards that gives us finer-grained details. Use
            `extras` for further data analysis.
        """
        reward, info = 0, {}

        # Unpack next goal step.
        objs, matches, targs, _, _, metric, params, max_reward = self.goals[0]

        # Evaluate by matching object poses.
        if metric == 'pose':
            step_reward = 0
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                pose = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                for j in targets_i:
                    target_pose = targs[j]
                    if self.is_match(pose, target_pose, symmetry):
                        step_reward += max_reward / len(objs)
                        print(f"object {i} match with target {j} rew: {step_reward}")
                        break

        # Evaluate by measuring object intersection with zone.
        elif metric == 'zone':
            zone_pts, total_pts = 0, 0
            obj_pts, zones = params
            for zone_idx, (zone_pose, zone_size) in enumerate(zones):

                # Count valid points in zone.
                for obj_idx, obj_id in enumerate(obj_pts):
                    pts = obj_pts[obj_id]
                    obj_pose = p.getBasePositionAndOrientation(obj_id)
                    world_to_zone = utils.invert(zone_pose)
                    obj_to_zone = utils.multiply(world_to_zone, obj_pose)
                    pts = np.float32(utils.apply(obj_to_zone, pts))
                    if len(zone_size) > 1:
                        valid_pts = np.logical_and.reduce([
                            pts[0, :] > -zone_size[0] / 2, pts[0, :] < zone_size[0] / 2,
                            pts[1, :] > -zone_size[1] / 2, pts[1, :] < zone_size[1] / 2,
                            pts[2, :] < self.zone_bounds[2, 1]])

                    # if zone_idx == matches[obj_idx].argmax():
                    zone_pts += np.sum(np.float32(valid_pts))
                    total_pts += pts.shape[1]
            step_reward = max_reward * (zone_pts / total_pts)

        # Get cumulative rewards and return delta.
        reward = self.progress + step_reward - self._rewards
        self._rewards = self.progress + step_reward

        # Move to next goal step if current goal step is complete.
        if np.abs(max_reward - step_reward) < 0.01:
            self.progress += max_reward  # Update task progress.
            self.goals.pop(0)
            if len(self.lang_goals) > 0:
                self.lang_goals.pop(0)

        return reward, info

    def done(self):
        """Check if the task is done or has failed.

        Returns:
          True if the episode should be considered a success, which we
            use for measuring successes, which is particularly helpful for tasks
            where one may get successes on the very last time step, e.g., getting
            the cloth coverage threshold on the last alllowed action.
            However, for bag-items-easy and bag-items-hard (which use the
            'bag-items' metric), it may be necessary to filter out demos that did
            not attain sufficiently high reward in external code. Currently, this
            is done in `main.py` and its ignore_this_demo() method.
        """
        return (len(self.goals) == 0) or (self._rewards > 0.99)
        # return zone_done or defs_done or goal_done

    # -------------------------------------------------------------------------
    # Environment Helper Functions
    # -------------------------------------------------------------------------

    def is_match(self, pose0, pose1, symmetry):
        """Check if pose0 and pose1 match within a threshold."""

        # Get translational error.
        diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
        dist_pos = np.linalg.norm(diff_pos)

        # Get rotational error around z-axis (account for symmetries).
        diff_rot = 0
        if symmetry > 0:
            rot0 = np.array(utils.quatXYZW_to_eulerXYZ(pose0[1]))[2]
            rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]
            diff_rot = np.abs(rot0 - rot1) % symmetry
            if diff_rot > (symmetry / 2):
                diff_rot = symmetry - diff_rot

        return (dist_pos < self.pos_eps) and (diff_rot < self.rot_eps)

    def get_random_pose(self, env, obj_size):
        """Get random collision-free object pose within workspace bounds."""

        # Get erosion size of object in pixels.
        max_size = np.sqrt(obj_size[0] ** 2 + obj_size[1] ** 2)
        erode_size = int(np.round(max_size / self.pix_size))

        _, hmap, obj_mask = self.get_true_image(env)

        # Randomly sample an object pose within free-space pixels.
        free = np.ones(obj_mask.shape, dtype=np.uint8)
        for obj_ids in env.obj_ids.values():
            for obj_id in obj_ids:
                free[obj_mask == obj_id] = 0
        free[0, :], free[:, 0], free[-1, :], free[:, -1] = 0, 0, 0, 0
        free = cv2.erode(free, np.ones((erode_size, erode_size), np.uint8))

        # if np.sum(free) == 0:
        #     return None, None

        if np.sum(free) == 0:
            # avoid returning None, None
            # return None, None
            pix = (obj_mask.shape[0] // 2, obj_mask.shape[1] // 2)
        else:
            pix = utils.sample_distribution(np.float32(free))
        pos = utils.pix_to_xyz(pix, hmap, self.bounds, self.pix_size)
        pos = (pos[0], pos[1], obj_size[2] / 2)
        theta = np.random.rand() * 2 * np.pi
        rot = utils.eulerXYZ_to_quatXYZW((0, 0, theta))
        return pos, rot

    def get_lang_goal(self):
        if len(self.lang_goals) == 0:
            return self.task_completed_desc
        else:
            return self.lang_goals[0]

    def get_reward(self):
        return float(self._rewards)

    # -------------------------------------------------------------------------
    # Helper Functions
    # -------------------------------------------------------------------------

    def fill_template(self, template, replace):
        """Read a file and replace key strings."""
        full_template_path = os.path.join(self.assets_root, template)
        with open(full_template_path, 'r') as file:
            fdata = file.read()
        for field in replace:
            for i in range(len(replace[field])):
                fdata = fdata.replace(f'{field}{i}', str(replace[field][i]))
        alphabet = string.ascii_lowercase + string.digits
        rname = ''.join(random.choices(alphabet, k=16))
        tmpdir = tempfile.gettempdir()
        template_filename = os.path.split(template)[-1]
        fname = os.path.join(tmpdir, f'{template_filename}.{rname}')
        with open(fname, 'w') as file:
            file.write(fdata)
        return fname

    def get_random_size(self, min_x, max_x, min_y, max_y, min_z, max_z):
        """Get random box size."""
        size = np.random.rand(3)
        size[0] = size[0] * (max_x - min_x) + min_x
        size[1] = size[1] * (max_y - min_y) + min_y
        size[2] = size[2] * (max_z - min_z) + min_z
        return tuple(size)

    def color_random_brown(self, obj):
        shade = np.random.rand() + 0.5
        color = np.float32([shade * 156, shade * 117, shade * 95, 255]) / 255
        p.changeVisualShape(obj, -1, rgbaColor=color)

  """""
  
  # Environment Class
  def add_object(self, urdf, pose, category='rigid'):
    """List of (fixed, rigid, or deformable) objects in env."""
    fixed_base = 1 if category == 'fixed' else 0
    obj_id = pybullet_utils.load_urdf(
        p,
        os.path.join(self.assets_root, urdf),
        pose[0],
        pose[1],
        useFixedBase=fixed_base)
    self.obj_ids[category].append(obj_id)
    return obj_id
"""

=========
Note that the objects need to obey physics and not collide with each other, and the object goal poses need to be above the table with lower bound x=0.25, y=-0.5 and upper bound x=0.75, y=0.5. When there are multiple objects for a multi-step pick-and-place task, there are often multiple subgoals. Once the task and environment are generated, an agent with a pick and place primitive will follow the defined goal to accomplish the tasks. 

Additionally, make sure you understand and summarize the ``self.goals`` variables, which has a list of 8-tuple with (objs, matches, targ_poses, replace, rotations, metric, params, step_max_reward, symmetries).
- objs (List of obj_id): object ID.
- matches (Binary Matrix): a binary matrix that denotes which object is matched with which target. This matrix has dimension len(objs) x len(targs).
- targ_poses (List of Poses [(translation, rotation)] ): a list of target poses of tuple (translation, rotation). 
- replace (Boolean): whether each object can match with one unique target. This is important if we have one target and multiple objects. If it's set to be false, then any object matching with the target will satisfy.
- rotations (Boolean): whether the placement action has a rotation degree of freedom. 
- metric (`pose` or `zone`): `pose` or `zone` that the object needs to be transported to. Example: `pose`. 
- params (List of (zone_target, zone_size)): a list of (zone_target, zone_size) for each zone if the metric is `zone`. 
- step_max_reward (float): the total reward of matching all the objects with all the target poses. It is not dependent on the number of objects but dependent on the number of goals. 
- symmetries: the radians that the object is symmetric around z axis.
- language_goal: the low-level language instructions that denote the goal of this step.
 


>>> Answer: 
Yes, I understand the provided APIs and their intended usage. Here's a summary of my understanding:

**Task Class:**

The `Task` class provides a base structure for defining and managing manipulation tasks within a simulated environment (likely PyBullet). It handles aspects like:

* **End-Effector:**  Uses a suction-based end-effector (`self.ee = Suction`).
* **Mode:**  Operates in either 'train' or other modes (`self.mode = 'train'`).
* **Action Space:** Can use either 3DoF or 6DoF actions (`self.sixdof = False`).
* **Primitive Actions:** Employs a pick-and-place primitive (`self.primitive = primitives.PickPlace()`).
* **Oracle:**  Includes an oracle agent for demonstration generation, using perfect sensing (`self.oracle_cams`).
* **Evaluation:** Defines position and rotation tolerances for evaluating success (`self.pos_eps`, `self.rot_eps`).
* **Workspace:**  Specifies the workspace boundaries and pixel size for image-based operations (`self.bounds`, `self.pix_size`, `self.zone_bounds`).
* **Goals:**  Stores the task goals, including object-target matches, target poses, and reward information (`self.goals`, `self.lang_goals`).
* **Progress and Reward:** Tracks task progress and cumulative rewards (`self.progress`, `self._rewards`).
* **Asset Management:** Manages paths to asset files (`self.assets_root`).

**Key Methods:**

* **`reset(self, env)`:**  Resets the task state, clearing goals and progress.
* **`oracle(self, env)`:**  Provides an oracle agent that generates pick-and-place actions based on perfect information.  It prioritizes picking objects farthest from their nearest target.
* **`reward(self)`:**  Calculates the reward for the current timestep based on the defined metric ('pose' or 'zone').  It returns a delta reward and an info dictionary.
* **`done(self)`:**  Checks if the task is completed or failed based on goal completion or reward threshold.
* **`is_match(self, pose0, pose1, symmetry)`:**  Determines if two poses are considered a match, accounting for positional and rotational tolerances, as well as object symmetries.
* **`get_random_pose(self, env, obj_size)`:**  Generates a random, collision-free pose within the workspace bounds.
* **`get_lang_goal(self)`:** Returns the language goal for the current step or a completion message if all goals are achieved.
* **`get_reward()`:** Returns the current cumulative reward.
* **`fill_template(self, template, replace)`:**  Utility function for filling in template files.
* **`get_random_size(self, min_x, max_x, min_y, max_y, min_z, max_z)`:**  Generates a random box size within specified ranges.
* **`color_random_brown(self, obj)`:**  Colors an object with a random shade of brown.

**Environment Class (Partial):**

The provided snippet from the environment class shows the `add_object` method, which loads a URDF model into the PyBullet environment at a specified pose and categorizes it as 'fixed', 'rigid', or 'deformable'.

**Understanding `self.goals`:**

The `self.goals` variable is crucial. It's a list of 8-tuples, each representing a sub-goal within the task.  Each tuple contains:

1. **`objs`:** A list of object IDs involved in the sub-goal.
2. **`matches`:** A binary matrix indicating which object should be matched with which target pose.
3. **`targ_poses`:** A list of target poses (position and orientation) for the objects.
4. **`replace`:** A boolean flag indicating whether multiple objects can match the same target.
5. **`rotations`:** A boolean flag indicating whether the end-effector rotation matters for achieving the goal.
6. **`metric`:** The metric used for evaluating the sub-goal ('pose' or 'zone').
7. **`params`:** Additional parameters specific to the metric (e.g., zone points and sizes).
8. **`step_max_reward`:** The maximum reward achievable for this sub-goal.


**Key Considerations:**

* The code emphasizes collision avoidance and ensures objects are placed within the defined workspace boundaries.
* The oracle agent provides a baseline for demonstrating task completion.
* The reward function and `done()` method define the success criteria for the task.
* The `self.goals` structure allows for complex multi-step manipulation tasks.


I'm ready to proceed with coding the "stack-balls-on-cylinder" task based on this understanding.  Please provide the specific requirements for this task, such as the number of balls, the cylinder dimensions, and the desired stacking configuration.


================= Error Book Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-on-cylinder". Here are some runtime errors that you do not want to make. Please confirm that you understand these runtime errors.

"""
- environment.py, line 338, in info
    pos, rot = p.getBasePositionAndOrientation(obj_id)
TypeError: an integer is required (got type NoneType)

- task.py, line 118, in act
    objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]
IndexError: list index out of range

- task.py, line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
TypeError: 'float' object is not subscriptable

- task.py", line 315, in is_match
  rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]

- utils.py", line 280, in quatXYZW_to_eulerXYZ
  quaternion_wxyz = np.array([q[3], q[0], q[1], q[2]])
IndexError: tuple index out of range

- pallet_pose = self.get_random_pose(env, pallet_size)
pallet_surface_height = pallet_pose[0][2]
TypeError: 'NoneType' object is not subscriptable

- No such file or directory: './cliport/environments/assets/circle/circle-template.urdf'

- No such file or directory: './cliport/environments/assets/block/block-template.urdf'

- task.py", line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
IndexError: invalid index to scalar variable.

-TypeError: get_random_size() missing 4 required positional arguments: 'min_y', 'max_y', 'min_z', and 'max_z' 

- task.py", line 195, in reward
    obj_pts, zones = params
TypeError: cannot unpack non-iterable NoneType object

-  environment.py", line 230, in step
    reward, info = self.task.reward() if action is not None else (0, {})
  File "task.py", line 200, in reward
    pts = obj_pts[obj_id]
IndexError: arrays used as indices must be of integer (or boolean) type

- generated_task.py", line 41, in reset
    utils.COLORS['green'], utils.COLORS['blue'], utils.COLORS['light blue'],
KeyError: 'light blue'

- environment.py", line 195, in reset
    self.task.reset(self)
  File "<string>", line 38, in reset
TypeError: can only concatenate str (not "list") to str

- environment.py", line 195, in reset
  object_shape = np.random.choice(object_shapes)
  in numpy.random.mtrand.RandomState.choice
ValueError: a must be 1-dimensional

- No such file or directory: 'assets/box-template/box-template.urdf'

- line 38, in reset.py
{'HALF': box_size / 2}
TypeError: unsupported operand type(s) for /: 'tuple' and 'int'. box_size is a tuple not a float.

- line 38, in reset.py
IndexError: tuple index out of range
box_pose = (pallet_pose[0], pallet_pose[1], pallet_pose[2] + np.sum(box_sizes[:i+1]))

- task.py", line 338, in fill_template
    for i in range(len(replace[field])):
TypeError: object of type 'float' has no len().

- task.py", line 325, in get_random_pose
    pos = (pos[0], pos[1], obj_size[2] / 2)
IndexError: tuple index out of range

- task.py", line 206, in reward
    for zone_idx, (zone_pose, zone_size) in enumerate(zones):
TypeError: 'NoneType' object is not iterable

- task.py",
ball_pose = self.get_random_pose(env, ball_size)
ball_pose[0][2] += 0.02
TypeError: 'tuple' object does not support item assignment
"""


You do not want to make mistakes such as
- using assets (urdfs) that do not exist
- use ambiguous language descriptions as goals. For instance, "place the colored blocks into the matching colored bowls" with one goal and sparse reward as the task instead of adding subgoal "place blue block into blue bowl" and give continuous reward. 
- `matches` in the goal has wrong dimensions. It should have the same dimensions as number of objects (N) multiplied by the number of goal poses (M). Usually it is N by M.
- have vector dimension problem such as `np.random.choice(box_size)` or `box_size / 2` where `box_size` is a tuple and not an int
- make too large an object for stacking or make the task objects invisible for picking. 
- accessing index out of bound `pallet_pose[2]` for `pallet_pose`.  `pallet_pose=get_random_pose` returns a tuple (translation, rotation). It does not have 3rd component. Similarly accessing `container_pose[2]` or `box_pose[2]` would cause errors as well. Since it's a tuple, try to modify it in-place will also trigger errors.
- forget to replace str using `fill_template()` for urdfs with template such as `cylinder-template.urdf`. `ball-template.urdf`, `line-template.urf`. 
- use `self.ee = Spatula()` as a function when doing pushing tasks, which is incorrect. It should be `self.ee = Spatula`.
- forget to compute target poses `targ_poses` for matching. Do not use object IDs for poses.
- change colors of complex objects such as `zone`. You can only change color of teomplate primitive such as `cylinder-template`.
- mistakenly use `random_pose` for target pose. Design target poses based on task objectives.
- add only one or fewer language goals which causes language-motion inconsistentcy. Note that the language goals usually are the same number as the pick and place goals.


>>> Answer: 
Yes, I understand the runtime errors listed and the points you've made about avoiding mistakes in task generation. I will keep these in mind when writing the code for the "stack-balls-on-cylinder" task.  I will pay particular attention to:

* **File Paths and Existence:** Verify that all URDF files exist in the correct locations.
* **Clear Language Goals:**  Provide specific and unambiguous language descriptions for each sub-goal, avoiding vague phrasing.
* **Matches Dimensions:** Ensure the `matches` array has the correct dimensions (N x M), reflecting the number of objects and target poses.
* **Vector Operations:** Be mindful of vector dimensions and avoid operations like division or random choice on tuples directly.  I'll use indexing to access individual elements of tuples.
* **Object Sizes and Visibility:** Keep object sizes reasonable for stacking and ensure they are visible for manipulation.
* **Pose Indexing:** Access pose components correctly, remembering that `get_random_pose` returns a (position, rotation) tuple. I will not attempt to modify tuples in-place.
* **Template Filling:** Use `fill_template()` to replace placeholders in URDFs with actual values.
* **Spatula Instantiation:** Use `self.ee = Spatula()` for spatula tasks, not as a function call.
* **Target Pose Calculation:** Explicitly calculate target poses (`targ_poses`) based on task requirements, not object IDs.
* **Color Changes:** Only change colors of primitive template objects, not complex objects like zones.
* **Random vs. Designed Poses:** Use `random_pose` appropriately and design target poses based on the task's logic.
* **Sufficient Language Goals:** Provide enough language goals to match the number of pick-and-place actions, ensuring language-motion consistency.


By addressing these points, I aim to avoid the listed runtime errors and create a robust and functional "stack-balls-on-cylinder" task.


================= Code Generation!

>>> Prompt: 
Now I will provide you some reference code and you can write the code for the task "stack-balls-on-cylinder".


"""
import os

import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils


class PackingShapes(Task):
    """pick up randomly sized shapes and place them tightly into a container."""

    def __init__(self):
        super().__init__()
        self.max_steps = 1
        self.homogeneous = False

        self.lang_template = "pack the {obj} in the brown box"
        self.task_completed_desc = "done packing shapes."
        self.additional_reset()


    def reset(self, env):
        super().reset(env)

        # Shape Names:
        shapes = utils.assembling_kit_shapes

        n_objects = 5
        if self.mode == 'train':
            obj_shapes = np.random.choice(self.train_set, n_objects, replace=False)
        else:
            if self.homogeneous:
                obj_shapes = [np.random.choice(self.test_set, replace=False)] * n_objects
            else:
                obj_shapes = np.random.choice(self.test_set, n_objects, replace=False)

        # Shuffle colors to avoid always picking an object of the same color
        colors, color_names = utils.get_colors(mode=self.mode)

        # Add container box.
        zone_size = self.get_random_size(0.1, 0.15, 0.1, 0.15, 0.05, 0.05)
        zone_pose = self.get_random_pose(env, zone_size)
        container_template = 'container/container-template.urdf'
        replace = {'DIM': zone_size, 'HALF': (zone_size[0] / 2, zone_size[1] / 2, zone_size[2] / 2)}
        # IMPORTANT: REPLACE THE TEMPLATE URDF with `fill_template`
        container_urdf = self.fill_template(container_template, replace)
        env.add_object(container_urdf, zone_pose, 'fixed')

        # Add objects.
        objects = []
        template = 'kitting/object-template.urdf'
        for i in range(n_objects):
            shape = obj_shapes[i]

            # x, y, z dimensions for the asset size
            size = (0.08, 0.08, 0.02)
            pose= self.get_random_pose(env, size)
            fname = f'{shape:02d}.obj'
            fname = os.path.join(self.assets_root, 'kitting', fname)
            scale = [0.003, 0.003, 0.001]  # .0005
            replace = {'FNAME': (fname,),
                       'SCALE': scale,
                       'COLOR': colors[i]}

            # IMPORTANT: REPLACE THE TEMPLATE URDF
            urdf = self.fill_template(template, replace)
            block_id = env.add_object(urdf, pose)
            objects.append(block_id)

        # Pick the first shape.
        num_objects_to_pick = 1
        for i in range(num_objects_to_pick):
            # IMPORTANT: Specify (obj_pts, [(zone_pose, zone_size)]) for target `zone`. obj_pts is a dict
            language_goal = self.lang_template.format(obj=shapes[obj_shapes[i]])
            self.add_goal(objs=[objects[i]], matches=np.int32([[1]]), targ_poses=[zone_pose], replace=False,
                rotations=True, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1 / num_objects_to_pick,
                language_goal=language_goal)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p


class PlaceRedInGreen(Task):
    """pick up the red blocks and place them into the green bowls amidst other objects."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "put the red blocks in a green bowl"
        self.task_completed_desc = "done placing blocks in bowls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)
        n_bowls = np.random.randint(1, 4)
        n_blocks = np.random.randint(1, n_bowls + 1)

        # Add bowls.
        # x, y, z dimensions for the asset size
        bowl_size = (0.12, 0.12, 0)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_poses = []
        for _ in range(n_bowls):
            bowl_pose = self.get_random_pose(env, obj_size=bowl_size)
            env.add_object(urdf=bowl_urdf, pose=bowl_pose, category='fixed')
            bowl_poses.append(bowl_pose)

        # Add blocks.
        # x, y, z dimensions for the asset size
        blocks = []
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'
        for _ in range(n_blocks):
            block_pose = self.get_random_pose(env, obj_size=block_size)
            block_id = env.add_object(block_urdf, block_pose)
            blocks.append(block_id)

        # Goal: each red block is in a different green bowl.
        self.add_goal(objs=blocks, matches=np.ones((len(blocks), len(bowl_poses))), targ_poses=bowl_poses, replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1, language_goal=self.lang_template)

        # Colors of distractor objects.
        bowl_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'green']
        block_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'red']

        # Add distractors.
        n_distractors = 0
        while n_distractors < 6:
            is_block = np.random.rand() > 0.5
            urdf = block_urdf if is_block else bowl_urdf
            size = block_size if is_block else bowl_size
            colors = block_colors if is_block else bowl_colors
            pose = self.get_random_pose(env, obj_size=size)
            color = colors[n_distractors % len(colors)]

            obj_id = env.add_object(urdf, pose, color=color)
            n_distractors += 1
"""
"""
import numpy as np
from cliport.tasks import primitives
from cliport.tasks.grippers import Spatula
from cliport.tasks.task import Task
from cliport.utils import utils


class SweepingPiles(Task):
    """Push piles of small objects into a target goal zone marked on the tabletop."""

    def __init__(self):
        super().__init__()
        self.max_steps = 20
        self.lang_template = "push the pile of blocks into the green square"
        self.task_completed_desc = "done sweeping."
        self.primitive = primitives.push
        self.ee = Spatula
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add goal zone.
        zone_size = (0.12, 0.12, 0)
        zone_pose = self.get_random_pose(env, zone_size)
        env.add_object('zone/zone.urdf', zone_pose, 'fixed')

        # Add pile of small blocks with `make_piles` function
        obj_ids = self.make_piles(env)

        # Add goal
        self.add_goal(objs=obj_ids, matches=np.ones((50, 1)), targ_poses=[zone_pose], replace=True,
                rotations=False, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1, language_goal=self.lang_template)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p

class StackBlockPyramid(Task):
    """Build a pyramid of colored blocks in a color sequence"""

    def __init__(self):
        super().__init__()
        self.max_steps = 12
        self.lang_template = "make the {row} row with {blocks}"
        self.task_completed_desc = "done stacking block pyramid."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add base.
        base_size = (0.05, 0.15, 0.005)
        base_urdf = 'stacking/stand.urdf'
        base_pose = self.get_random_pose(env, base_size)
        env.add_object(base_urdf, base_pose, category='fixed')

        # Block colors.
        colors = [
            utils.COLORS['purple'], utils.COLORS['blue'], utils.COLORS['green'],
            utils.COLORS['yellow'], utils.COLORS['orange'], utils.COLORS['red']
        ]

        # Add blocks.
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'

        objs = []
        for i in range(6):
            block_pose = self.get_random_pose(env, block_size)
            block_id = env.add_object(block_urdf, block_pose, color=colors[i])
            objs.append(block_id)

        # IMPORTANT Associate placement locations for goals.
        place_pos = [(0, -0.05, 0.03), (0, 0, 0.03),
                     (0, 0.05, 0.03), (0, -0.025, 0.08),
                     (0, 0.025, 0.08), (0, 0, 0.13)]
        targs = [(utils.apply(base_pose, i), base_pose[1]) for i in place_pos]

        # Goal: blocks are stacked in a pyramid (bottom row: green, blue, purple).
        language_goal = self.lang_template.format(blocks="the green, blue and purple blocks", row="bottom")
        self.add_goal(objs=objs[:3], matches=np.ones((3, 3)), targ_poses=targs[:3], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 2, symmetries=[np.pi/2]*3, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (middle row: yellow, orange).
        language_goal = self.lang_template.format(blocks="the yellow and orange blocks", row="middle")      
        self.add_goal(objs=objs[3:5], matches=np.ones((2, 2)), targ_poses=targs[3:5], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 3, symmetries=[np.pi/2]*2, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (top row: red).
        language_goal = self.lang_template.format(blocks="the red block", row="top")
        self.add_goal(objs=objs[5:], matches=np.ones((1, 1)), targ_poses=targs[5:], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 6, symmetries=[np.pi/2]*1, language_goal=language_goal)
"""



Do not use libraries, functions, and assets that you don't know. For each object, try to describe its color, size, category in the task first before you write the code. You do not need extra helper functions. Comment the code liberally to explain what each piece does and why it's written that way. If you have only one goal, `step_max_reward` in `add_goal` should be 1. Use functions `make_piles` and `make_ropes` for creating piles and cables. To use spatula together with the push primitives, import the libraries 
"""
from cliport.tasks import primitives;
from cliport.tasks.grippers import Spatula
"""
and then use `self.primitive = primitives.push` and `self.ee = Spatula`.
Note that the number of language goals usually match the number of motion goals, since they should correspond to each other.

Now write the code for the task "stack-balls-on-cylinder" in python code block starting with ```python.  Reminder: {'task-name': 'stack-balls-on-cylinder', 'task-description': 'Stack three different colored balls (red, green, blue) on top of a cylinder.', 'assets-used': ['ball/ball-template.urdf', 'cylinder/cylinder-template.urdf']} 


>>> Answer: 
```python
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils

class StackBallsOnCylinder(Task):
    """Stack three different colored balls (red, green, blue) on top of a cylinder."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "stack the {color} ball on the cylinder"
        self.task_completed_desc = "done stacking balls on cylinder."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Cylinder: gray, radius=0.03, height=0.1
        cylinder_size = (0.03, 0.1) # radius, height
        cylinder_pose = self.get_random_pose(env, cylinder_size)
        cylinder_template = 'cylinder/cylinder-template.urdf'
        replace = {'DIM': cylinder_size}
        cylinder_urdf = self.fill_template(cylinder_template, replace)
        env.add_object(cylinder_urdf, cylinder_pose, 'fixed')

        # Balls: red, green, blue, radius=0.03
        ball_size = (0.03,) # radius
        ball_template = 'ball/ball-template.urdf'
        colors = [utils.COLORS['red'], utils.COLORS['green'], utils.COLORS['blue']]
        ball_ids = []

        # placement positions for the balls relative to the cylinder top center
        place_pos = [(0, 0, 0.03), (0, 0, 0.09), (0, 0, 0.15)]
        target_poses = []

        for i in range(3):
            ball_pose = self.get_random_pose(env, ball_size)
            replace = {'DIM': ball_size, 'COLOR': colors[i]}
            ball_urdf = self.fill_template(ball_template, replace)
            ball_id = env.add_object(ball_urdf, ball_pose)
            ball_ids.append(ball_id)

            # Calculate target poses by adding place_pos to the cylinder pose
            targ_pose = utils.apply(cylinder_pose, place_pos[i])
            target_poses.append((targ_pose, cylinder_pose[1])) # Include cylinder orientation

        # Goal: stack balls on cylinder in the order red, green, blue.
        for i in range(3):
            language_goal = self.lang_template.format(color=['red', 'green', 'blue'][i])
            self.add_goal(objs=[ball_ids[i]], matches=np.ones((1, 1)), targ_poses=[target_poses[i]], replace=False,
                          rotations=True, metric='pose', params=None, step_max_reward=1/3, language_goal=language_goal) # 1/3 since 3 goals

```

================= TRIAL: 5

================= Task and Asset Design!

>>> Prompt: 
You are an AI in robot simulation code and task design. I will provide you some example tasks, code implementation, and some guidelines for how to generate tasks and then you will help me generate a new task. My goal is to design diverse and feasible tasks for tabletop manipulation. I will first ask you to describe the task in natural languages and then will let you write the code for it. 

=========
Here are all the assets. Use only these assets in the task and code design. 
"""
insertion/:
ell.urdf  fixture.urdf

bowl/:
bowl.urdf

box/:
box-template.urdf

stacking/:
block.urdf  stand.urdf

zone/:
zone.obj  zone.urdf

pallet/:
pallet.obj  pallet.urdf

ball/:
ball-template.urdf

cylinder/:
cylinder-template.urdf

bowl/:
bowl.urdf

# assets not for picking
corner/:
corner-template.urdf

line/:
single-green-line-template.urdf

container/:
container-template.urdf
"""
 
=========
Here are some examples of good tasks. Try to learn from these structures but avoid overlapping wiht them.

{"assets-used": ["zone/zone.urdf", "block/small.urdf"],
 "task-description": "Push piles of small objects into a target goal zone marked on the tabletop.",
 "task-name": "sweeping-piles"}

{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "Place all blocks of a specified color in a bowl of specified color.",
 "task-name": "put-block-in-bowl"}
 
{"assets-used": ["insertion/ell.urdf", "insertion/fixture.urdf"],
 "task-description": "pick up the L-shaped red block and place it into the L-shaped fixture.",
 "task-name": "block-insertion"}
 
{"assets-used": ["kitting/kit.urdf", "kitting/object-template.urdf"],
 "task-description": "pick up different objects and arrange them on a board marked with corresponding silhouettes.",
 "task-name": "assembling-kits"}
 
{"assets-used": ["pallet/pallet.urdf", "box/box-template.urdf"],
 "task-description": "pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.",
 "task-name": "palletizing-boxes"}
 
{"assets-used": ["stacking/stand.urdf", "stacking/block.urdf"],
 "task-description": "sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.",
 "task-name": "stack-block-pyramid"}
 
{"assets-used": ["container/container-template.urdf", "box/box-template.urdf"],
 "task-description": "pick up randomly sized boxes and place them tightly into a container.",
 "task-name": "packing-boxes"}
 
{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "pick up the red blocks and place them into the green bowls amidst other objects.",
 "task-name": "place-red-in-green"}
 
{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

=========
Here are some tasks that you have come up with before. Try to learn from these structures but avoid overlapping with these tasks. For instance, `bowl_ball_placement` and `sort_balls_in_bowls` are the same task. `pile_boxes_in_corner` and `stack_blocks_into_pallet` are similar tasks, `align-cylinder-in-corner` and `align-cylinder-corner` are similar.
- sweeping-piles: {'assets-used': ['zone/zone.urdf', 'block/small.urdf'], 'task-description': 'push piles of small objects into a target goal zone marked on the tabletop.', 'task-name': 'sweeping-piles'}
- place-red-in-green: {'assets-used': ['bowl/bowl.urdf', 'stacking/block.urdf'], 'task-description': 'pick up the red blocks and place them into the green bowls amidst other objects.', 'task-name': 'place-red-in-green'}
- align-box-corner: {'assets-used': ['box/box-template.urdf', 'corner/corner-template.urdf'], 'task-description': 'pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..', 'task-name': 'align-box-corner'}
- stack-block-pyramid: {'assets-used': ['stacking/stand.urdf', 'stacking/block.urdf'], 'task-description': 'sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.', 'task-name': 'stack-block-pyramid'}
- palletizing-boxes: {'assets-used': ['pallet/pallet.urdf', 'box/box-template.urdf'], 'task-description': 'pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.', 'task-name': 'palletizing-boxes'}
- assembling-kits: {'assets-used': ['kitting/kit.urdf', 'kitting/object-template.urdf'], 'task-description': 'pick up different objects and arrange them on a board marked with corresponding silhouettes.', 'task-name': 'assembling-kits'}
- packing-boxes: {'assets-used': ['container/container-template.urdf', 'box/box-template.urdf'], 'task-description': 'pick up randomly sized boxes and place them tightly into a container.', 'task-name': 'packing-boxes'}
- manipulating-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'rearrange a deformable rope such that it connects the two endpoints of a 3-sided square.', 'task-name': 'manipulating-rope'}
- align-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'manipulate a deformable rope to connect its end-points between two corners of a 3-sided square.', 'task-name': 'align-rope'}





=========
Here are some bad example task instances with explanations.
{
    "task_name": "sort-color-blocks",
    "task_descriptions": "Pick up differently colored blocks and place them into separate bowls of matching color."
    "assets-used": ["bowl.urdf", "box/box-template.urdf],
}
reasons: not interesting because it overlaps with the current task `put-block-in-bowl`.

{
    "task-name": "guided-ball-maze",
    "task-description": "Navigate a small ball through a maze by tilting the maze board to reach the target zone.",
    "assets-used": ["zone-template.urdf", "square-template.urdf", "ball.urdf", "maze.urdf"],
}
reasons: the language descriptions are too ambiguous. Navigation is also hard to complete. Also maze.urf does not exist.

{
    "task-name": "insert_cylinder_in_sphere",
    "task-description": "Pick up the cylinder and insert it into the sphere with an opening on top.",
    "assets-used": ["cylinder/cylinder-template.urdf", "sphere/sphere-template.urdf"],
}
reasons: this task does not make sense. The sphere does not have an opening on top, and you cannot insert a cylinder into a sphere. Similarly tasks like `insert-ball-into-cylinder` and `cylinder-box-insertion` are invalid.

{
    "task-name": "ball-box-obstacle-course",
    "task-description": "Navigate a ball through an obstacle course created by randomly placed boxes and finally place it inside a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: Navigate the ball is not related to tabletop manipulation tasks.

{
    "task-name": "ball-in-box",
    "task-description": "Use a cable to guide a ball into an open box.",
    "assets-used": ["cable/cable.urdf", "ball/ball-template.urdf", "box/box-template.urdf"]
}
reasons: This task is too hard since it involves interaction of the cable and the ball and cannot be easily completed.

{
    "task-name": "ball-in-container",
    "task-description": "Use the spatula to lift a ball over a wall of boxes and drop it into a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: The only action primitives as pick and place. One cannot use a spatula to lift an object.

{
    "task-name": "line-ball-sorting",
    "task-description": "Move balls of different colors along a single green line, placing each ball in a designated colored box at the end of the line. The challenge includes precision in maintaining the ball on the line and the correct identification of the box color corresponding to each ball.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "line/single-green-line-template.urdf"]
}
reasons: Piling or stacking balls are physically infeasible in the simulation.



=========
Now please describe the new task in natural languages and explain its novelty and challenges. Format the answer in a python dictionary with keys "task-name" and value type string, "task-description" (one specific sentence) and value type string, and "assets-used" and value type list of strings. Note that

- Do not use assets that are not in the list above. 
- Tasks that have more colors and shapes are interesting.
- Be as specific as possible about the number, shape, and color of each asset in the task descriptions. 
- The task need to obey physics and remain feasible.





>>> Answer: 
```python
{
    "task-name": "stack-balls-on-cylinder",
    "task-description": "Stack three different colored balls (red, green, and blue) on top of a vertically placed cylinder.",
    "assets-used": ["ball/ball-template.urdf", "cylinder/cylinder-template.urdf"]
}
```

**Novelty and Challenges:**

This task introduces the challenge of stacking round objects, which is inherently unstable and requires precise manipulation.  While stacking blocks is common, stacking balls on a cylinder presents a different level of difficulty due to the rolling nature of the balls and the limited contact area.  The use of different colored balls adds a minor element of visual distinction, but the core challenge lies in the dexterity required for successful stacking.  This task is distinct from previous examples as it combines stacking with unstable objects and requires building a vertical structure.


================= API Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-on-cylinder". Here are some APIs that are defined. Please confirm that you understand these APIs.

"""
class Task():
    """Base Task class."""

    def __init__(self):
        self.ee = Suction
        self.mode = 'train'
        self.sixdof = False
        self.primitive = primitives.PickPlace()
        self.oracle_cams = cameras.Oracle.CONFIG

        # Evaluation epsilons (for pose evaluation metric).
        self.pos_eps = 0.01
        self.rot_eps = np.deg2rad(15)

        # Workspace bounds.
        self.pix_size = 0.003125
        self.bounds = np.array([[0.25, 0.75], [-0.5, 0.5], [0, 0.3]])
        self.zone_bounds = np.copy(self.bounds)

        self.goals = []
        self.lang_goals = []
        self.task_completed_desc = "task completed."
        self.progress = 0
        self._rewards = 0
        self.assets_root = None

    def reset(self, env):
        if not self.assets_root:
            raise ValueError('assets_root must be set for task, '
                             'call set_assets_root().')
        self.goals = []
        self.lang_goals = []
        self.progress = 0  # Task progression metric in range [0, 1].
        self._rewards = 0  # Cumulative returned rewards.

    # -------------------------------------------------------------------------
    # Oracle Agent
    # -------------------------------------------------------------------------

    def oracle(self, env):
        """Oracle agent."""
        OracleAgent = collections.namedtuple('OracleAgent', ['act'])

        def act(obs, info):
            """Calculate action."""

            # Oracle uses perfect RGB-D orthographic images and segmentation masks.
            _, hmap, obj_mask = self.get_true_image(env)

            # Unpack next goal step.
            objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]

            # Match objects to targets without replacement.
            if not replace:

                # Modify a copy of the match matrix.
                matches = matches.copy()

                # Ignore already matched objects.
                for i in range(len(objs)):
                    object_id, (symmetry, _) = objs[i]
                    pose = p.getBasePositionAndOrientation(object_id)
                    targets_i = np.argwhere(matches[i, :]).reshape(-1)
                    for j in targets_i:
                        if self.is_match(pose, targs[j], symmetry):
                            matches[i, :] = 0
                            matches[:, j] = 0

            # Get objects to be picked (prioritize farthest from nearest neighbor).
            nn_dists = []
            nn_targets = []
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                xyz, _ = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                if len(targets_i) > 0:
                    targets_xyz = np.float32([targs[j][0] for j in targets_i])
                    dists = np.linalg.norm(
                        targets_xyz - np.float32(xyz).reshape(1, 3), axis=1)
                    nn = np.argmin(dists)
                    nn_dists.append(dists[nn])
                    nn_targets.append(targets_i[nn])

                # Handle ignored objects.
                else:
                    nn_dists.append(0)
                    nn_targets.append(-1)
            order = np.argsort(nn_dists)[::-1]

            # Filter out matched objects.
            order = [i for i in order if nn_dists[i] > 0]

            pick_mask = None
            for pick_i in order:
                pick_mask = np.uint8(obj_mask == objs[pick_i][0])

                # Erode to avoid picking on edges.
                # pick_mask = cv2.erode(pick_mask, np.ones((3, 3), np.uint8))

                if np.sum(pick_mask) > 0:
                    break

            # Trigger task reset if no object is visible.
            if pick_mask is None or np.sum(pick_mask) == 0:
                self.goals = []
                self.lang_goals = []
                print('Object for pick is not visible. Skipping demonstration.')
                return

            # Get picking pose.
            pick_prob = np.float32(pick_mask)
            pick_pix = utils.sample_distribution(pick_prob)
            # For "deterministic" demonstrations on insertion-easy, use this:
            # pick_pix = (160,80)
            pick_pos = utils.pix_to_xyz(pick_pix, hmap,
                                        self.bounds, self.pix_size)
            pick_pose = (np.asarray(pick_pos), np.asarray((0, 0, 0, 1)))

            # Get placing pose.
            targ_pose = targs[nn_targets[pick_i]]
            obj_pose = p.getBasePositionAndOrientation(objs[pick_i][0])
            if not self.sixdof:
                obj_euler = utils.quatXYZW_to_eulerXYZ(obj_pose[1])
                obj_quat = utils.eulerXYZ_to_quatXYZW((0, 0, obj_euler[2]))
                obj_pose = (obj_pose[0], obj_quat)
            world_to_pick = utils.invert(pick_pose)
            obj_to_pick = utils.multiply(world_to_pick, obj_pose)
            pick_to_obj = utils.invert(obj_to_pick)
            place_pose = utils.multiply(targ_pose, pick_to_obj)

            # Rotate end effector?
            if not rotations:
                place_pose = (place_pose[0], (0, 0, 0, 1))

            place_pose = (np.asarray(place_pose[0]), np.asarray(place_pose[1]))

            return {'pose0': pick_pose, 'pose1': place_pose}

        return OracleAgent(act)

    # -------------------------------------------------------------------------
    # Reward Function and Task Completion Metrics
    # -------------------------------------------------------------------------

    def reward(self):
        """Get delta rewards for current timestep.

        Returns:
          A tuple consisting of the scalar (delta) reward, plus `extras`
            dict which has extra task-dependent info from the process of
            computing rewards that gives us finer-grained details. Use
            `extras` for further data analysis.
        """
        reward, info = 0, {}

        # Unpack next goal step.
        objs, matches, targs, _, _, metric, params, max_reward = self.goals[0]

        # Evaluate by matching object poses.
        if metric == 'pose':
            step_reward = 0
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                pose = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                for j in targets_i:
                    target_pose = targs[j]
                    if self.is_match(pose, target_pose, symmetry):
                        step_reward += max_reward / len(objs)
                        print(f"object {i} match with target {j} rew: {step_reward}")
                        break

        # Evaluate by measuring object intersection with zone.
        elif metric == 'zone':
            zone_pts, total_pts = 0, 0
            obj_pts, zones = params
            for zone_idx, (zone_pose, zone_size) in enumerate(zones):

                # Count valid points in zone.
                for obj_idx, obj_id in enumerate(obj_pts):
                    pts = obj_pts[obj_id]
                    obj_pose = p.getBasePositionAndOrientation(obj_id)
                    world_to_zone = utils.invert(zone_pose)
                    obj_to_zone = utils.multiply(world_to_zone, obj_pose)
                    pts = np.float32(utils.apply(obj_to_zone, pts))
                    if len(zone_size) > 1:
                        valid_pts = np.logical_and.reduce([
                            pts[0, :] > -zone_size[0] / 2, pts[0, :] < zone_size[0] / 2,
                            pts[1, :] > -zone_size[1] / 2, pts[1, :] < zone_size[1] / 2,
                            pts[2, :] < self.zone_bounds[2, 1]])

                    # if zone_idx == matches[obj_idx].argmax():
                    zone_pts += np.sum(np.float32(valid_pts))
                    total_pts += pts.shape[1]
            step_reward = max_reward * (zone_pts / total_pts)

        # Get cumulative rewards and return delta.
        reward = self.progress + step_reward - self._rewards
        self._rewards = self.progress + step_reward

        # Move to next goal step if current goal step is complete.
        if np.abs(max_reward - step_reward) < 0.01:
            self.progress += max_reward  # Update task progress.
            self.goals.pop(0)
            if len(self.lang_goals) > 0:
                self.lang_goals.pop(0)

        return reward, info

    def done(self):
        """Check if the task is done or has failed.

        Returns:
          True if the episode should be considered a success, which we
            use for measuring successes, which is particularly helpful for tasks
            where one may get successes on the very last time step, e.g., getting
            the cloth coverage threshold on the last alllowed action.
            However, for bag-items-easy and bag-items-hard (which use the
            'bag-items' metric), it may be necessary to filter out demos that did
            not attain sufficiently high reward in external code. Currently, this
            is done in `main.py` and its ignore_this_demo() method.
        """
        return (len(self.goals) == 0) or (self._rewards > 0.99)
        # return zone_done or defs_done or goal_done

    # -------------------------------------------------------------------------
    # Environment Helper Functions
    # -------------------------------------------------------------------------

    def is_match(self, pose0, pose1, symmetry):
        """Check if pose0 and pose1 match within a threshold."""

        # Get translational error.
        diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
        dist_pos = np.linalg.norm(diff_pos)

        # Get rotational error around z-axis (account for symmetries).
        diff_rot = 0
        if symmetry > 0:
            rot0 = np.array(utils.quatXYZW_to_eulerXYZ(pose0[1]))[2]
            rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]
            diff_rot = np.abs(rot0 - rot1) % symmetry
            if diff_rot > (symmetry / 2):
                diff_rot = symmetry - diff_rot

        return (dist_pos < self.pos_eps) and (diff_rot < self.rot_eps)

    def get_random_pose(self, env, obj_size):
        """Get random collision-free object pose within workspace bounds."""

        # Get erosion size of object in pixels.
        max_size = np.sqrt(obj_size[0] ** 2 + obj_size[1] ** 2)
        erode_size = int(np.round(max_size / self.pix_size))

        _, hmap, obj_mask = self.get_true_image(env)

        # Randomly sample an object pose within free-space pixels.
        free = np.ones(obj_mask.shape, dtype=np.uint8)
        for obj_ids in env.obj_ids.values():
            for obj_id in obj_ids:
                free[obj_mask == obj_id] = 0
        free[0, :], free[:, 0], free[-1, :], free[:, -1] = 0, 0, 0, 0
        free = cv2.erode(free, np.ones((erode_size, erode_size), np.uint8))

        # if np.sum(free) == 0:
        #     return None, None

        if np.sum(free) == 0:
            # avoid returning None, None
            # return None, None
            pix = (obj_mask.shape[0] // 2, obj_mask.shape[1] // 2)
        else:
            pix = utils.sample_distribution(np.float32(free))
        pos = utils.pix_to_xyz(pix, hmap, self.bounds, self.pix_size)
        pos = (pos[0], pos[1], obj_size[2] / 2)
        theta = np.random.rand() * 2 * np.pi
        rot = utils.eulerXYZ_to_quatXYZW((0, 0, theta))
        return pos, rot

    def get_lang_goal(self):
        if len(self.lang_goals) == 0:
            return self.task_completed_desc
        else:
            return self.lang_goals[0]

    def get_reward(self):
        return float(self._rewards)

    # -------------------------------------------------------------------------
    # Helper Functions
    # -------------------------------------------------------------------------

    def fill_template(self, template, replace):
        """Read a file and replace key strings."""
        full_template_path = os.path.join(self.assets_root, template)
        with open(full_template_path, 'r') as file:
            fdata = file.read()
        for field in replace:
            for i in range(len(replace[field])):
                fdata = fdata.replace(f'{field}{i}', str(replace[field][i]))
        alphabet = string.ascii_lowercase + string.digits
        rname = ''.join(random.choices(alphabet, k=16))
        tmpdir = tempfile.gettempdir()
        template_filename = os.path.split(template)[-1]
        fname = os.path.join(tmpdir, f'{template_filename}.{rname}')
        with open(fname, 'w') as file:
            file.write(fdata)
        return fname

    def get_random_size(self, min_x, max_x, min_y, max_y, min_z, max_z):
        """Get random box size."""
        size = np.random.rand(3)
        size[0] = size[0] * (max_x - min_x) + min_x
        size[1] = size[1] * (max_y - min_y) + min_y
        size[2] = size[2] * (max_z - min_z) + min_z
        return tuple(size)

    def color_random_brown(self, obj):
        shade = np.random.rand() + 0.5
        color = np.float32([shade * 156, shade * 117, shade * 95, 255]) / 255
        p.changeVisualShape(obj, -1, rgbaColor=color)

  """""
  
  # Environment Class
  def add_object(self, urdf, pose, category='rigid'):
    """List of (fixed, rigid, or deformable) objects in env."""
    fixed_base = 1 if category == 'fixed' else 0
    obj_id = pybullet_utils.load_urdf(
        p,
        os.path.join(self.assets_root, urdf),
        pose[0],
        pose[1],
        useFixedBase=fixed_base)
    self.obj_ids[category].append(obj_id)
    return obj_id
"""

=========
Note that the objects need to obey physics and not collide with each other, and the object goal poses need to be above the table with lower bound x=0.25, y=-0.5 and upper bound x=0.75, y=0.5. When there are multiple objects for a multi-step pick-and-place task, there are often multiple subgoals. Once the task and environment are generated, an agent with a pick and place primitive will follow the defined goal to accomplish the tasks. 

Additionally, make sure you understand and summarize the ``self.goals`` variables, which has a list of 8-tuple with (objs, matches, targ_poses, replace, rotations, metric, params, step_max_reward, symmetries).
- objs (List of obj_id): object ID.
- matches (Binary Matrix): a binary matrix that denotes which object is matched with which target. This matrix has dimension len(objs) x len(targs).
- targ_poses (List of Poses [(translation, rotation)] ): a list of target poses of tuple (translation, rotation). 
- replace (Boolean): whether each object can match with one unique target. This is important if we have one target and multiple objects. If it's set to be false, then any object matching with the target will satisfy.
- rotations (Boolean): whether the placement action has a rotation degree of freedom. 
- metric (`pose` or `zone`): `pose` or `zone` that the object needs to be transported to. Example: `pose`. 
- params (List of (zone_target, zone_size)): a list of (zone_target, zone_size) for each zone if the metric is `zone`. 
- step_max_reward (float): the total reward of matching all the objects with all the target poses. It is not dependent on the number of objects but dependent on the number of goals. 
- symmetries: the radians that the object is symmetric around z axis.
- language_goal: the low-level language instructions that denote the goal of this step.
 


>>> Answer: 
Yes, I understand the provided APIs and their intended usage. Here's a summary of my understanding:

**Task Class:**

The `Task` class defines the core logic for managing a manipulation task, including reward calculation, completion criteria, and oracle agent behavior.  It handles goal setting, progress tracking, and interaction with the PyBullet environment (`env`).

**Key Components and Understanding:**

* **Environment Interaction:**  The `Task` class interacts with the PyBullet environment through methods like `add_object` (in the environment class) to add objects, `p.getBasePositionAndOrientation` to get object poses, and visual shape modification functions.
* **End Effector:**  The task uses a suction-based end effector (`self.ee = Suction`).
* **Pick and Place Primitive:** The task utilizes a `PickPlace` primitive for actions.
* **Oracle Agent:** The `oracle` method provides an expert policy for demonstration generation. It uses perfect information (RGB-D, segmentation masks) to select pick and place poses.  The oracle prioritizes picking objects farthest from their nearest target.
* **Reward Function (`reward`):**  Calculates the reward based on the specified metric ('pose' or 'zone').  The 'pose' metric checks if object poses match target poses within defined tolerances (`pos_eps`, `rot_eps`). The 'zone' metric calculates the proportion of object points within designated zones.
* **Task Completion (`done`):**  The task is considered done when all goals are achieved (`len(self.goals) == 0`) or the cumulative reward exceeds 0.99.
* **Helper Functions:**  The class includes helper functions for generating random poses, checking pose matching (`is_match`), processing templates, and generating random sizes.  These functions streamline task definition and setup.
* **`self.goals` Structure:** This variable is crucial. It's a list where each element represents a subgoal. Each subgoal is an 8-tuple:

    1. **`objs`:** A list of object IDs involved in the current subgoal.
    2. **`matches`:** A binary matrix indicating which object should be matched with which target pose.  Rows correspond to objects, columns to targets.
    3. **`targs` (or `targ_poses`):** A list of target poses (position, orientation quaternions) for the objects in the current subgoal.
    4. **`replace`:** A boolean flag. If `False`, each object can only match with one unique target.  If `True`, multiple objects can match the same target.
    5. **`rotations`:** A boolean flag indicating whether the placement action considers rotations.
    6. **`metric`:**  The metric used for evaluating the subgoal ('pose' or 'zone').
    7. **`params`:** Additional parameters specific to the metric. For 'zone', it's a list of (zone_pose, zone_size) tuples.
    8. **`step_max_reward`:** The maximum reward achievable for the current subgoal.


**Workspace and Constraints:**

The code defines workspace boundaries (`self.bounds`) and a pixel size (`self.pix_size`) for converting between pixel coordinates and Cartesian coordinates.  The code ensures that generated poses are within these bounds and that objects do not collide. The lower bound for the table is x=0.25, y=-0.5 and the upper bound is x=0.75, y=0.5.

**Multi-Step Tasks and Subgoals:**

The `self.goals` list allows for defining multi-step pick-and-place tasks. Each element in the list represents a subgoal. The agent progresses through these subgoals sequentially, receiving rewards for completing each step.

**Agent and Primitive:**

The task assumes an agent using a `PickPlace` primitive. The oracle agent demonstrates how this primitive can be used to achieve the defined goals.


This detailed understanding of the APIs and the `self.goals` structure is essential for implementing the "stack-balls-on-cylinder" task correctly. I'm ready to proceed with the code implementation.


================= Error Book Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-on-cylinder". Here are some runtime errors that you do not want to make. Please confirm that you understand these runtime errors.

"""
- environment.py, line 338, in info
    pos, rot = p.getBasePositionAndOrientation(obj_id)
TypeError: an integer is required (got type NoneType)

- task.py, line 118, in act
    objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]
IndexError: list index out of range

- task.py, line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
TypeError: 'float' object is not subscriptable

- task.py", line 315, in is_match
  rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]

- utils.py", line 280, in quatXYZW_to_eulerXYZ
  quaternion_wxyz = np.array([q[3], q[0], q[1], q[2]])
IndexError: tuple index out of range

- pallet_pose = self.get_random_pose(env, pallet_size)
pallet_surface_height = pallet_pose[0][2]
TypeError: 'NoneType' object is not subscriptable

- No such file or directory: './cliport/environments/assets/circle/circle-template.urdf'

- No such file or directory: './cliport/environments/assets/block/block-template.urdf'

- task.py", line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
IndexError: invalid index to scalar variable.

-TypeError: get_random_size() missing 4 required positional arguments: 'min_y', 'max_y', 'min_z', and 'max_z' 

- task.py", line 195, in reward
    obj_pts, zones = params
TypeError: cannot unpack non-iterable NoneType object

-  environment.py", line 230, in step
    reward, info = self.task.reward() if action is not None else (0, {})
  File "task.py", line 200, in reward
    pts = obj_pts[obj_id]
IndexError: arrays used as indices must be of integer (or boolean) type

- generated_task.py", line 41, in reset
    utils.COLORS['green'], utils.COLORS['blue'], utils.COLORS['light blue'],
KeyError: 'light blue'

- environment.py", line 195, in reset
    self.task.reset(self)
  File "<string>", line 38, in reset
TypeError: can only concatenate str (not "list") to str

- environment.py", line 195, in reset
  object_shape = np.random.choice(object_shapes)
  in numpy.random.mtrand.RandomState.choice
ValueError: a must be 1-dimensional

- No such file or directory: 'assets/box-template/box-template.urdf'

- line 38, in reset.py
{'HALF': box_size / 2}
TypeError: unsupported operand type(s) for /: 'tuple' and 'int'. box_size is a tuple not a float.

- line 38, in reset.py
IndexError: tuple index out of range
box_pose = (pallet_pose[0], pallet_pose[1], pallet_pose[2] + np.sum(box_sizes[:i+1]))

- task.py", line 338, in fill_template
    for i in range(len(replace[field])):
TypeError: object of type 'float' has no len().

- task.py", line 325, in get_random_pose
    pos = (pos[0], pos[1], obj_size[2] / 2)
IndexError: tuple index out of range

- task.py", line 206, in reward
    for zone_idx, (zone_pose, zone_size) in enumerate(zones):
TypeError: 'NoneType' object is not iterable

- task.py",
ball_pose = self.get_random_pose(env, ball_size)
ball_pose[0][2] += 0.02
TypeError: 'tuple' object does not support item assignment
"""


You do not want to make mistakes such as
- using assets (urdfs) that do not exist
- use ambiguous language descriptions as goals. For instance, "place the colored blocks into the matching colored bowls" with one goal and sparse reward as the task instead of adding subgoal "place blue block into blue bowl" and give continuous reward. 
- `matches` in the goal has wrong dimensions. It should have the same dimensions as number of objects (N) multiplied by the number of goal poses (M). Usually it is N by M.
- have vector dimension problem such as `np.random.choice(box_size)` or `box_size / 2` where `box_size` is a tuple and not an int
- make too large an object for stacking or make the task objects invisible for picking. 
- accessing index out of bound `pallet_pose[2]` for `pallet_pose`.  `pallet_pose=get_random_pose` returns a tuple (translation, rotation). It does not have 3rd component. Similarly accessing `container_pose[2]` or `box_pose[2]` would cause errors as well. Since it's a tuple, try to modify it in-place will also trigger errors.
- forget to replace str using `fill_template()` for urdfs with template such as `cylinder-template.urdf`. `ball-template.urdf`, `line-template.urf`. 
- use `self.ee = Spatula()` as a function when doing pushing tasks, which is incorrect. It should be `self.ee = Spatula`.
- forget to compute target poses `targ_poses` for matching. Do not use object IDs for poses.
- change colors of complex objects such as `zone`. You can only change color of teomplate primitive such as `cylinder-template`.
- mistakenly use `random_pose` for target pose. Design target poses based on task objectives.
- add only one or fewer language goals which causes language-motion inconsistentcy. Note that the language goals usually are the same number as the pick and place goals.


>>> Answer: 
Yes, I understand the runtime errors listed and the additional points you've made about avoiding mistakes in task generation. I will be mindful of these issues when writing the code for the "stack-balls-on-cylinder" task.  I will pay particular attention to:

* **File Paths and Existence:** Verify that all URDF files exist in the correct locations.
* **Clear Language Goals:**  Provide specific and unambiguous language descriptions for each subgoal, avoiding vague phrasing.
* **Matches Dimensions:** Ensure the `matches` array has the correct dimensions (N x M), reflecting the number of objects and target poses.
* **Vector Operations:**  Handle vector and scalar operations correctly, paying attention to the dimensions of variables like `box_size`.
* **Object Sizes and Visibility:**  Keep object sizes reasonable for stacking and ensure they are visible for picking.
* **Pose Indexing:** Access pose components correctly, remembering that `get_random_pose` returns a (position, rotation) tuple.  Avoid in-place modification of tuples.
* **Template Filling:** Use `fill_template()` to replace placeholders in URDFs with actual values.
* **Spatula Initialization:** Initialize the spatula correctly using `self.ee = Spatula`, not as a function call.
* **Target Pose Calculation:** Explicitly calculate target poses (`targ_poses`) based on task objectives, not object IDs.
* **Color Changes:** Only change colors of primitive template objects, not complex objects like zones.
* **Random Poses vs. Target Poses:** Use `random_pose` appropriately and design specific target poses for the task.
* **Sufficient Language Goals:** Provide enough language goals to match the number of pick-and-place actions, ensuring language-motion consistency.


By addressing these points, I aim to avoid the listed runtime errors and create a robust and functional "stack-balls-on-cylinder" task.


================= Code Generation!

>>> Prompt: 
Now I will provide you some reference code and you can write the code for the task "stack-balls-on-cylinder".


"""
import os

import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils


class PackingShapes(Task):
    """pick up randomly sized shapes and place them tightly into a container."""

    def __init__(self):
        super().__init__()
        self.max_steps = 1
        self.homogeneous = False

        self.lang_template = "pack the {obj} in the brown box"
        self.task_completed_desc = "done packing shapes."
        self.additional_reset()


    def reset(self, env):
        super().reset(env)

        # Shape Names:
        shapes = utils.assembling_kit_shapes

        n_objects = 5
        if self.mode == 'train':
            obj_shapes = np.random.choice(self.train_set, n_objects, replace=False)
        else:
            if self.homogeneous:
                obj_shapes = [np.random.choice(self.test_set, replace=False)] * n_objects
            else:
                obj_shapes = np.random.choice(self.test_set, n_objects, replace=False)

        # Shuffle colors to avoid always picking an object of the same color
        colors, color_names = utils.get_colors(mode=self.mode)

        # Add container box.
        zone_size = self.get_random_size(0.1, 0.15, 0.1, 0.15, 0.05, 0.05)
        zone_pose = self.get_random_pose(env, zone_size)
        container_template = 'container/container-template.urdf'
        replace = {'DIM': zone_size, 'HALF': (zone_size[0] / 2, zone_size[1] / 2, zone_size[2] / 2)}
        # IMPORTANT: REPLACE THE TEMPLATE URDF with `fill_template`
        container_urdf = self.fill_template(container_template, replace)
        env.add_object(container_urdf, zone_pose, 'fixed')

        # Add objects.
        objects = []
        template = 'kitting/object-template.urdf'
        for i in range(n_objects):
            shape = obj_shapes[i]

            # x, y, z dimensions for the asset size
            size = (0.08, 0.08, 0.02)
            pose= self.get_random_pose(env, size)
            fname = f'{shape:02d}.obj'
            fname = os.path.join(self.assets_root, 'kitting', fname)
            scale = [0.003, 0.003, 0.001]  # .0005
            replace = {'FNAME': (fname,),
                       'SCALE': scale,
                       'COLOR': colors[i]}

            # IMPORTANT: REPLACE THE TEMPLATE URDF
            urdf = self.fill_template(template, replace)
            block_id = env.add_object(urdf, pose)
            objects.append(block_id)

        # Pick the first shape.
        num_objects_to_pick = 1
        for i in range(num_objects_to_pick):
            # IMPORTANT: Specify (obj_pts, [(zone_pose, zone_size)]) for target `zone`. obj_pts is a dict
            language_goal = self.lang_template.format(obj=shapes[obj_shapes[i]])
            self.add_goal(objs=[objects[i]], matches=np.int32([[1]]), targ_poses=[zone_pose], replace=False,
                rotations=True, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1 / num_objects_to_pick,
                language_goal=language_goal)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p


class PlaceRedInGreen(Task):
    """pick up the red blocks and place them into the green bowls amidst other objects."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "put the red blocks in a green bowl"
        self.task_completed_desc = "done placing blocks in bowls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)
        n_bowls = np.random.randint(1, 4)
        n_blocks = np.random.randint(1, n_bowls + 1)

        # Add bowls.
        # x, y, z dimensions for the asset size
        bowl_size = (0.12, 0.12, 0)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_poses = []
        for _ in range(n_bowls):
            bowl_pose = self.get_random_pose(env, obj_size=bowl_size)
            env.add_object(urdf=bowl_urdf, pose=bowl_pose, category='fixed')
            bowl_poses.append(bowl_pose)

        # Add blocks.
        # x, y, z dimensions for the asset size
        blocks = []
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'
        for _ in range(n_blocks):
            block_pose = self.get_random_pose(env, obj_size=block_size)
            block_id = env.add_object(block_urdf, block_pose)
            blocks.append(block_id)

        # Goal: each red block is in a different green bowl.
        self.add_goal(objs=blocks, matches=np.ones((len(blocks), len(bowl_poses))), targ_poses=bowl_poses, replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1, language_goal=self.lang_template)

        # Colors of distractor objects.
        bowl_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'green']
        block_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'red']

        # Add distractors.
        n_distractors = 0
        while n_distractors < 6:
            is_block = np.random.rand() > 0.5
            urdf = block_urdf if is_block else bowl_urdf
            size = block_size if is_block else bowl_size
            colors = block_colors if is_block else bowl_colors
            pose = self.get_random_pose(env, obj_size=size)
            color = colors[n_distractors % len(colors)]

            obj_id = env.add_object(urdf, pose, color=color)
            n_distractors += 1
"""
"""
import numpy as np
from cliport.tasks import primitives
from cliport.tasks.grippers import Spatula
from cliport.tasks.task import Task
from cliport.utils import utils


class SweepingPiles(Task):
    """Push piles of small objects into a target goal zone marked on the tabletop."""

    def __init__(self):
        super().__init__()
        self.max_steps = 20
        self.lang_template = "push the pile of blocks into the green square"
        self.task_completed_desc = "done sweeping."
        self.primitive = primitives.push
        self.ee = Spatula
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add goal zone.
        zone_size = (0.12, 0.12, 0)
        zone_pose = self.get_random_pose(env, zone_size)
        env.add_object('zone/zone.urdf', zone_pose, 'fixed')

        # Add pile of small blocks with `make_piles` function
        obj_ids = self.make_piles(env)

        # Add goal
        self.add_goal(objs=obj_ids, matches=np.ones((50, 1)), targ_poses=[zone_pose], replace=True,
                rotations=False, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1, language_goal=self.lang_template)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p

class StackBlockPyramid(Task):
    """Build a pyramid of colored blocks in a color sequence"""

    def __init__(self):
        super().__init__()
        self.max_steps = 12
        self.lang_template = "make the {row} row with {blocks}"
        self.task_completed_desc = "done stacking block pyramid."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add base.
        base_size = (0.05, 0.15, 0.005)
        base_urdf = 'stacking/stand.urdf'
        base_pose = self.get_random_pose(env, base_size)
        env.add_object(base_urdf, base_pose, category='fixed')

        # Block colors.
        colors = [
            utils.COLORS['purple'], utils.COLORS['blue'], utils.COLORS['green'],
            utils.COLORS['yellow'], utils.COLORS['orange'], utils.COLORS['red']
        ]

        # Add blocks.
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'

        objs = []
        for i in range(6):
            block_pose = self.get_random_pose(env, block_size)
            block_id = env.add_object(block_urdf, block_pose, color=colors[i])
            objs.append(block_id)

        # IMPORTANT Associate placement locations for goals.
        place_pos = [(0, -0.05, 0.03), (0, 0, 0.03),
                     (0, 0.05, 0.03), (0, -0.025, 0.08),
                     (0, 0.025, 0.08), (0, 0, 0.13)]
        targs = [(utils.apply(base_pose, i), base_pose[1]) for i in place_pos]

        # Goal: blocks are stacked in a pyramid (bottom row: green, blue, purple).
        language_goal = self.lang_template.format(blocks="the green, blue and purple blocks", row="bottom")
        self.add_goal(objs=objs[:3], matches=np.ones((3, 3)), targ_poses=targs[:3], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 2, symmetries=[np.pi/2]*3, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (middle row: yellow, orange).
        language_goal = self.lang_template.format(blocks="the yellow and orange blocks", row="middle")      
        self.add_goal(objs=objs[3:5], matches=np.ones((2, 2)), targ_poses=targs[3:5], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 3, symmetries=[np.pi/2]*2, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (top row: red).
        language_goal = self.lang_template.format(blocks="the red block", row="top")
        self.add_goal(objs=objs[5:], matches=np.ones((1, 1)), targ_poses=targs[5:], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 6, symmetries=[np.pi/2]*1, language_goal=language_goal)
"""



Do not use libraries, functions, and assets that you don't know. For each object, try to describe its color, size, category in the task first before you write the code. You do not need extra helper functions. Comment the code liberally to explain what each piece does and why it's written that way. If you have only one goal, `step_max_reward` in `add_goal` should be 1. Use functions `make_piles` and `make_ropes` for creating piles and cables. To use spatula together with the push primitives, import the libraries 
"""
from cliport.tasks import primitives;
from cliport.tasks.grippers import Spatula
"""
and then use `self.primitive = primitives.push` and `self.ee = Spatula`.
Note that the number of language goals usually match the number of motion goals, since they should correspond to each other.

Now write the code for the task "stack-balls-on-cylinder" in python code block starting with ```python.  Reminder: {'task-name': 'stack-balls-on-cylinder', 'task-description': 'Stack three different colored balls (red, green, and blue) on top of a vertically placed cylinder.', 'assets-used': ['ball/ball-template.urdf', 'cylinder/cylinder-template.urdf']} 


>>> Answer: 
```python
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils

class StackBallsOnCylinder(Task):
    """Stack three different colored balls (red, green, and blue) on top of a vertically placed cylinder."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "stack the {color} ball on the cylinder"
        self.task_completed_desc = "done stacking balls on cylinder."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Cylinder: Gray, radius=0.03, height=0.1
        cylinder_size = (0.03, 0.1)  # Radius, height
        cylinder_template = 'cylinder/cylinder-template.urdf'
        cylinder_pose = self.get_random_pose(env, cylinder_size)
        cylinder_urdf = self.fill_template(cylinder_template, {'DIM': cylinder_size})
        env.add_object(cylinder_urdf, cylinder_pose, 'fixed')

        # Balls: red, green, blue, radius=0.03
        ball_size = (0.03,) # Radius
        ball_template = 'ball/ball-template.urdf'
        colors = [utils.COLORS['red'], utils.COLORS['green'], utils.COLORS['blue']]
        ball_ids = []

        ball_poses = []
        for i in range(3):
            ball_pose = self.get_random_pose(env, ball_size)
            ball_urdf = self.fill_template(ball_template, {'DIM': ball_size, 'COLOR': colors[i]})
            ball_id = env.add_object(ball_urdf, ball_pose)
            ball_ids.append(ball_id)

            # Calculate target poses on top of the cylinder.
            target_z = cylinder_pose[0][2] + cylinder_size[1] + ball_size[0] * (i+1) # Height of cylinder + radius of each stacked ball
            target_pose = (cylinder_pose[0][:2] + (target_z,), cylinder_pose[1])
            ball_poses.append(target_pose)

        # Goal: stack balls on cylinder in red, green, blue order.
        for i, ball_id in enumerate(ball_ids):
            language_goal = self.lang_template.format(color=['red', 'green', 'blue'][i])
            self.add_goal(objs=[ball_id], matches=np.ones((1, 1)), targ_poses=[ball_poses[i]], replace=False,
                          rotations=True, metric='pose', params=None, step_max_reward=1/3, language_goal=language_goal) # 1/3 since 3 goals
```

================= TRIAL: 6

================= Task and Asset Design!

>>> Prompt: 
You are an AI in robot simulation code and task design. I will provide you some example tasks, code implementation, and some guidelines for how to generate tasks and then you will help me generate a new task. My goal is to design diverse and feasible tasks for tabletop manipulation. I will first ask you to describe the task in natural languages and then will let you write the code for it. 

=========
Here are all the assets. Use only these assets in the task and code design. 
"""
insertion/:
ell.urdf  fixture.urdf

bowl/:
bowl.urdf

box/:
box-template.urdf

stacking/:
block.urdf  stand.urdf

zone/:
zone.obj  zone.urdf

pallet/:
pallet.obj  pallet.urdf

ball/:
ball-template.urdf

cylinder/:
cylinder-template.urdf

bowl/:
bowl.urdf

# assets not for picking
corner/:
corner-template.urdf

line/:
single-green-line-template.urdf

container/:
container-template.urdf
"""
 
=========
Here are some examples of good tasks. Try to learn from these structures but avoid overlapping wiht them.

{"assets-used": ["zone/zone.urdf", "block/small.urdf"],
 "task-description": "Push piles of small objects into a target goal zone marked on the tabletop.",
 "task-name": "sweeping-piles"}

{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "Place all blocks of a specified color in a bowl of specified color.",
 "task-name": "put-block-in-bowl"}
 
{"assets-used": ["insertion/ell.urdf", "insertion/fixture.urdf"],
 "task-description": "pick up the L-shaped red block and place it into the L-shaped fixture.",
 "task-name": "block-insertion"}
 
{"assets-used": ["kitting/kit.urdf", "kitting/object-template.urdf"],
 "task-description": "pick up different objects and arrange them on a board marked with corresponding silhouettes.",
 "task-name": "assembling-kits"}
 
{"assets-used": ["pallet/pallet.urdf", "box/box-template.urdf"],
 "task-description": "pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.",
 "task-name": "palletizing-boxes"}
 
{"assets-used": ["stacking/stand.urdf", "stacking/block.urdf"],
 "task-description": "sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.",
 "task-name": "stack-block-pyramid"}
 
{"assets-used": ["container/container-template.urdf", "box/box-template.urdf"],
 "task-description": "pick up randomly sized boxes and place them tightly into a container.",
 "task-name": "packing-boxes"}
 
{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "pick up the red blocks and place them into the green bowls amidst other objects.",
 "task-name": "place-red-in-green"}
 
{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

=========
Here are some tasks that you have come up with before. Try to learn from these structures but avoid overlapping with these tasks. For instance, `bowl_ball_placement` and `sort_balls_in_bowls` are the same task. `pile_boxes_in_corner` and `stack_blocks_into_pallet` are similar tasks, `align-cylinder-in-corner` and `align-cylinder-corner` are similar.
- sweeping-piles: {'assets-used': ['zone/zone.urdf', 'block/small.urdf'], 'task-description': 'push piles of small objects into a target goal zone marked on the tabletop.', 'task-name': 'sweeping-piles'}
- place-red-in-green: {'assets-used': ['bowl/bowl.urdf', 'stacking/block.urdf'], 'task-description': 'pick up the red blocks and place them into the green bowls amidst other objects.', 'task-name': 'place-red-in-green'}
- align-box-corner: {'assets-used': ['box/box-template.urdf', 'corner/corner-template.urdf'], 'task-description': 'pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..', 'task-name': 'align-box-corner'}
- stack-block-pyramid: {'assets-used': ['stacking/stand.urdf', 'stacking/block.urdf'], 'task-description': 'sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.', 'task-name': 'stack-block-pyramid'}
- palletizing-boxes: {'assets-used': ['pallet/pallet.urdf', 'box/box-template.urdf'], 'task-description': 'pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.', 'task-name': 'palletizing-boxes'}
- assembling-kits: {'assets-used': ['kitting/kit.urdf', 'kitting/object-template.urdf'], 'task-description': 'pick up different objects and arrange them on a board marked with corresponding silhouettes.', 'task-name': 'assembling-kits'}
- packing-boxes: {'assets-used': ['container/container-template.urdf', 'box/box-template.urdf'], 'task-description': 'pick up randomly sized boxes and place them tightly into a container.', 'task-name': 'packing-boxes'}
- manipulating-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'rearrange a deformable rope such that it connects the two endpoints of a 3-sided square.', 'task-name': 'manipulating-rope'}
- align-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'manipulate a deformable rope to connect its end-points between two corners of a 3-sided square.', 'task-name': 'align-rope'}





=========
Here are some bad example task instances with explanations.
{
    "task_name": "sort-color-blocks",
    "task_descriptions": "Pick up differently colored blocks and place them into separate bowls of matching color."
    "assets-used": ["bowl.urdf", "box/box-template.urdf],
}
reasons: not interesting because it overlaps with the current task `put-block-in-bowl`.

{
    "task-name": "guided-ball-maze",
    "task-description": "Navigate a small ball through a maze by tilting the maze board to reach the target zone.",
    "assets-used": ["zone-template.urdf", "square-template.urdf", "ball.urdf", "maze.urdf"],
}
reasons: the language descriptions are too ambiguous. Navigation is also hard to complete. Also maze.urf does not exist.

{
    "task-name": "insert_cylinder_in_sphere",
    "task-description": "Pick up the cylinder and insert it into the sphere with an opening on top.",
    "assets-used": ["cylinder/cylinder-template.urdf", "sphere/sphere-template.urdf"],
}
reasons: this task does not make sense. The sphere does not have an opening on top, and you cannot insert a cylinder into a sphere. Similarly tasks like `insert-ball-into-cylinder` and `cylinder-box-insertion` are invalid.

{
    "task-name": "ball-box-obstacle-course",
    "task-description": "Navigate a ball through an obstacle course created by randomly placed boxes and finally place it inside a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: Navigate the ball is not related to tabletop manipulation tasks.

{
    "task-name": "ball-in-box",
    "task-description": "Use a cable to guide a ball into an open box.",
    "assets-used": ["cable/cable.urdf", "ball/ball-template.urdf", "box/box-template.urdf"]
}
reasons: This task is too hard since it involves interaction of the cable and the ball and cannot be easily completed.

{
    "task-name": "ball-in-container",
    "task-description": "Use the spatula to lift a ball over a wall of boxes and drop it into a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: The only action primitives as pick and place. One cannot use a spatula to lift an object.

{
    "task-name": "line-ball-sorting",
    "task-description": "Move balls of different colors along a single green line, placing each ball in a designated colored box at the end of the line. The challenge includes precision in maintaining the ball on the line and the correct identification of the box color corresponding to each ball.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "line/single-green-line-template.urdf"]
}
reasons: Piling or stacking balls are physically infeasible in the simulation.



=========
Now please describe the new task in natural languages and explain its novelty and challenges. Format the answer in a python dictionary with keys "task-name" and value type string, "task-description" (one specific sentence) and value type string, and "assets-used" and value type list of strings. Note that

- Do not use assets that are not in the list above. 
- Tasks that have more colors and shapes are interesting.
- Be as specific as possible about the number, shape, and color of each asset in the task descriptions. 
- The task need to obey physics and remain feasible.





>>> Answer: 
```python
{
    "task-name": "stack-balls-in-bowls",
    "task-description": "Pick up three different colored balls (red, green, and blue) and stack them inside a correspondingly colored bowl (red, green, and blue).",
    "assets-used": ["ball/ball-template.urdf", "bowl/bowl.urdf"]
}
```

**Novelty and Challenges:**

This task combines stacking and color matching, creating a more complex challenge than simply placing objects in containers.  While stacking blocks is common, stacking balls introduces instability and requires more precise manipulation due to their round shape. The color matching adds another layer of complexity, requiring the robot to differentiate and correctly associate balls and bowls based on their color.  Successfully completing this task demonstrates a higher level of dexterity and planning compared to simpler pick-and-place tasks.


================= API Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-in-bowls". Here are some APIs that are defined. Please confirm that you understand these APIs.

"""
class Task():
    """Base Task class."""

    def __init__(self):
        self.ee = Suction
        self.mode = 'train'
        self.sixdof = False
        self.primitive = primitives.PickPlace()
        self.oracle_cams = cameras.Oracle.CONFIG

        # Evaluation epsilons (for pose evaluation metric).
        self.pos_eps = 0.01
        self.rot_eps = np.deg2rad(15)

        # Workspace bounds.
        self.pix_size = 0.003125
        self.bounds = np.array([[0.25, 0.75], [-0.5, 0.5], [0, 0.3]])
        self.zone_bounds = np.copy(self.bounds)

        self.goals = []
        self.lang_goals = []
        self.task_completed_desc = "task completed."
        self.progress = 0
        self._rewards = 0
        self.assets_root = None

    def reset(self, env):
        if not self.assets_root:
            raise ValueError('assets_root must be set for task, '
                             'call set_assets_root().')
        self.goals = []
        self.lang_goals = []
        self.progress = 0  # Task progression metric in range [0, 1].
        self._rewards = 0  # Cumulative returned rewards.

    # -------------------------------------------------------------------------
    # Oracle Agent
    # -------------------------------------------------------------------------

    def oracle(self, env):
        """Oracle agent."""
        OracleAgent = collections.namedtuple('OracleAgent', ['act'])

        def act(obs, info):
            """Calculate action."""

            # Oracle uses perfect RGB-D orthographic images and segmentation masks.
            _, hmap, obj_mask = self.get_true_image(env)

            # Unpack next goal step.
            objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]

            # Match objects to targets without replacement.
            if not replace:

                # Modify a copy of the match matrix.
                matches = matches.copy()

                # Ignore already matched objects.
                for i in range(len(objs)):
                    object_id, (symmetry, _) = objs[i]
                    pose = p.getBasePositionAndOrientation(object_id)
                    targets_i = np.argwhere(matches[i, :]).reshape(-1)
                    for j in targets_i:
                        if self.is_match(pose, targs[j], symmetry):
                            matches[i, :] = 0
                            matches[:, j] = 0

            # Get objects to be picked (prioritize farthest from nearest neighbor).
            nn_dists = []
            nn_targets = []
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                xyz, _ = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                if len(targets_i) > 0:
                    targets_xyz = np.float32([targs[j][0] for j in targets_i])
                    dists = np.linalg.norm(
                        targets_xyz - np.float32(xyz).reshape(1, 3), axis=1)
                    nn = np.argmin(dists)
                    nn_dists.append(dists[nn])
                    nn_targets.append(targets_i[nn])

                # Handle ignored objects.
                else:
                    nn_dists.append(0)
                    nn_targets.append(-1)
            order = np.argsort(nn_dists)[::-1]

            # Filter out matched objects.
            order = [i for i in order if nn_dists[i] > 0]

            pick_mask = None
            for pick_i in order:
                pick_mask = np.uint8(obj_mask == objs[pick_i][0])

                # Erode to avoid picking on edges.
                # pick_mask = cv2.erode(pick_mask, np.ones((3, 3), np.uint8))

                if np.sum(pick_mask) > 0:
                    break

            # Trigger task reset if no object is visible.
            if pick_mask is None or np.sum(pick_mask) == 0:
                self.goals = []
                self.lang_goals = []
                print('Object for pick is not visible. Skipping demonstration.')
                return

            # Get picking pose.
            pick_prob = np.float32(pick_mask)
            pick_pix = utils.sample_distribution(pick_prob)
            # For "deterministic" demonstrations on insertion-easy, use this:
            # pick_pix = (160,80)
            pick_pos = utils.pix_to_xyz(pick_pix, hmap,
                                        self.bounds, self.pix_size)
            pick_pose = (np.asarray(pick_pos), np.asarray((0, 0, 0, 1)))

            # Get placing pose.
            targ_pose = targs[nn_targets[pick_i]]
            obj_pose = p.getBasePositionAndOrientation(objs[pick_i][0])
            if not self.sixdof:
                obj_euler = utils.quatXYZW_to_eulerXYZ(obj_pose[1])
                obj_quat = utils.eulerXYZ_to_quatXYZW((0, 0, obj_euler[2]))
                obj_pose = (obj_pose[0], obj_quat)
            world_to_pick = utils.invert(pick_pose)
            obj_to_pick = utils.multiply(world_to_pick, obj_pose)
            pick_to_obj = utils.invert(obj_to_pick)
            place_pose = utils.multiply(targ_pose, pick_to_obj)

            # Rotate end effector?
            if not rotations:
                place_pose = (place_pose[0], (0, 0, 0, 1))

            place_pose = (np.asarray(place_pose[0]), np.asarray(place_pose[1]))

            return {'pose0': pick_pose, 'pose1': place_pose}

        return OracleAgent(act)

    # -------------------------------------------------------------------------
    # Reward Function and Task Completion Metrics
    # -------------------------------------------------------------------------

    def reward(self):
        """Get delta rewards for current timestep.

        Returns:
          A tuple consisting of the scalar (delta) reward, plus `extras`
            dict which has extra task-dependent info from the process of
            computing rewards that gives us finer-grained details. Use
            `extras` for further data analysis.
        """
        reward, info = 0, {}

        # Unpack next goal step.
        objs, matches, targs, _, _, metric, params, max_reward = self.goals[0]

        # Evaluate by matching object poses.
        if metric == 'pose':
            step_reward = 0
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                pose = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                for j in targets_i:
                    target_pose = targs[j]
                    if self.is_match(pose, target_pose, symmetry):
                        step_reward += max_reward / len(objs)
                        print(f"object {i} match with target {j} rew: {step_reward}")
                        break

        # Evaluate by measuring object intersection with zone.
        elif metric == 'zone':
            zone_pts, total_pts = 0, 0
            obj_pts, zones = params
            for zone_idx, (zone_pose, zone_size) in enumerate(zones):

                # Count valid points in zone.
                for obj_idx, obj_id in enumerate(obj_pts):
                    pts = obj_pts[obj_id]
                    obj_pose = p.getBasePositionAndOrientation(obj_id)
                    world_to_zone = utils.invert(zone_pose)
                    obj_to_zone = utils.multiply(world_to_zone, obj_pose)
                    pts = np.float32(utils.apply(obj_to_zone, pts))
                    if len(zone_size) > 1:
                        valid_pts = np.logical_and.reduce([
                            pts[0, :] > -zone_size[0] / 2, pts[0, :] < zone_size[0] / 2,
                            pts[1, :] > -zone_size[1] / 2, pts[1, :] < zone_size[1] / 2,
                            pts[2, :] < self.zone_bounds[2, 1]])

                    # if zone_idx == matches[obj_idx].argmax():
                    zone_pts += np.sum(np.float32(valid_pts))
                    total_pts += pts.shape[1]
            step_reward = max_reward * (zone_pts / total_pts)

        # Get cumulative rewards and return delta.
        reward = self.progress + step_reward - self._rewards
        self._rewards = self.progress + step_reward

        # Move to next goal step if current goal step is complete.
        if np.abs(max_reward - step_reward) < 0.01:
            self.progress += max_reward  # Update task progress.
            self.goals.pop(0)
            if len(self.lang_goals) > 0:
                self.lang_goals.pop(0)

        return reward, info

    def done(self):
        """Check if the task is done or has failed.

        Returns:
          True if the episode should be considered a success, which we
            use for measuring successes, which is particularly helpful for tasks
            where one may get successes on the very last time step, e.g., getting
            the cloth coverage threshold on the last alllowed action.
            However, for bag-items-easy and bag-items-hard (which use the
            'bag-items' metric), it may be necessary to filter out demos that did
            not attain sufficiently high reward in external code. Currently, this
            is done in `main.py` and its ignore_this_demo() method.
        """
        return (len(self.goals) == 0) or (self._rewards > 0.99)
        # return zone_done or defs_done or goal_done

    # -------------------------------------------------------------------------
    # Environment Helper Functions
    # -------------------------------------------------------------------------

    def is_match(self, pose0, pose1, symmetry):
        """Check if pose0 and pose1 match within a threshold."""

        # Get translational error.
        diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
        dist_pos = np.linalg.norm(diff_pos)

        # Get rotational error around z-axis (account for symmetries).
        diff_rot = 0
        if symmetry > 0:
            rot0 = np.array(utils.quatXYZW_to_eulerXYZ(pose0[1]))[2]
            rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]
            diff_rot = np.abs(rot0 - rot1) % symmetry
            if diff_rot > (symmetry / 2):
                diff_rot = symmetry - diff_rot

        return (dist_pos < self.pos_eps) and (diff_rot < self.rot_eps)

    def get_random_pose(self, env, obj_size):
        """Get random collision-free object pose within workspace bounds."""

        # Get erosion size of object in pixels.
        max_size = np.sqrt(obj_size[0] ** 2 + obj_size[1] ** 2)
        erode_size = int(np.round(max_size / self.pix_size))

        _, hmap, obj_mask = self.get_true_image(env)

        # Randomly sample an object pose within free-space pixels.
        free = np.ones(obj_mask.shape, dtype=np.uint8)
        for obj_ids in env.obj_ids.values():
            for obj_id in obj_ids:
                free[obj_mask == obj_id] = 0
        free[0, :], free[:, 0], free[-1, :], free[:, -1] = 0, 0, 0, 0
        free = cv2.erode(free, np.ones((erode_size, erode_size), np.uint8))

        # if np.sum(free) == 0:
        #     return None, None

        if np.sum(free) == 0:
            # avoid returning None, None
            # return None, None
            pix = (obj_mask.shape[0] // 2, obj_mask.shape[1] // 2)
        else:
            pix = utils.sample_distribution(np.float32(free))
        pos = utils.pix_to_xyz(pix, hmap, self.bounds, self.pix_size)
        pos = (pos[0], pos[1], obj_size[2] / 2)
        theta = np.random.rand() * 2 * np.pi
        rot = utils.eulerXYZ_to_quatXYZW((0, 0, theta))
        return pos, rot

    def get_lang_goal(self):
        if len(self.lang_goals) == 0:
            return self.task_completed_desc
        else:
            return self.lang_goals[0]

    def get_reward(self):
        return float(self._rewards)

    # -------------------------------------------------------------------------
    # Helper Functions
    # -------------------------------------------------------------------------

    def fill_template(self, template, replace):
        """Read a file and replace key strings."""
        full_template_path = os.path.join(self.assets_root, template)
        with open(full_template_path, 'r') as file:
            fdata = file.read()
        for field in replace:
            for i in range(len(replace[field])):
                fdata = fdata.replace(f'{field}{i}', str(replace[field][i]))
        alphabet = string.ascii_lowercase + string.digits
        rname = ''.join(random.choices(alphabet, k=16))
        tmpdir = tempfile.gettempdir()
        template_filename = os.path.split(template)[-1]
        fname = os.path.join(tmpdir, f'{template_filename}.{rname}')
        with open(fname, 'w') as file:
            file.write(fdata)
        return fname

    def get_random_size(self, min_x, max_x, min_y, max_y, min_z, max_z):
        """Get random box size."""
        size = np.random.rand(3)
        size[0] = size[0] * (max_x - min_x) + min_x
        size[1] = size[1] * (max_y - min_y) + min_y
        size[2] = size[2] * (max_z - min_z) + min_z
        return tuple(size)

    def color_random_brown(self, obj):
        shade = np.random.rand() + 0.5
        color = np.float32([shade * 156, shade * 117, shade * 95, 255]) / 255
        p.changeVisualShape(obj, -1, rgbaColor=color)

  """""
  
  # Environment Class
  def add_object(self, urdf, pose, category='rigid'):
    """List of (fixed, rigid, or deformable) objects in env."""
    fixed_base = 1 if category == 'fixed' else 0
    obj_id = pybullet_utils.load_urdf(
        p,
        os.path.join(self.assets_root, urdf),
        pose[0],
        pose[1],
        useFixedBase=fixed_base)
    self.obj_ids[category].append(obj_id)
    return obj_id
"""

=========
Note that the objects need to obey physics and not collide with each other, and the object goal poses need to be above the table with lower bound x=0.25, y=-0.5 and upper bound x=0.75, y=0.5. When there are multiple objects for a multi-step pick-and-place task, there are often multiple subgoals. Once the task and environment are generated, an agent with a pick and place primitive will follow the defined goal to accomplish the tasks. 

Additionally, make sure you understand and summarize the ``self.goals`` variables, which has a list of 8-tuple with (objs, matches, targ_poses, replace, rotations, metric, params, step_max_reward, symmetries).
- objs (List of obj_id): object ID.
- matches (Binary Matrix): a binary matrix that denotes which object is matched with which target. This matrix has dimension len(objs) x len(targs).
- targ_poses (List of Poses [(translation, rotation)] ): a list of target poses of tuple (translation, rotation). 
- replace (Boolean): whether each object can match with one unique target. This is important if we have one target and multiple objects. If it's set to be false, then any object matching with the target will satisfy.
- rotations (Boolean): whether the placement action has a rotation degree of freedom. 
- metric (`pose` or `zone`): `pose` or `zone` that the object needs to be transported to. Example: `pose`. 
- params (List of (zone_target, zone_size)): a list of (zone_target, zone_size) for each zone if the metric is `zone`. 
- step_max_reward (float): the total reward of matching all the objects with all the target poses. It is not dependent on the number of objects but dependent on the number of goals. 
- symmetries: the radians that the object is symmetric around z axis.
- language_goal: the low-level language instructions that denote the goal of this step.
 


>>> Answer: 
Yes, I understand the provided APIs and their intended usage. Here's a summary of my understanding:

**Task Class:**

The `Task` class defines the base structure and functionality for a manipulation task within a simulated environment (likely PyBullet). It handles aspects like:

* **Action Primitive:** Uses a `PickPlace` primitive, suggesting tasks involve picking up and placing objects.
* **Oracle:** Includes an `oracle` function that provides a demonstration policy using perfect information (RGB-D, segmentation masks). This is useful for generating expert demonstrations for imitation learning.
* **Reward Function:** The `reward` function calculates rewards based on goal completion. It supports two metrics: 'pose' (matching object poses to target poses) and 'zone' (measuring object intersection with a target zone).
* **Task Completion:** The `done` function checks if the task is complete based on goal completion or a reward threshold.
* **Helper Functions:** Provides helper functions for pose matching, random pose generation, language goal retrieval, and other utilities.
* **Goal Structure (`self.goals`):**  This is a crucial component. Each element in `self.goals` represents a sub-goal or a step in a multi-step task.  The 8-tuple structure defines the specifics of each sub-goal:

    1. **`objs`:** A list of object IDs involved in the current sub-goal.
    2. **`matches`:** A binary matrix indicating which object should be matched with which target pose.  Rows correspond to objects, columns to target poses. A '1' at `matches[i, j]` means object `i` should be placed at target pose `j`.
    3. **`targs` (or `targ_poses`):** A list of target poses, each represented as a (position, orientation) tuple.
    4. **`replace`:** A boolean flag. If `False`, each object can only be matched to one unique target.  If `True`, multiple objects can be matched to the same target.
    5. **`rotations`:** A boolean flag. If `True`, the orientation of the placed object is considered in the reward calculation. If `False`, only the position matters.
    6. **`metric`:**  The metric used for evaluating the sub-goal ('pose' or 'zone').
    7. **`params`:** Additional parameters specific to the metric. For 'zone', it's a list of (zone_target, zone_size) tuples.
    8. **`step_max_reward`:** The maximum reward achievable for completing the current sub-goal.
    9. **`symmetries`:** The rotational symmetry of the object around the z-axis (in radians). This is used in the `is_match` function to account for object symmetries when comparing poses.

* **Language Goals (`self.lang_goals`):**  A list of strings providing natural language descriptions of the sub-goals.

**Environment Integration:**

The `add_object` function snippet suggests how objects are added to the environment, specifying their URDF, pose, and category (fixed, rigid, or deformable).

**Key Considerations:**

* **Physics:** The environment simulates physics, requiring objects to obey physical laws (gravity, collisions).
* **Workspace Bounds:** Object goal poses must be within the defined workspace bounds on the table.
* **Multi-Step Tasks:** The `self.goals` list allows for defining multi-step pick-and-place tasks, where each element represents a sub-goal.
* **Agent Interaction:** An agent using the `PickPlace` primitive interacts with the environment to achieve the defined goals.


This structure provides a flexible and well-organized framework for defining and evaluating various manipulation tasks. The `self.goals` list is particularly important for representing complex, multi-step tasks.  The `oracle` function is valuable for generating demonstrations, and the different reward metrics ('pose' and 'zone') allow for flexibility in defining task success.


================= Error Book Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-in-bowls". Here are some runtime errors that you do not want to make. Please confirm that you understand these runtime errors.

"""
- environment.py, line 338, in info
    pos, rot = p.getBasePositionAndOrientation(obj_id)
TypeError: an integer is required (got type NoneType)

- task.py, line 118, in act
    objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]
IndexError: list index out of range

- task.py, line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
TypeError: 'float' object is not subscriptable

- task.py", line 315, in is_match
  rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]

- utils.py", line 280, in quatXYZW_to_eulerXYZ
  quaternion_wxyz = np.array([q[3], q[0], q[1], q[2]])
IndexError: tuple index out of range

- pallet_pose = self.get_random_pose(env, pallet_size)
pallet_surface_height = pallet_pose[0][2]
TypeError: 'NoneType' object is not subscriptable

- No such file or directory: './cliport/environments/assets/circle/circle-template.urdf'

- No such file or directory: './cliport/environments/assets/block/block-template.urdf'

- task.py", line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
IndexError: invalid index to scalar variable.

-TypeError: get_random_size() missing 4 required positional arguments: 'min_y', 'max_y', 'min_z', and 'max_z' 

- task.py", line 195, in reward
    obj_pts, zones = params
TypeError: cannot unpack non-iterable NoneType object

-  environment.py", line 230, in step
    reward, info = self.task.reward() if action is not None else (0, {})
  File "task.py", line 200, in reward
    pts = obj_pts[obj_id]
IndexError: arrays used as indices must be of integer (or boolean) type

- generated_task.py", line 41, in reset
    utils.COLORS['green'], utils.COLORS['blue'], utils.COLORS['light blue'],
KeyError: 'light blue'

- environment.py", line 195, in reset
    self.task.reset(self)
  File "<string>", line 38, in reset
TypeError: can only concatenate str (not "list") to str

- environment.py", line 195, in reset
  object_shape = np.random.choice(object_shapes)
  in numpy.random.mtrand.RandomState.choice
ValueError: a must be 1-dimensional

- No such file or directory: 'assets/box-template/box-template.urdf'

- line 38, in reset.py
{'HALF': box_size / 2}
TypeError: unsupported operand type(s) for /: 'tuple' and 'int'. box_size is a tuple not a float.

- line 38, in reset.py
IndexError: tuple index out of range
box_pose = (pallet_pose[0], pallet_pose[1], pallet_pose[2] + np.sum(box_sizes[:i+1]))

- task.py", line 338, in fill_template
    for i in range(len(replace[field])):
TypeError: object of type 'float' has no len().

- task.py", line 325, in get_random_pose
    pos = (pos[0], pos[1], obj_size[2] / 2)
IndexError: tuple index out of range

- task.py", line 206, in reward
    for zone_idx, (zone_pose, zone_size) in enumerate(zones):
TypeError: 'NoneType' object is not iterable

- task.py",
ball_pose = self.get_random_pose(env, ball_size)
ball_pose[0][2] += 0.02
TypeError: 'tuple' object does not support item assignment
"""


You do not want to make mistakes such as
- using assets (urdfs) that do not exist
- use ambiguous language descriptions as goals. For instance, "place the colored blocks into the matching colored bowls" with one goal and sparse reward as the task instead of adding subgoal "place blue block into blue bowl" and give continuous reward. 
- `matches` in the goal has wrong dimensions. It should have the same dimensions as number of objects (N) multiplied by the number of goal poses (M). Usually it is N by M.
- have vector dimension problem such as `np.random.choice(box_size)` or `box_size / 2` where `box_size` is a tuple and not an int
- make too large an object for stacking or make the task objects invisible for picking. 
- accessing index out of bound `pallet_pose[2]` for `pallet_pose`.  `pallet_pose=get_random_pose` returns a tuple (translation, rotation). It does not have 3rd component. Similarly accessing `container_pose[2]` or `box_pose[2]` would cause errors as well. Since it's a tuple, try to modify it in-place will also trigger errors.
- forget to replace str using `fill_template()` for urdfs with template such as `cylinder-template.urdf`. `ball-template.urdf`, `line-template.urf`. 
- use `self.ee = Spatula()` as a function when doing pushing tasks, which is incorrect. It should be `self.ee = Spatula`.
- forget to compute target poses `targ_poses` for matching. Do not use object IDs for poses.
- change colors of complex objects such as `zone`. You can only change color of teomplate primitive such as `cylinder-template`.
- mistakenly use `random_pose` for target pose. Design target poses based on task objectives.
- add only one or fewer language goals which causes language-motion inconsistentcy. Note that the language goals usually are the same number as the pick and place goals.


>>> Answer: 
Yes, I understand the runtime errors listed and the additional points you've made about avoiding mistakes in task generation. I will be mindful of these issues when writing the code for the "stack-balls-in-bowls" task.  I will pay particular attention to:

* **File Paths:** Ensuring all URDF files exist in the correct locations.
* **Clear Goal Descriptions:**  Using specific language and subgoals for each object and target, avoiding ambiguity.
* **Matches Dimensions:** Ensuring the `matches` array has the correct dimensions (N x M).
* **Vector Operations:**  Handling tuples and arrays correctly, avoiding operations like division or random choice on tuples directly.
* **Object Sizes and Visibility:** Keeping object sizes reasonable for stacking and ensuring they are visible for picking.
* **Pose Indexing:** Accessing pose tuples correctly, remembering they contain (translation, rotation) and not additional elements.  Avoiding in-place modification of tuples.
* **Template Filling:** Using `fill_template()` to replace placeholders in URDFs with specific values.
* **Spatula Initialization:** Using `self.ee = Spatula()` correctly, not as a function call.
* **Target Pose Calculation:** Explicitly calculating `targ_poses` based on task objectives, not using object IDs.
* **Color Changes:** Only changing colors of template primitives, not complex objects.
* **Random Poses vs. Designed Poses:** Using `random_pose` appropriately and designing target poses based on the task.
* **Sufficient Language Goals:** Providing enough language goals to match the pick and place actions, ensuring language-motion consistency.


By addressing these points, I aim to avoid the listed runtime errors and create a robust and functional "stack-balls-in-bowls" task.


================= Code Generation!

>>> Prompt: 
Now I will provide you some reference code and you can write the code for the task "stack-balls-in-bowls".


"""
import os

import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils


class PackingShapes(Task):
    """pick up randomly sized shapes and place them tightly into a container."""

    def __init__(self):
        super().__init__()
        self.max_steps = 1
        self.homogeneous = False

        self.lang_template = "pack the {obj} in the brown box"
        self.task_completed_desc = "done packing shapes."
        self.additional_reset()


    def reset(self, env):
        super().reset(env)

        # Shape Names:
        shapes = utils.assembling_kit_shapes

        n_objects = 5
        if self.mode == 'train':
            obj_shapes = np.random.choice(self.train_set, n_objects, replace=False)
        else:
            if self.homogeneous:
                obj_shapes = [np.random.choice(self.test_set, replace=False)] * n_objects
            else:
                obj_shapes = np.random.choice(self.test_set, n_objects, replace=False)

        # Shuffle colors to avoid always picking an object of the same color
        colors, color_names = utils.get_colors(mode=self.mode)

        # Add container box.
        zone_size = self.get_random_size(0.1, 0.15, 0.1, 0.15, 0.05, 0.05)
        zone_pose = self.get_random_pose(env, zone_size)
        container_template = 'container/container-template.urdf'
        replace = {'DIM': zone_size, 'HALF': (zone_size[0] / 2, zone_size[1] / 2, zone_size[2] / 2)}
        # IMPORTANT: REPLACE THE TEMPLATE URDF with `fill_template`
        container_urdf = self.fill_template(container_template, replace)
        env.add_object(container_urdf, zone_pose, 'fixed')

        # Add objects.
        objects = []
        template = 'kitting/object-template.urdf'
        for i in range(n_objects):
            shape = obj_shapes[i]

            # x, y, z dimensions for the asset size
            size = (0.08, 0.08, 0.02)
            pose= self.get_random_pose(env, size)
            fname = f'{shape:02d}.obj'
            fname = os.path.join(self.assets_root, 'kitting', fname)
            scale = [0.003, 0.003, 0.001]  # .0005
            replace = {'FNAME': (fname,),
                       'SCALE': scale,
                       'COLOR': colors[i]}

            # IMPORTANT: REPLACE THE TEMPLATE URDF
            urdf = self.fill_template(template, replace)
            block_id = env.add_object(urdf, pose)
            objects.append(block_id)

        # Pick the first shape.
        num_objects_to_pick = 1
        for i in range(num_objects_to_pick):
            # IMPORTANT: Specify (obj_pts, [(zone_pose, zone_size)]) for target `zone`. obj_pts is a dict
            language_goal = self.lang_template.format(obj=shapes[obj_shapes[i]])
            self.add_goal(objs=[objects[i]], matches=np.int32([[1]]), targ_poses=[zone_pose], replace=False,
                rotations=True, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1 / num_objects_to_pick,
                language_goal=language_goal)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p


class PlaceRedInGreen(Task):
    """pick up the red blocks and place them into the green bowls amidst other objects."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "put the red blocks in a green bowl"
        self.task_completed_desc = "done placing blocks in bowls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)
        n_bowls = np.random.randint(1, 4)
        n_blocks = np.random.randint(1, n_bowls + 1)

        # Add bowls.
        # x, y, z dimensions for the asset size
        bowl_size = (0.12, 0.12, 0)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_poses = []
        for _ in range(n_bowls):
            bowl_pose = self.get_random_pose(env, obj_size=bowl_size)
            env.add_object(urdf=bowl_urdf, pose=bowl_pose, category='fixed')
            bowl_poses.append(bowl_pose)

        # Add blocks.
        # x, y, z dimensions for the asset size
        blocks = []
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'
        for _ in range(n_blocks):
            block_pose = self.get_random_pose(env, obj_size=block_size)
            block_id = env.add_object(block_urdf, block_pose)
            blocks.append(block_id)

        # Goal: each red block is in a different green bowl.
        self.add_goal(objs=blocks, matches=np.ones((len(blocks), len(bowl_poses))), targ_poses=bowl_poses, replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1, language_goal=self.lang_template)

        # Colors of distractor objects.
        bowl_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'green']
        block_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'red']

        # Add distractors.
        n_distractors = 0
        while n_distractors < 6:
            is_block = np.random.rand() > 0.5
            urdf = block_urdf if is_block else bowl_urdf
            size = block_size if is_block else bowl_size
            colors = block_colors if is_block else bowl_colors
            pose = self.get_random_pose(env, obj_size=size)
            color = colors[n_distractors % len(colors)]

            obj_id = env.add_object(urdf, pose, color=color)
            n_distractors += 1
"""
"""
import numpy as np
from cliport.tasks import primitives
from cliport.tasks.grippers import Spatula
from cliport.tasks.task import Task
from cliport.utils import utils


class SweepingPiles(Task):
    """Push piles of small objects into a target goal zone marked on the tabletop."""

    def __init__(self):
        super().__init__()
        self.max_steps = 20
        self.lang_template = "push the pile of blocks into the green square"
        self.task_completed_desc = "done sweeping."
        self.primitive = primitives.push
        self.ee = Spatula
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add goal zone.
        zone_size = (0.12, 0.12, 0)
        zone_pose = self.get_random_pose(env, zone_size)
        env.add_object('zone/zone.urdf', zone_pose, 'fixed')

        # Add pile of small blocks with `make_piles` function
        obj_ids = self.make_piles(env)

        # Add goal
        self.add_goal(objs=obj_ids, matches=np.ones((50, 1)), targ_poses=[zone_pose], replace=True,
                rotations=False, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1, language_goal=self.lang_template)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p

class StackBlockPyramid(Task):
    """Build a pyramid of colored blocks in a color sequence"""

    def __init__(self):
        super().__init__()
        self.max_steps = 12
        self.lang_template = "make the {row} row with {blocks}"
        self.task_completed_desc = "done stacking block pyramid."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add base.
        base_size = (0.05, 0.15, 0.005)
        base_urdf = 'stacking/stand.urdf'
        base_pose = self.get_random_pose(env, base_size)
        env.add_object(base_urdf, base_pose, category='fixed')

        # Block colors.
        colors = [
            utils.COLORS['purple'], utils.COLORS['blue'], utils.COLORS['green'],
            utils.COLORS['yellow'], utils.COLORS['orange'], utils.COLORS['red']
        ]

        # Add blocks.
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'

        objs = []
        for i in range(6):
            block_pose = self.get_random_pose(env, block_size)
            block_id = env.add_object(block_urdf, block_pose, color=colors[i])
            objs.append(block_id)

        # IMPORTANT Associate placement locations for goals.
        place_pos = [(0, -0.05, 0.03), (0, 0, 0.03),
                     (0, 0.05, 0.03), (0, -0.025, 0.08),
                     (0, 0.025, 0.08), (0, 0, 0.13)]
        targs = [(utils.apply(base_pose, i), base_pose[1]) for i in place_pos]

        # Goal: blocks are stacked in a pyramid (bottom row: green, blue, purple).
        language_goal = self.lang_template.format(blocks="the green, blue and purple blocks", row="bottom")
        self.add_goal(objs=objs[:3], matches=np.ones((3, 3)), targ_poses=targs[:3], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 2, symmetries=[np.pi/2]*3, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (middle row: yellow, orange).
        language_goal = self.lang_template.format(blocks="the yellow and orange blocks", row="middle")      
        self.add_goal(objs=objs[3:5], matches=np.ones((2, 2)), targ_poses=targs[3:5], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 3, symmetries=[np.pi/2]*2, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (top row: red).
        language_goal = self.lang_template.format(blocks="the red block", row="top")
        self.add_goal(objs=objs[5:], matches=np.ones((1, 1)), targ_poses=targs[5:], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 6, symmetries=[np.pi/2]*1, language_goal=language_goal)
"""



Do not use libraries, functions, and assets that you don't know. For each object, try to describe its color, size, category in the task first before you write the code. You do not need extra helper functions. Comment the code liberally to explain what each piece does and why it's written that way. If you have only one goal, `step_max_reward` in `add_goal` should be 1. Use functions `make_piles` and `make_ropes` for creating piles and cables. To use spatula together with the push primitives, import the libraries 
"""
from cliport.tasks import primitives;
from cliport.tasks.grippers import Spatula
"""
and then use `self.primitive = primitives.push` and `self.ee = Spatula`.
Note that the number of language goals usually match the number of motion goals, since they should correspond to each other.

Now write the code for the task "stack-balls-in-bowls" in python code block starting with ```python.  Reminder: {'task-name': 'stack-balls-in-bowls', 'task-description': 'Pick up three different colored balls (red, green, and blue) and stack them inside a correspondingly colored bowl (red, green, and blue).', 'assets-used': ['ball/ball-template.urdf', 'bowl/bowl.urdf']} 


>>> Answer: 
```python
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils

class StackBallsInBowls(Task):
    """Pick up three different colored balls (red, green, and blue) and stack them inside a correspondingly colored bowl (red, green, and blue)."""

    def __init__(self):
        super().__init__()
        self.max_steps = 15 # Set maximum steps
        self.lang_template = "place the {color} ball in the {color} bowl"
        self.task_completed_desc = "done stacking balls in bowls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Define colors and corresponding language descriptions
        colors = ['red', 'green', 'blue']

        # Bowl properties:
        # Category: fixed (cannot be moved by the robot)
        # Size: (0.12, 0.12, 0) - slightly larger than the balls
        bowl_size = (0.12, 0.12, 0)
        bowl_urdf = 'bowl/bowl.urdf'

        # Ball properties:
        # Category: object (can be manipulated)
        # Size: (0.04, 0.04, 0.04)
        ball_size = (0.04, 0.04, 0.04)
        ball_urdf = 'ball/ball-template.urdf'

        # Initialize lists to store object IDs and target poses
        balls = []
        bowl_poses = []

        # Add bowls and balls to the environment
        for color in colors:
            # Get a random pose for the bowl
            bowl_pose = self.get_random_pose(env, bowl_size)
            # Add the bowl with the specified color
            env.add_object(bowl_urdf, bowl_pose, color=utils.COLORS[color], category='fixed')
            bowl_poses.append(bowl_pose)

            # Get a random pose for the ball
            ball_pose = self.get_random_pose(env, ball_size)
            # Add the ball with the specified color
            ball_id = env.add_object(ball_urdf, ball_pose, color=utils.COLORS[color])
            balls.append(ball_id)

        # Define goal matches - each ball corresponds to a specific bowl (same color)
        matches = np.eye(3)

        # Add goals for each ball-bowl pair
        for i in range(3):
            language_goal = self.lang_template.format(color=colors[i]) # Format language goal
            self.add_goal(objs=[balls[i]], matches=matches[i:i+1], targ_poses=[bowl_poses[i]], replace=False,
                          rotations=True, metric='pose', params=None, step_max_reward=1/3, # step_max_reward is 1/3 since there are 3 goals
                          language_goal=language_goal) # Add language goal
```

================= TRIAL: 7