

================= Task and Asset Design!

>>> Prompt: 
You are an AI in robot simulation code and task design. I will provide you some example tasks, code implementation, and some guidelines for how to generate tasks and then you will help me generate a new task. My goal is to design diverse and feasible tasks for tabletop manipulation. I will first ask you to describe the task in natural languages and then will let you write the code for it. 

=========
Here are all the assets. Use only these assets in the task and code design. 
"""
insertion/:
ell.urdf  fixture.urdf

bowl/:
bowl.urdf

box/:
box-template.urdf

stacking/:
block.urdf  stand.urdf

zone/:
zone.obj  zone.urdf

pallet/:
pallet.obj  pallet.urdf

ball/:
ball-template.urdf

cylinder/:
cylinder-template.urdf

bowl/:
bowl.urdf

# assets not for picking
corner/:
corner-template.urdf

line/:
single-green-line-template.urdf

container/:
container-template.urdf
"""
 
=========
Here are some examples of good tasks. Try to learn from these structures but avoid overlapping wiht them.

{"assets-used": ["zone/zone.urdf", "block/small.urdf"],
 "task-description": "Push piles of small objects into a target goal zone marked on the tabletop.",
 "task-name": "sweeping-piles"}

{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "Place all blocks of a specified color in a bowl of specified color.",
 "task-name": "put-block-in-bowl"}
 
{"assets-used": ["insertion/ell.urdf", "insertion/fixture.urdf"],
 "task-description": "pick up the L-shaped red block and place it into the L-shaped fixture.",
 "task-name": "block-insertion"}
 
{"assets-used": ["kitting/kit.urdf", "kitting/object-template.urdf"],
 "task-description": "pick up different objects and arrange them on a board marked with corresponding silhouettes.",
 "task-name": "assembling-kits"}
 
{"assets-used": ["pallet/pallet.urdf", "box/box-template.urdf"],
 "task-description": "pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.",
 "task-name": "palletizing-boxes"}
 
{"assets-used": ["stacking/stand.urdf", "stacking/block.urdf"],
 "task-description": "sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.",
 "task-name": "stack-block-pyramid"}
 
{"assets-used": ["container/container-template.urdf", "box/box-template.urdf"],
 "task-description": "pick up randomly sized boxes and place them tightly into a container.",
 "task-name": "packing-boxes"}
 
{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "pick up the red blocks and place them into the green bowls amidst other objects.",
 "task-name": "place-red-in-green"}
 
{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

=========
Here are some tasks that you have come up with before. Try to learn from these structures but avoid overlapping with these tasks. For instance, `bowl_ball_placement` and `sort_balls_in_bowls` are the same task. `pile_boxes_in_corner` and `stack_blocks_into_pallet` are similar tasks, `align-cylinder-in-corner` and `align-cylinder-corner` are similar.
- sweeping-piles: {'assets-used': ['zone/zone.urdf', 'block/small.urdf'], 'task-description': 'push piles of small objects into a target goal zone marked on the tabletop.', 'task-name': 'sweeping-piles'}
- place-red-in-green: {'assets-used': ['bowl/bowl.urdf', 'stacking/block.urdf'], 'task-description': 'pick up the red blocks and place them into the green bowls amidst other objects.', 'task-name': 'place-red-in-green'}
- align-box-corner: {'assets-used': ['box/box-template.urdf', 'corner/corner-template.urdf'], 'task-description': 'pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..', 'task-name': 'align-box-corner'}
- stack-block-pyramid: {'assets-used': ['stacking/stand.urdf', 'stacking/block.urdf'], 'task-description': 'sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.', 'task-name': 'stack-block-pyramid'}
- palletizing-boxes: {'assets-used': ['pallet/pallet.urdf', 'box/box-template.urdf'], 'task-description': 'pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.', 'task-name': 'palletizing-boxes'}
- assembling-kits: {'assets-used': ['kitting/kit.urdf', 'kitting/object-template.urdf'], 'task-description': 'pick up different objects and arrange them on a board marked with corresponding silhouettes.', 'task-name': 'assembling-kits'}
- packing-boxes: {'assets-used': ['container/container-template.urdf', 'box/box-template.urdf'], 'task-description': 'pick up randomly sized boxes and place them tightly into a container.', 'task-name': 'packing-boxes'}
- manipulating-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'rearrange a deformable rope such that it connects the two endpoints of a 3-sided square.', 'task-name': 'manipulating-rope'}
- align-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'manipulate a deformable rope to connect its end-points between two corners of a 3-sided square.', 'task-name': 'align-rope'}





=========
Here are some bad example task instances with explanations.
{
    "task_name": "sort-color-blocks",
    "task_descriptions": "Pick up differently colored blocks and place them into separate bowls of matching color."
    "assets-used": ["bowl.urdf", "box/box-template.urdf],
}
reasons: not interesting because it overlaps with the current task `put-block-in-bowl`.

{
    "task-name": "guided-ball-maze",
    "task-description": "Navigate a small ball through a maze by tilting the maze board to reach the target zone.",
    "assets-used": ["zone-template.urdf", "square-template.urdf", "ball.urdf", "maze.urdf"],
}
reasons: the language descriptions are too ambiguous. Navigation is also hard to complete. Also maze.urf does not exist.

{
    "task-name": "insert_cylinder_in_sphere",
    "task-description": "Pick up the cylinder and insert it into the sphere with an opening on top.",
    "assets-used": ["cylinder/cylinder-template.urdf", "sphere/sphere-template.urdf"],
}
reasons: this task does not make sense. The sphere does not have an opening on top, and you cannot insert a cylinder into a sphere. Similarly tasks like `insert-ball-into-cylinder` and `cylinder-box-insertion` are invalid.

{
    "task-name": "ball-box-obstacle-course",
    "task-description": "Navigate a ball through an obstacle course created by randomly placed boxes and finally place it inside a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: Navigate the ball is not related to tabletop manipulation tasks.

{
    "task-name": "ball-in-box",
    "task-description": "Use a cable to guide a ball into an open box.",
    "assets-used": ["cable/cable.urdf", "ball/ball-template.urdf", "box/box-template.urdf"]
}
reasons: This task is too hard since it involves interaction of the cable and the ball and cannot be easily completed.

{
    "task-name": "ball-in-container",
    "task-description": "Use the spatula to lift a ball over a wall of boxes and drop it into a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: The only action primitives as pick and place. One cannot use a spatula to lift an object.

{
    "task-name": "line-ball-sorting",
    "task-description": "Move balls of different colors along a single green line, placing each ball in a designated colored box at the end of the line. The challenge includes precision in maintaining the ball on the line and the correct identification of the box color corresponding to each ball.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "line/single-green-line-template.urdf"]
}
reasons: Piling or stacking balls are physically infeasible in the simulation.



=========
Now please describe the new task in natural languages and explain its novelty and challenges. Format the answer in a python dictionary with keys "task-name" and value type string, "task-description" (one specific sentence) and value type string, and "assets-used" and value type list of strings. Note that

- Do not use assets that are not in the list above. 
- Tasks that have more colors and shapes are interesting.
- Be as specific as possible about the number, shape, and color of each asset in the task descriptions. 
- The task need to obey physics and remain feasible.





>>> Answer: 
```python
{
    "task-name": "stack-balls-on-pallet",
    "task-description": "Stack three balls of different colors (red, green, and blue) on top of each other in a specific order (red on the bottom, green in the middle, blue on top) on a pallet.",
    "assets-used": ["pallet/pallet.urdf", "ball/ball-template.urdf"]
}
```

**Novelty and Challenges:**

* **Novelty:** While stacking blocks is a common task, stacking balls introduces a new level of challenge due to their round shape and tendency to roll. This task combines the precision of stacking with the instability of spherical objects.  It hasn't been explored in the provided examples.
* **Challenges:**
    * **Stability:**  Maintaining the balance of the balls during stacking requires precise placement and control.  A slight misplacement of a lower ball can cause the entire stack to collapse.
    * **Precision:**  Picking and placing the balls accurately on top of each other demands fine-grained motor control.
    * **Order Constraint:** The specific color order adds an additional layer of complexity. The robot needs to identify and manipulate the balls in the correct sequence.


This task is feasible within the constraints of a pick-and-place robot simulation, as it relies on basic manipulation skills.  It introduces an interesting challenge that goes beyond simple block stacking, without requiring complex actions or unrealistic physics.


================= API Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-on-pallet". Here are some APIs that are defined. Please confirm that you understand these APIs.

"""
class Task():
    """Base Task class."""

    def __init__(self):
        self.ee = Suction
        self.mode = 'train'
        self.sixdof = False
        self.primitive = primitives.PickPlace()
        self.oracle_cams = cameras.Oracle.CONFIG

        # Evaluation epsilons (for pose evaluation metric).
        self.pos_eps = 0.01
        self.rot_eps = np.deg2rad(15)

        # Workspace bounds.
        self.pix_size = 0.003125
        self.bounds = np.array([[0.25, 0.75], [-0.5, 0.5], [0, 0.3]])
        self.zone_bounds = np.copy(self.bounds)

        self.goals = []
        self.lang_goals = []
        self.task_completed_desc = "task completed."
        self.progress = 0
        self._rewards = 0
        self.assets_root = None

    def reset(self, env):
        if not self.assets_root:
            raise ValueError('assets_root must be set for task, '
                             'call set_assets_root().')
        self.goals = []
        self.lang_goals = []
        self.progress = 0  # Task progression metric in range [0, 1].
        self._rewards = 0  # Cumulative returned rewards.

    # -------------------------------------------------------------------------
    # Oracle Agent
    # -------------------------------------------------------------------------

    def oracle(self, env):
        """Oracle agent."""
        OracleAgent = collections.namedtuple('OracleAgent', ['act'])

        def act(obs, info):
            """Calculate action."""

            # Oracle uses perfect RGB-D orthographic images and segmentation masks.
            _, hmap, obj_mask = self.get_true_image(env)

            # Unpack next goal step.
            objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]

            # Match objects to targets without replacement.
            if not replace:

                # Modify a copy of the match matrix.
                matches = matches.copy()

                # Ignore already matched objects.
                for i in range(len(objs)):
                    object_id, (symmetry, _) = objs[i]
                    pose = p.getBasePositionAndOrientation(object_id)
                    targets_i = np.argwhere(matches[i, :]).reshape(-1)
                    for j in targets_i:
                        if self.is_match(pose, targs[j], symmetry):
                            matches[i, :] = 0
                            matches[:, j] = 0

            # Get objects to be picked (prioritize farthest from nearest neighbor).
            nn_dists = []
            nn_targets = []
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                xyz, _ = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                if len(targets_i) > 0:
                    targets_xyz = np.float32([targs[j][0] for j in targets_i])
                    dists = np.linalg.norm(
                        targets_xyz - np.float32(xyz).reshape(1, 3), axis=1)
                    nn = np.argmin(dists)
                    nn_dists.append(dists[nn])
                    nn_targets.append(targets_i[nn])

                # Handle ignored objects.
                else:
                    nn_dists.append(0)
                    nn_targets.append(-1)
            order = np.argsort(nn_dists)[::-1]

            # Filter out matched objects.
            order = [i for i in order if nn_dists[i] > 0]

            pick_mask = None
            for pick_i in order:
                pick_mask = np.uint8(obj_mask == objs[pick_i][0])

                # Erode to avoid picking on edges.
                # pick_mask = cv2.erode(pick_mask, np.ones((3, 3), np.uint8))

                if np.sum(pick_mask) > 0:
                    break

            # Trigger task reset if no object is visible.
            if pick_mask is None or np.sum(pick_mask) == 0:
                self.goals = []
                self.lang_goals = []
                print('Object for pick is not visible. Skipping demonstration.')
                return

            # Get picking pose.
            pick_prob = np.float32(pick_mask)
            pick_pix = utils.sample_distribution(pick_prob)
            # For "deterministic" demonstrations on insertion-easy, use this:
            # pick_pix = (160,80)
            pick_pos = utils.pix_to_xyz(pick_pix, hmap,
                                        self.bounds, self.pix_size)
            pick_pose = (np.asarray(pick_pos), np.asarray((0, 0, 0, 1)))

            # Get placing pose.
            targ_pose = targs[nn_targets[pick_i]]
            obj_pose = p.getBasePositionAndOrientation(objs[pick_i][0])
            if not self.sixdof:
                obj_euler = utils.quatXYZW_to_eulerXYZ(obj_pose[1])
                obj_quat = utils.eulerXYZ_to_quatXYZW((0, 0, obj_euler[2]))
                obj_pose = (obj_pose[0], obj_quat)
            world_to_pick = utils.invert(pick_pose)
            obj_to_pick = utils.multiply(world_to_pick, obj_pose)
            pick_to_obj = utils.invert(obj_to_pick)
            place_pose = utils.multiply(targ_pose, pick_to_obj)

            # Rotate end effector?
            if not rotations:
                place_pose = (place_pose[0], (0, 0, 0, 1))

            place_pose = (np.asarray(place_pose[0]), np.asarray(place_pose[1]))

            return {'pose0': pick_pose, 'pose1': place_pose}

        return OracleAgent(act)

    # -------------------------------------------------------------------------
    # Reward Function and Task Completion Metrics
    # -------------------------------------------------------------------------

    def reward(self):
        """Get delta rewards for current timestep.

        Returns:
          A tuple consisting of the scalar (delta) reward, plus `extras`
            dict which has extra task-dependent info from the process of
            computing rewards that gives us finer-grained details. Use
            `extras` for further data analysis.
        """
        reward, info = 0, {}

        # Unpack next goal step.
        objs, matches, targs, _, _, metric, params, max_reward = self.goals[0]

        # Evaluate by matching object poses.
        if metric == 'pose':
            step_reward = 0
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                pose = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                for j in targets_i:
                    target_pose = targs[j]
                    if self.is_match(pose, target_pose, symmetry):
                        step_reward += max_reward / len(objs)
                        print(f"object {i} match with target {j} rew: {step_reward}")
                        break

        # Evaluate by measuring object intersection with zone.
        elif metric == 'zone':
            zone_pts, total_pts = 0, 0
            obj_pts, zones = params
            for zone_idx, (zone_pose, zone_size) in enumerate(zones):

                # Count valid points in zone.
                for obj_idx, obj_id in enumerate(obj_pts):
                    pts = obj_pts[obj_id]
                    obj_pose = p.getBasePositionAndOrientation(obj_id)
                    world_to_zone = utils.invert(zone_pose)
                    obj_to_zone = utils.multiply(world_to_zone, obj_pose)
                    pts = np.float32(utils.apply(obj_to_zone, pts))
                    if len(zone_size) > 1:
                        valid_pts = np.logical_and.reduce([
                            pts[0, :] > -zone_size[0] / 2, pts[0, :] < zone_size[0] / 2,
                            pts[1, :] > -zone_size[1] / 2, pts[1, :] < zone_size[1] / 2,
                            pts[2, :] < self.zone_bounds[2, 1]])

                    # if zone_idx == matches[obj_idx].argmax():
                    zone_pts += np.sum(np.float32(valid_pts))
                    total_pts += pts.shape[1]
            step_reward = max_reward * (zone_pts / total_pts)

        # Get cumulative rewards and return delta.
        reward = self.progress + step_reward - self._rewards
        self._rewards = self.progress + step_reward

        # Move to next goal step if current goal step is complete.
        if np.abs(max_reward - step_reward) < 0.01:
            self.progress += max_reward  # Update task progress.
            self.goals.pop(0)
            if len(self.lang_goals) > 0:
                self.lang_goals.pop(0)

        return reward, info

    def done(self):
        """Check if the task is done or has failed.

        Returns:
          True if the episode should be considered a success, which we
            use for measuring successes, which is particularly helpful for tasks
            where one may get successes on the very last time step, e.g., getting
            the cloth coverage threshold on the last alllowed action.
            However, for bag-items-easy and bag-items-hard (which use the
            'bag-items' metric), it may be necessary to filter out demos that did
            not attain sufficiently high reward in external code. Currently, this
            is done in `main.py` and its ignore_this_demo() method.
        """
        return (len(self.goals) == 0) or (self._rewards > 0.99)
        # return zone_done or defs_done or goal_done

    # -------------------------------------------------------------------------
    # Environment Helper Functions
    # -------------------------------------------------------------------------

    def is_match(self, pose0, pose1, symmetry):
        """Check if pose0 and pose1 match within a threshold."""

        # Get translational error.
        diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
        dist_pos = np.linalg.norm(diff_pos)

        # Get rotational error around z-axis (account for symmetries).
        diff_rot = 0
        if symmetry > 0:
            rot0 = np.array(utils.quatXYZW_to_eulerXYZ(pose0[1]))[2]
            rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]
            diff_rot = np.abs(rot0 - rot1) % symmetry
            if diff_rot > (symmetry / 2):
                diff_rot = symmetry - diff_rot

        return (dist_pos < self.pos_eps) and (diff_rot < self.rot_eps)

    def get_random_pose(self, env, obj_size):
        """Get random collision-free object pose within workspace bounds."""

        # Get erosion size of object in pixels.
        max_size = np.sqrt(obj_size[0] ** 2 + obj_size[1] ** 2)
        erode_size = int(np.round(max_size / self.pix_size))

        _, hmap, obj_mask = self.get_true_image(env)

        # Randomly sample an object pose within free-space pixels.
        free = np.ones(obj_mask.shape, dtype=np.uint8)
        for obj_ids in env.obj_ids.values():
            for obj_id in obj_ids:
                free[obj_mask == obj_id] = 0
        free[0, :], free[:, 0], free[-1, :], free[:, -1] = 0, 0, 0, 0
        free = cv2.erode(free, np.ones((erode_size, erode_size), np.uint8))

        # if np.sum(free) == 0:
        #     return None, None

        if np.sum(free) == 0:
            # avoid returning None, None
            # return None, None
            pix = (obj_mask.shape[0] // 2, obj_mask.shape[1] // 2)
        else:
            pix = utils.sample_distribution(np.float32(free))
        pos = utils.pix_to_xyz(pix, hmap, self.bounds, self.pix_size)
        pos = (pos[0], pos[1], obj_size[2] / 2)
        theta = np.random.rand() * 2 * np.pi
        rot = utils.eulerXYZ_to_quatXYZW((0, 0, theta))
        return pos, rot

    def get_lang_goal(self):
        if len(self.lang_goals) == 0:
            return self.task_completed_desc
        else:
            return self.lang_goals[0]

    def get_reward(self):
        return float(self._rewards)

    # -------------------------------------------------------------------------
    # Helper Functions
    # -------------------------------------------------------------------------

    def fill_template(self, template, replace):
        """Read a file and replace key strings."""
        full_template_path = os.path.join(self.assets_root, template)
        with open(full_template_path, 'r') as file:
            fdata = file.read()
        for field in replace:
            for i in range(len(replace[field])):
                fdata = fdata.replace(f'{field}{i}', str(replace[field][i]))
        alphabet = string.ascii_lowercase + string.digits
        rname = ''.join(random.choices(alphabet, k=16))
        tmpdir = tempfile.gettempdir()
        template_filename = os.path.split(template)[-1]
        fname = os.path.join(tmpdir, f'{template_filename}.{rname}')
        with open(fname, 'w') as file:
            file.write(fdata)
        return fname

    def get_random_size(self, min_x, max_x, min_y, max_y, min_z, max_z):
        """Get random box size."""
        size = np.random.rand(3)
        size[0] = size[0] * (max_x - min_x) + min_x
        size[1] = size[1] * (max_y - min_y) + min_y
        size[2] = size[2] * (max_z - min_z) + min_z
        return tuple(size)

    def color_random_brown(self, obj):
        shade = np.random.rand() + 0.5
        color = np.float32([shade * 156, shade * 117, shade * 95, 255]) / 255
        p.changeVisualShape(obj, -1, rgbaColor=color)

  """""
  
  # Environment Class
  def add_object(self, urdf, pose, category='rigid'):
    """List of (fixed, rigid, or deformable) objects in env."""
    fixed_base = 1 if category == 'fixed' else 0
    obj_id = pybullet_utils.load_urdf(
        p,
        os.path.join(self.assets_root, urdf),
        pose[0],
        pose[1],
        useFixedBase=fixed_base)
    self.obj_ids[category].append(obj_id)
    return obj_id
"""

=========
Note that the objects need to obey physics and not collide with each other, and the object goal poses need to be above the table with lower bound x=0.25, y=-0.5 and upper bound x=0.75, y=0.5. When there are multiple objects for a multi-step pick-and-place task, there are often multiple subgoals. Once the task and environment are generated, an agent with a pick and place primitive will follow the defined goal to accomplish the tasks. 

Additionally, make sure you understand and summarize the ``self.goals`` variables, which has a list of 8-tuple with (objs, matches, targ_poses, replace, rotations, metric, params, step_max_reward, symmetries).
- objs (List of obj_id): object ID.
- matches (Binary Matrix): a binary matrix that denotes which object is matched with which target. This matrix has dimension len(objs) x len(targs).
- targ_poses (List of Poses [(translation, rotation)] ): a list of target poses of tuple (translation, rotation). 
- replace (Boolean): whether each object can match with one unique target. This is important if we have one target and multiple objects. If it's set to be false, then any object matching with the target will satisfy.
- rotations (Boolean): whether the placement action has a rotation degree of freedom. 
- metric (`pose` or `zone`): `pose` or `zone` that the object needs to be transported to. Example: `pose`. 
- params (List of (zone_target, zone_size)): a list of (zone_target, zone_size) for each zone if the metric is `zone`. 
- step_max_reward (float): the total reward of matching all the objects with all the target poses. It is not dependent on the number of objects but dependent on the number of goals. 
- symmetries: the radians that the object is symmetric around z axis.
- language_goal: the low-level language instructions that denote the goal of this step.
 


>>> Answer: 
Yes, I understand the provided APIs and their intended usage. Here's a summary of my understanding:

**Task Class:**

The `Task` class defines the base structure and functionality for a manipulation task involving picking and placing objects.  It handles reward calculation, task completion checks, oracle agent actions, and helper functions for environment interaction.

**Key Attributes and Methods:**

* **`ee`**:  Represents the end-effector, which is a suction cup in this case.
* **`mode`**:  Indicates whether the task is in 'train' or other modes.
* **`sixdof`**:  Specifies whether the task involves 6 degrees of freedom (DoF) manipulation.
* **`primitive`**:  Defines the action primitive used, which is `PickPlace`.
* **`oracle_cams`**:  Configuration for oracle cameras (perfect perception).
* **`pos_eps`, `rot_eps`**:  Position and rotation tolerances for evaluating pose matching.
* **`pix_size`, `bounds`, `zone_bounds`**:  Define the workspace and zone dimensions in the environment.
* **`goals`, `lang_goals`**:  Store the task goals and their corresponding language descriptions.  Crucially, `goals` contains the structured representation of the task, while `lang_goals` provides human-readable descriptions.
* **`task_completed_desc`**:  Message indicating task completion.
* **`progress`, `_rewards`**:  Track task progress and cumulative rewards.
* **`assets_root`**:  Path to the directory containing task-related assets (URDFs, etc.).

* **`reset(env)`**:  Resets the task state, clearing goals and progress.
* **`oracle(env)`**:  Returns an oracle agent that uses perfect information to perform the task.  This is useful for generating demonstrations.
* **`reward()`**:  Calculates the reward for the current timestep based on the `metric` defined in the goal.  It returns a delta reward and an `info` dictionary.
* **`done()`**:  Checks if the task is completed or failed.
* **`is_match()`**:  Determines if two poses match within the defined tolerances, considering symmetry.
* **`get_random_pose()`**:  Generates a random, collision-free pose within the workspace.
* **`get_lang_goal()`**:  Returns the language description of the current goal.
* **`get_reward()`**: Returns the current cumulative reward.
* **`fill_template()`: Reads a template file, replaces placeholders, and writes to a temporary file. Used for procedural generation of scene descriptions.
* **`get_random_size()`: Generates a random size within specified ranges for x, y, and z dimensions.
* **`color_random_brown()`: Colors an object with a random shade of brown.

**Environment Class (add_object):**

* **`add_object(urdf, pose, category)`**: Adds an object to the PyBullet environment. The `category` argument specifies whether the object is 'fixed', 'rigid', or 'deformable'.


**Understanding `self.goals`:**

The `self.goals` variable is a list where each element is an 8-tuple representing a sub-goal.  These tuples are structured as follows:

1. **`objs`**: A list of object IDs (integers) involved in the sub-goal.
2. **`matches`**: A binary matrix indicating which object should be matched with which target pose.  Rows correspond to objects, and columns correspond to target poses. A '1' at `matches[i, j]` means object `i` should be placed at target pose `j`.
3. **`targs` (or `targ_poses`):** A list of target poses, each represented as a tuple `(position, orientation)`.  `position` is a 3D vector, and `orientation` is a quaternion.
4. **`replace`**: A boolean flag. If `False`, each object can only be matched to one unique target.  If `True`, multiple objects can be matched to the same target.
5. **`rotations`**: A boolean flag indicating whether the placement action should consider rotations.
6. **`metric`**: A string specifying the evaluation metric for the sub-goal.  Can be 'pose' (matching object pose to target pose) or 'zone' (object within a designated zone).
7. **`params`**:  Additional parameters specific to the metric. For 'zone', it's a list of tuples `(zone_pose, zone_size)` defining the zone's location and dimensions.
8. **`step_max_reward`**: The maximum reward achievable for this sub-goal.
9. **`symmetries`**: The rotational symmetry of the object around the z-axis, in radians.


**Key Considerations:**

* **Physics and Collisions:** Objects in the environment are subject to physics and should not collide with each other.
* **Goal Poses:** Target poses should be above the table within the specified workspace bounds.
* **Multi-Step Tasks:** Multi-step pick-and-place tasks involve multiple sub-goals, each represented by an 8-tuple in `self.goals`.
* **Agent and Primitive:** An agent using the `PickPlace` primitive will attempt to achieve the goals defined in `self.goals`.


This detailed understanding of the APIs will be crucial for implementing the "stack-balls-on-pallet" task correctly. I'm ready to proceed with the code implementation.


================= Error Book Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-on-pallet". Here are some runtime errors that you do not want to make. Please confirm that you understand these runtime errors.

"""
- environment.py, line 338, in info
    pos, rot = p.getBasePositionAndOrientation(obj_id)
TypeError: an integer is required (got type NoneType)

- task.py, line 118, in act
    objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]
IndexError: list index out of range

- task.py, line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
TypeError: 'float' object is not subscriptable

- task.py", line 315, in is_match
  rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]

- utils.py", line 280, in quatXYZW_to_eulerXYZ
  quaternion_wxyz = np.array([q[3], q[0], q[1], q[2]])
IndexError: tuple index out of range

- pallet_pose = self.get_random_pose(env, pallet_size)
pallet_surface_height = pallet_pose[0][2]
TypeError: 'NoneType' object is not subscriptable

- No such file or directory: './cliport/environments/assets/circle/circle-template.urdf'

- No such file or directory: './cliport/environments/assets/block/block-template.urdf'

- task.py", line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
IndexError: invalid index to scalar variable.

-TypeError: get_random_size() missing 4 required positional arguments: 'min_y', 'max_y', 'min_z', and 'max_z' 

- task.py", line 195, in reward
    obj_pts, zones = params
TypeError: cannot unpack non-iterable NoneType object

-  environment.py", line 230, in step
    reward, info = self.task.reward() if action is not None else (0, {})
  File "task.py", line 200, in reward
    pts = obj_pts[obj_id]
IndexError: arrays used as indices must be of integer (or boolean) type

- generated_task.py", line 41, in reset
    utils.COLORS['green'], utils.COLORS['blue'], utils.COLORS['light blue'],
KeyError: 'light blue'

- environment.py", line 195, in reset
    self.task.reset(self)
  File "<string>", line 38, in reset
TypeError: can only concatenate str (not "list") to str

- environment.py", line 195, in reset
  object_shape = np.random.choice(object_shapes)
  in numpy.random.mtrand.RandomState.choice
ValueError: a must be 1-dimensional

- No such file or directory: 'assets/box-template/box-template.urdf'

- line 38, in reset.py
{'HALF': box_size / 2}
TypeError: unsupported operand type(s) for /: 'tuple' and 'int'. box_size is a tuple not a float.

- line 38, in reset.py
IndexError: tuple index out of range
box_pose = (pallet_pose[0], pallet_pose[1], pallet_pose[2] + np.sum(box_sizes[:i+1]))

- task.py", line 338, in fill_template
    for i in range(len(replace[field])):
TypeError: object of type 'float' has no len().

- task.py", line 325, in get_random_pose
    pos = (pos[0], pos[1], obj_size[2] / 2)
IndexError: tuple index out of range

- task.py", line 206, in reward
    for zone_idx, (zone_pose, zone_size) in enumerate(zones):
TypeError: 'NoneType' object is not iterable

- task.py",
ball_pose = self.get_random_pose(env, ball_size)
ball_pose[0][2] += 0.02
TypeError: 'tuple' object does not support item assignment
"""


You do not want to make mistakes such as
- using assets (urdfs) that do not exist
- use ambiguous language descriptions as goals. For instance, "place the colored blocks into the matching colored bowls" with one goal and sparse reward as the task instead of adding subgoal "place blue block into blue bowl" and give continuous reward. 
- `matches` in the goal has wrong dimensions. It should have the same dimensions as number of objects (N) multiplied by the number of goal poses (M). Usually it is N by M.
- have vector dimension problem such as `np.random.choice(box_size)` or `box_size / 2` where `box_size` is a tuple and not an int
- make too large an object for stacking or make the task objects invisible for picking. 
- accessing index out of bound `pallet_pose[2]` for `pallet_pose`.  `pallet_pose=get_random_pose` returns a tuple (translation, rotation). It does not have 3rd component. Similarly accessing `container_pose[2]` or `box_pose[2]` would cause errors as well. Since it's a tuple, try to modify it in-place will also trigger errors.
- forget to replace str using `fill_template()` for urdfs with template such as `cylinder-template.urdf`. `ball-template.urdf`, `line-template.urf`. 
- use `self.ee = Spatula()` as a function when doing pushing tasks, which is incorrect. It should be `self.ee = Spatula`.
- forget to compute target poses `targ_poses` for matching. Do not use object IDs for poses.
- change colors of complex objects such as `zone`. You can only change color of teomplate primitive such as `cylinder-template`.
- mistakenly use `random_pose` for target pose. Design target poses based on task objectives.
- add only one or fewer language goals which causes language-motion inconsistentcy. Note that the language goals usually are the same number as the pick and place goals.


>>> Answer: 
Yes, I understand the runtime errors listed and the additional points you've made about avoiding mistakes in task generation. I will keep these in mind when writing the code for the "stack-balls-on-pallet" task.  I will pay particular attention to:

* **File Paths and Existence:** Verify that all URDF files exist in the correct locations.
* **Unambiguous Language Goals:**  Provide specific and clear language goals corresponding to each sub-goal, avoiding vague descriptions.
* **Matches Dimensions:** Ensure the `matches` array has the correct dimensions (N x M), reflecting the number of objects and target poses.
* **Vector Dimensions and Operations:**  Handle tuple and array operations correctly, avoiding operations like division or random choice on tuples directly.  I will unpack tuples into individual components when necessary.
* **Object Sizes and Visibility:** Ensure objects are appropriately sized for the task and visible for manipulation.
* **Index out of bounds:** Avoid accessing indices beyond the bounds of tuples or arrays, especially with poses returned from `get_random_pose`. I understand that these tuples typically contain translation and rotation, and I won't try to access a third element or modify them in-place.
* **Template Filling:** Use `fill_template()` to replace placeholder strings in URDFs with specific values.
* **Spatula Initialization:** Use `self.ee = Spatula()` for initialization, not as a function call.
* **Target Pose Computation:** Explicitly calculate `targ_poses` based on task requirements, not object IDs.
* **Color Changes:** Only change colors of primitive template objects, not complex objects like zones.
* **Random vs. Designed Poses:** Use `random_pose` appropriately and design target poses based on the task's logic.
* **Sufficient Language Goals:** Provide enough language goals to match the number of pick-and-place actions, ensuring language-motion consistency.


By addressing these points, I aim to avoid the listed runtime errors and create a robust and functional "stack-balls-on-pallet" task.


================= Code Generation!

>>> Prompt: 
Now I will provide you some reference code and you can write the code for the task "stack-balls-on-pallet".


"""
import os

import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils


class PackingShapes(Task):
    """pick up randomly sized shapes and place them tightly into a container."""

    def __init__(self):
        super().__init__()
        self.max_steps = 1
        self.homogeneous = False

        self.lang_template = "pack the {obj} in the brown box"
        self.task_completed_desc = "done packing shapes."
        self.additional_reset()


    def reset(self, env):
        super().reset(env)

        # Shape Names:
        shapes = utils.assembling_kit_shapes

        n_objects = 5
        if self.mode == 'train':
            obj_shapes = np.random.choice(self.train_set, n_objects, replace=False)
        else:
            if self.homogeneous:
                obj_shapes = [np.random.choice(self.test_set, replace=False)] * n_objects
            else:
                obj_shapes = np.random.choice(self.test_set, n_objects, replace=False)

        # Shuffle colors to avoid always picking an object of the same color
        colors, color_names = utils.get_colors(mode=self.mode)

        # Add container box.
        zone_size = self.get_random_size(0.1, 0.15, 0.1, 0.15, 0.05, 0.05)
        zone_pose = self.get_random_pose(env, zone_size)
        container_template = 'container/container-template.urdf'
        replace = {'DIM': zone_size, 'HALF': (zone_size[0] / 2, zone_size[1] / 2, zone_size[2] / 2)}
        # IMPORTANT: REPLACE THE TEMPLATE URDF with `fill_template`
        container_urdf = self.fill_template(container_template, replace)
        env.add_object(container_urdf, zone_pose, 'fixed')

        # Add objects.
        objects = []
        template = 'kitting/object-template.urdf'
        for i in range(n_objects):
            shape = obj_shapes[i]

            # x, y, z dimensions for the asset size
            size = (0.08, 0.08, 0.02)
            pose= self.get_random_pose(env, size)
            fname = f'{shape:02d}.obj'
            fname = os.path.join(self.assets_root, 'kitting', fname)
            scale = [0.003, 0.003, 0.001]  # .0005
            replace = {'FNAME': (fname,),
                       'SCALE': scale,
                       'COLOR': colors[i]}

            # IMPORTANT: REPLACE THE TEMPLATE URDF
            urdf = self.fill_template(template, replace)
            block_id = env.add_object(urdf, pose)
            objects.append(block_id)

        # Pick the first shape.
        num_objects_to_pick = 1
        for i in range(num_objects_to_pick):
            # IMPORTANT: Specify (obj_pts, [(zone_pose, zone_size)]) for target `zone`. obj_pts is a dict
            language_goal = self.lang_template.format(obj=shapes[obj_shapes[i]])
            self.add_goal(objs=[objects[i]], matches=np.int32([[1]]), targ_poses=[zone_pose], replace=False,
                rotations=True, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1 / num_objects_to_pick,
                language_goal=language_goal)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p


class PlaceRedInGreen(Task):
    """pick up the red blocks and place them into the green bowls amidst other objects."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "put the red blocks in a green bowl"
        self.task_completed_desc = "done placing blocks in bowls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)
        n_bowls = np.random.randint(1, 4)
        n_blocks = np.random.randint(1, n_bowls + 1)

        # Add bowls.
        # x, y, z dimensions for the asset size
        bowl_size = (0.12, 0.12, 0)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_poses = []
        for _ in range(n_bowls):
            bowl_pose = self.get_random_pose(env, obj_size=bowl_size)
            env.add_object(urdf=bowl_urdf, pose=bowl_pose, category='fixed')
            bowl_poses.append(bowl_pose)

        # Add blocks.
        # x, y, z dimensions for the asset size
        blocks = []
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'
        for _ in range(n_blocks):
            block_pose = self.get_random_pose(env, obj_size=block_size)
            block_id = env.add_object(block_urdf, block_pose)
            blocks.append(block_id)

        # Goal: each red block is in a different green bowl.
        self.add_goal(objs=blocks, matches=np.ones((len(blocks), len(bowl_poses))), targ_poses=bowl_poses, replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1, language_goal=self.lang_template)

        # Colors of distractor objects.
        bowl_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'green']
        block_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'red']

        # Add distractors.
        n_distractors = 0
        while n_distractors < 6:
            is_block = np.random.rand() > 0.5
            urdf = block_urdf if is_block else bowl_urdf
            size = block_size if is_block else bowl_size
            colors = block_colors if is_block else bowl_colors
            pose = self.get_random_pose(env, obj_size=size)
            color = colors[n_distractors % len(colors)]

            obj_id = env.add_object(urdf, pose, color=color)
            n_distractors += 1
"""
"""
import numpy as np
from cliport.tasks import primitives
from cliport.tasks.grippers import Spatula
from cliport.tasks.task import Task
from cliport.utils import utils


class SweepingPiles(Task):
    """Push piles of small objects into a target goal zone marked on the tabletop."""

    def __init__(self):
        super().__init__()
        self.max_steps = 20
        self.lang_template = "push the pile of blocks into the green square"
        self.task_completed_desc = "done sweeping."
        self.primitive = primitives.push
        self.ee = Spatula
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add goal zone.
        zone_size = (0.12, 0.12, 0)
        zone_pose = self.get_random_pose(env, zone_size)
        env.add_object('zone/zone.urdf', zone_pose, 'fixed')

        # Add pile of small blocks with `make_piles` function
        obj_ids = self.make_piles(env)

        # Add goal
        self.add_goal(objs=obj_ids, matches=np.ones((50, 1)), targ_poses=[zone_pose], replace=True,
                rotations=False, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1, language_goal=self.lang_template)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p

class StackBlockPyramid(Task):
    """Build a pyramid of colored blocks in a color sequence"""

    def __init__(self):
        super().__init__()
        self.max_steps = 12
        self.lang_template = "make the {row} row with {blocks}"
        self.task_completed_desc = "done stacking block pyramid."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add base.
        base_size = (0.05, 0.15, 0.005)
        base_urdf = 'stacking/stand.urdf'
        base_pose = self.get_random_pose(env, base_size)
        env.add_object(base_urdf, base_pose, category='fixed')

        # Block colors.
        colors = [
            utils.COLORS['purple'], utils.COLORS['blue'], utils.COLORS['green'],
            utils.COLORS['yellow'], utils.COLORS['orange'], utils.COLORS['red']
        ]

        # Add blocks.
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'

        objs = []
        for i in range(6):
            block_pose = self.get_random_pose(env, block_size)
            block_id = env.add_object(block_urdf, block_pose, color=colors[i])
            objs.append(block_id)

        # IMPORTANT Associate placement locations for goals.
        place_pos = [(0, -0.05, 0.03), (0, 0, 0.03),
                     (0, 0.05, 0.03), (0, -0.025, 0.08),
                     (0, 0.025, 0.08), (0, 0, 0.13)]
        targs = [(utils.apply(base_pose, i), base_pose[1]) for i in place_pos]

        # Goal: blocks are stacked in a pyramid (bottom row: green, blue, purple).
        language_goal = self.lang_template.format(blocks="the green, blue and purple blocks", row="bottom")
        self.add_goal(objs=objs[:3], matches=np.ones((3, 3)), targ_poses=targs[:3], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 2, symmetries=[np.pi/2]*3, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (middle row: yellow, orange).
        language_goal = self.lang_template.format(blocks="the yellow and orange blocks", row="middle")      
        self.add_goal(objs=objs[3:5], matches=np.ones((2, 2)), targ_poses=targs[3:5], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 3, symmetries=[np.pi/2]*2, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (top row: red).
        language_goal = self.lang_template.format(blocks="the red block", row="top")
        self.add_goal(objs=objs[5:], matches=np.ones((1, 1)), targ_poses=targs[5:], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 6, symmetries=[np.pi/2]*1, language_goal=language_goal)
"""



Do not use libraries, functions, and assets that you don't know. For each object, try to describe its color, size, category in the task first before you write the code. You do not need extra helper functions. Comment the code liberally to explain what each piece does and why it's written that way. If you have only one goal, `step_max_reward` in `add_goal` should be 1. Use functions `make_piles` and `make_ropes` for creating piles and cables. To use spatula together with the push primitives, import the libraries 
"""
from cliport.tasks import primitives;
from cliport.tasks.grippers import Spatula
"""
and then use `self.primitive = primitives.push` and `self.ee = Spatula`.
Note that the number of language goals usually match the number of motion goals, since they should correspond to each other.

Now write the code for the task "stack-balls-on-pallet" in python code block starting with ```python.  Reminder: {'task-name': 'stack-balls-on-pallet', 'task-description': 'Stack three balls of different colors (red, green, and blue) on top of each other in a specific order (red on the bottom, green in the middle, blue on top) on a pallet.', 'assets-used': ['pallet/pallet.urdf', 'ball/ball-template.urdf']} 


>>> Answer: 
```python
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils

class StackBallsOnPallet(Task):
    """Stack three balls (red, green, blue) on a pallet (red at bottom, green middle, blue top)."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10  # Set maximum steps
        self.lang_template = "Stack the {color} ball on the {target}"
        self.task_completed_desc = "Done stacking balls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Pallet (brown, large, fixed)
        pallet_size = (0.15, 0.15, 0.02)  # Dimensions of the pallet
        pallet_pose = self.get_random_pose(env, pallet_size)  # Random pose on the tabletop
        pallet_urdf = 'pallet/pallet.urdf'
        env.add_object(pallet_urdf, pallet_pose, 'fixed')  # Add pallet to the environment

        # Balls (red, green, blue, small)
        ball_size = (0.04, 0.04, 0.04)  # Dimensions of the balls
        ball_urdf = 'ball/ball-template.urdf'
        colors = ['red', 'green', 'blue']
        ball_ids = []

        for color in colors:
            ball_pose = self.get_random_pose(env, ball_size)  # Random pose on the tabletop
            ball_id = env.add_object(ball_urdf, ball_pose, color=utils.COLORS[color])  # Add ball with specified color
            ball_ids.append(ball_id)

        # Goal: Stack balls in order on the pallet.
        targets = ['pallet', 'red ball', 'green ball']
        target_poses = [pallet_pose]  # Initial target is the pallet

        for i in range(3):
            # Calculate target pose for each ball (stacking on top of previous object)
            target_pose = (pallet_pose[0], pallet_pose[1], pallet_pose[2] + ball_size[2] * (i + 1))
            target_poses.append(target_pose)

            language_goal = self.lang_template.format(color=colors[i], target=targets[i])
            self.add_goal(objs=[ball_ids[i]], matches=np.ones((1, 1)), targ_poses=[target_pose], replace=False,
                          rotations=True, metric='pose', params=None, step_max_reward=1/3, language_goal=language_goal)

```

================= TRIAL: 1

================= Task and Asset Design!

>>> Prompt: 
You are an AI in robot simulation code and task design. I will provide you some example tasks, code implementation, and some guidelines for how to generate tasks and then you will help me generate a new task. My goal is to design diverse and feasible tasks for tabletop manipulation. I will first ask you to describe the task in natural languages and then will let you write the code for it. 

=========
Here are all the assets. Use only these assets in the task and code design. 
"""
insertion/:
ell.urdf  fixture.urdf

bowl/:
bowl.urdf

box/:
box-template.urdf

stacking/:
block.urdf  stand.urdf

zone/:
zone.obj  zone.urdf

pallet/:
pallet.obj  pallet.urdf

ball/:
ball-template.urdf

cylinder/:
cylinder-template.urdf

bowl/:
bowl.urdf

# assets not for picking
corner/:
corner-template.urdf

line/:
single-green-line-template.urdf

container/:
container-template.urdf
"""
 
=========
Here are some examples of good tasks. Try to learn from these structures but avoid overlapping wiht them.

{"assets-used": ["zone/zone.urdf", "block/small.urdf"],
 "task-description": "Push piles of small objects into a target goal zone marked on the tabletop.",
 "task-name": "sweeping-piles"}

{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "Place all blocks of a specified color in a bowl of specified color.",
 "task-name": "put-block-in-bowl"}
 
{"assets-used": ["insertion/ell.urdf", "insertion/fixture.urdf"],
 "task-description": "pick up the L-shaped red block and place it into the L-shaped fixture.",
 "task-name": "block-insertion"}
 
{"assets-used": ["kitting/kit.urdf", "kitting/object-template.urdf"],
 "task-description": "pick up different objects and arrange them on a board marked with corresponding silhouettes.",
 "task-name": "assembling-kits"}
 
{"assets-used": ["pallet/pallet.urdf", "box/box-template.urdf"],
 "task-description": "pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.",
 "task-name": "palletizing-boxes"}
 
{"assets-used": ["stacking/stand.urdf", "stacking/block.urdf"],
 "task-description": "sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.",
 "task-name": "stack-block-pyramid"}
 
{"assets-used": ["container/container-template.urdf", "box/box-template.urdf"],
 "task-description": "pick up randomly sized boxes and place them tightly into a container.",
 "task-name": "packing-boxes"}
 
{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "pick up the red blocks and place them into the green bowls amidst other objects.",
 "task-name": "place-red-in-green"}
 
{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

=========
Here are some tasks that you have come up with before. Try to learn from these structures but avoid overlapping with these tasks. For instance, `bowl_ball_placement` and `sort_balls_in_bowls` are the same task. `pile_boxes_in_corner` and `stack_blocks_into_pallet` are similar tasks, `align-cylinder-in-corner` and `align-cylinder-corner` are similar.
- sweeping-piles: {'assets-used': ['zone/zone.urdf', 'block/small.urdf'], 'task-description': 'push piles of small objects into a target goal zone marked on the tabletop.', 'task-name': 'sweeping-piles'}
- place-red-in-green: {'assets-used': ['bowl/bowl.urdf', 'stacking/block.urdf'], 'task-description': 'pick up the red blocks and place them into the green bowls amidst other objects.', 'task-name': 'place-red-in-green'}
- align-box-corner: {'assets-used': ['box/box-template.urdf', 'corner/corner-template.urdf'], 'task-description': 'pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..', 'task-name': 'align-box-corner'}
- stack-block-pyramid: {'assets-used': ['stacking/stand.urdf', 'stacking/block.urdf'], 'task-description': 'sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.', 'task-name': 'stack-block-pyramid'}
- palletizing-boxes: {'assets-used': ['pallet/pallet.urdf', 'box/box-template.urdf'], 'task-description': 'pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.', 'task-name': 'palletizing-boxes'}
- assembling-kits: {'assets-used': ['kitting/kit.urdf', 'kitting/object-template.urdf'], 'task-description': 'pick up different objects and arrange them on a board marked with corresponding silhouettes.', 'task-name': 'assembling-kits'}
- packing-boxes: {'assets-used': ['container/container-template.urdf', 'box/box-template.urdf'], 'task-description': 'pick up randomly sized boxes and place them tightly into a container.', 'task-name': 'packing-boxes'}
- manipulating-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'rearrange a deformable rope such that it connects the two endpoints of a 3-sided square.', 'task-name': 'manipulating-rope'}
- align-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'manipulate a deformable rope to connect its end-points between two corners of a 3-sided square.', 'task-name': 'align-rope'}





=========
Here are some bad example task instances with explanations.
{
    "task_name": "sort-color-blocks",
    "task_descriptions": "Pick up differently colored blocks and place them into separate bowls of matching color."
    "assets-used": ["bowl.urdf", "box/box-template.urdf],
}
reasons: not interesting because it overlaps with the current task `put-block-in-bowl`.

{
    "task-name": "guided-ball-maze",
    "task-description": "Navigate a small ball through a maze by tilting the maze board to reach the target zone.",
    "assets-used": ["zone-template.urdf", "square-template.urdf", "ball.urdf", "maze.urdf"],
}
reasons: the language descriptions are too ambiguous. Navigation is also hard to complete. Also maze.urf does not exist.

{
    "task-name": "insert_cylinder_in_sphere",
    "task-description": "Pick up the cylinder and insert it into the sphere with an opening on top.",
    "assets-used": ["cylinder/cylinder-template.urdf", "sphere/sphere-template.urdf"],
}
reasons: this task does not make sense. The sphere does not have an opening on top, and you cannot insert a cylinder into a sphere. Similarly tasks like `insert-ball-into-cylinder` and `cylinder-box-insertion` are invalid.

{
    "task-name": "ball-box-obstacle-course",
    "task-description": "Navigate a ball through an obstacle course created by randomly placed boxes and finally place it inside a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: Navigate the ball is not related to tabletop manipulation tasks.

{
    "task-name": "ball-in-box",
    "task-description": "Use a cable to guide a ball into an open box.",
    "assets-used": ["cable/cable.urdf", "ball/ball-template.urdf", "box/box-template.urdf"]
}
reasons: This task is too hard since it involves interaction of the cable and the ball and cannot be easily completed.

{
    "task-name": "ball-in-container",
    "task-description": "Use the spatula to lift a ball over a wall of boxes and drop it into a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: The only action primitives as pick and place. One cannot use a spatula to lift an object.

{
    "task-name": "line-ball-sorting",
    "task-description": "Move balls of different colors along a single green line, placing each ball in a designated colored box at the end of the line. The challenge includes precision in maintaining the ball on the line and the correct identification of the box color corresponding to each ball.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "line/single-green-line-template.urdf"]
}
reasons: Piling or stacking balls are physically infeasible in the simulation.



=========
Now please describe the new task in natural languages and explain its novelty and challenges. Format the answer in a python dictionary with keys "task-name" and value type string, "task-description" (one specific sentence) and value type string, and "assets-used" and value type list of strings. Note that

- Do not use assets that are not in the list above. 
- Tasks that have more colors and shapes are interesting.
- Be as specific as possible about the number, shape, and color of each asset in the task descriptions. 
- The task need to obey physics and remain feasible.





>>> Answer: 
```python
{
    "task-name": "stack-balls-on-cylinder",
    "task-description": "Stack three different colored balls (red, green, and blue) vertically on top of a upright cylinder.",
    "assets-used": ["ball/ball-template.urdf", "cylinder/cylinder-template.urdf"]
}
```

**Novelty:** This task introduces a stacking challenge involving spherical objects, which are inherently unstable, onto a cylindrical base. This differs from block stacking, which offers flat surfaces for easier placement.  It also encourages precise manipulation and control due to the round shapes involved.

**Challenges:**
* **Stability:**  Maintaining the balance of the balls during stacking is the primary challenge.  Slight inaccuracies in placement can cause the stack to topple.
* **Precision:**  Precise placement of each ball is crucial for successful stacking.  The robot needs to accurately position the balls on top of each other and on the cylinder.
* **Physics:** The task requires a good understanding of the physics engine's behavior with spherical and cylindrical objects.  The robot needs to account for rolling and slipping. 


================= API Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-on-cylinder". Here are some APIs that are defined. Please confirm that you understand these APIs.

"""
class Task():
    """Base Task class."""

    def __init__(self):
        self.ee = Suction
        self.mode = 'train'
        self.sixdof = False
        self.primitive = primitives.PickPlace()
        self.oracle_cams = cameras.Oracle.CONFIG

        # Evaluation epsilons (for pose evaluation metric).
        self.pos_eps = 0.01
        self.rot_eps = np.deg2rad(15)

        # Workspace bounds.
        self.pix_size = 0.003125
        self.bounds = np.array([[0.25, 0.75], [-0.5, 0.5], [0, 0.3]])
        self.zone_bounds = np.copy(self.bounds)

        self.goals = []
        self.lang_goals = []
        self.task_completed_desc = "task completed."
        self.progress = 0
        self._rewards = 0
        self.assets_root = None

    def reset(self, env):
        if not self.assets_root:
            raise ValueError('assets_root must be set for task, '
                             'call set_assets_root().')
        self.goals = []
        self.lang_goals = []
        self.progress = 0  # Task progression metric in range [0, 1].
        self._rewards = 0  # Cumulative returned rewards.

    # -------------------------------------------------------------------------
    # Oracle Agent
    # -------------------------------------------------------------------------

    def oracle(self, env):
        """Oracle agent."""
        OracleAgent = collections.namedtuple('OracleAgent', ['act'])

        def act(obs, info):
            """Calculate action."""

            # Oracle uses perfect RGB-D orthographic images and segmentation masks.
            _, hmap, obj_mask = self.get_true_image(env)

            # Unpack next goal step.
            objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]

            # Match objects to targets without replacement.
            if not replace:

                # Modify a copy of the match matrix.
                matches = matches.copy()

                # Ignore already matched objects.
                for i in range(len(objs)):
                    object_id, (symmetry, _) = objs[i]
                    pose = p.getBasePositionAndOrientation(object_id)
                    targets_i = np.argwhere(matches[i, :]).reshape(-1)
                    for j in targets_i:
                        if self.is_match(pose, targs[j], symmetry):
                            matches[i, :] = 0
                            matches[:, j] = 0

            # Get objects to be picked (prioritize farthest from nearest neighbor).
            nn_dists = []
            nn_targets = []
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                xyz, _ = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                if len(targets_i) > 0:
                    targets_xyz = np.float32([targs[j][0] for j in targets_i])
                    dists = np.linalg.norm(
                        targets_xyz - np.float32(xyz).reshape(1, 3), axis=1)
                    nn = np.argmin(dists)
                    nn_dists.append(dists[nn])
                    nn_targets.append(targets_i[nn])

                # Handle ignored objects.
                else:
                    nn_dists.append(0)
                    nn_targets.append(-1)
            order = np.argsort(nn_dists)[::-1]

            # Filter out matched objects.
            order = [i for i in order if nn_dists[i] > 0]

            pick_mask = None
            for pick_i in order:
                pick_mask = np.uint8(obj_mask == objs[pick_i][0])

                # Erode to avoid picking on edges.
                # pick_mask = cv2.erode(pick_mask, np.ones((3, 3), np.uint8))

                if np.sum(pick_mask) > 0:
                    break

            # Trigger task reset if no object is visible.
            if pick_mask is None or np.sum(pick_mask) == 0:
                self.goals = []
                self.lang_goals = []
                print('Object for pick is not visible. Skipping demonstration.')
                return

            # Get picking pose.
            pick_prob = np.float32(pick_mask)
            pick_pix = utils.sample_distribution(pick_prob)
            # For "deterministic" demonstrations on insertion-easy, use this:
            # pick_pix = (160,80)
            pick_pos = utils.pix_to_xyz(pick_pix, hmap,
                                        self.bounds, self.pix_size)
            pick_pose = (np.asarray(pick_pos), np.asarray((0, 0, 0, 1)))

            # Get placing pose.
            targ_pose = targs[nn_targets[pick_i]]
            obj_pose = p.getBasePositionAndOrientation(objs[pick_i][0])
            if not self.sixdof:
                obj_euler = utils.quatXYZW_to_eulerXYZ(obj_pose[1])
                obj_quat = utils.eulerXYZ_to_quatXYZW((0, 0, obj_euler[2]))
                obj_pose = (obj_pose[0], obj_quat)
            world_to_pick = utils.invert(pick_pose)
            obj_to_pick = utils.multiply(world_to_pick, obj_pose)
            pick_to_obj = utils.invert(obj_to_pick)
            place_pose = utils.multiply(targ_pose, pick_to_obj)

            # Rotate end effector?
            if not rotations:
                place_pose = (place_pose[0], (0, 0, 0, 1))

            place_pose = (np.asarray(place_pose[0]), np.asarray(place_pose[1]))

            return {'pose0': pick_pose, 'pose1': place_pose}

        return OracleAgent(act)

    # -------------------------------------------------------------------------
    # Reward Function and Task Completion Metrics
    # -------------------------------------------------------------------------

    def reward(self):
        """Get delta rewards for current timestep.

        Returns:
          A tuple consisting of the scalar (delta) reward, plus `extras`
            dict which has extra task-dependent info from the process of
            computing rewards that gives us finer-grained details. Use
            `extras` for further data analysis.
        """
        reward, info = 0, {}

        # Unpack next goal step.
        objs, matches, targs, _, _, metric, params, max_reward = self.goals[0]

        # Evaluate by matching object poses.
        if metric == 'pose':
            step_reward = 0
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                pose = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                for j in targets_i:
                    target_pose = targs[j]
                    if self.is_match(pose, target_pose, symmetry):
                        step_reward += max_reward / len(objs)
                        print(f"object {i} match with target {j} rew: {step_reward}")
                        break

        # Evaluate by measuring object intersection with zone.
        elif metric == 'zone':
            zone_pts, total_pts = 0, 0
            obj_pts, zones = params
            for zone_idx, (zone_pose, zone_size) in enumerate(zones):

                # Count valid points in zone.
                for obj_idx, obj_id in enumerate(obj_pts):
                    pts = obj_pts[obj_id]
                    obj_pose = p.getBasePositionAndOrientation(obj_id)
                    world_to_zone = utils.invert(zone_pose)
                    obj_to_zone = utils.multiply(world_to_zone, obj_pose)
                    pts = np.float32(utils.apply(obj_to_zone, pts))
                    if len(zone_size) > 1:
                        valid_pts = np.logical_and.reduce([
                            pts[0, :] > -zone_size[0] / 2, pts[0, :] < zone_size[0] / 2,
                            pts[1, :] > -zone_size[1] / 2, pts[1, :] < zone_size[1] / 2,
                            pts[2, :] < self.zone_bounds[2, 1]])

                    # if zone_idx == matches[obj_idx].argmax():
                    zone_pts += np.sum(np.float32(valid_pts))
                    total_pts += pts.shape[1]
            step_reward = max_reward * (zone_pts / total_pts)

        # Get cumulative rewards and return delta.
        reward = self.progress + step_reward - self._rewards
        self._rewards = self.progress + step_reward

        # Move to next goal step if current goal step is complete.
        if np.abs(max_reward - step_reward) < 0.01:
            self.progress += max_reward  # Update task progress.
            self.goals.pop(0)
            if len(self.lang_goals) > 0:
                self.lang_goals.pop(0)

        return reward, info

    def done(self):
        """Check if the task is done or has failed.

        Returns:
          True if the episode should be considered a success, which we
            use for measuring successes, which is particularly helpful for tasks
            where one may get successes on the very last time step, e.g., getting
            the cloth coverage threshold on the last alllowed action.
            However, for bag-items-easy and bag-items-hard (which use the
            'bag-items' metric), it may be necessary to filter out demos that did
            not attain sufficiently high reward in external code. Currently, this
            is done in `main.py` and its ignore_this_demo() method.
        """
        return (len(self.goals) == 0) or (self._rewards > 0.99)
        # return zone_done or defs_done or goal_done

    # -------------------------------------------------------------------------
    # Environment Helper Functions
    # -------------------------------------------------------------------------

    def is_match(self, pose0, pose1, symmetry):
        """Check if pose0 and pose1 match within a threshold."""

        # Get translational error.
        diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
        dist_pos = np.linalg.norm(diff_pos)

        # Get rotational error around z-axis (account for symmetries).
        diff_rot = 0
        if symmetry > 0:
            rot0 = np.array(utils.quatXYZW_to_eulerXYZ(pose0[1]))[2]
            rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]
            diff_rot = np.abs(rot0 - rot1) % symmetry
            if diff_rot > (symmetry / 2):
                diff_rot = symmetry - diff_rot

        return (dist_pos < self.pos_eps) and (diff_rot < self.rot_eps)

    def get_random_pose(self, env, obj_size):
        """Get random collision-free object pose within workspace bounds."""

        # Get erosion size of object in pixels.
        max_size = np.sqrt(obj_size[0] ** 2 + obj_size[1] ** 2)
        erode_size = int(np.round(max_size / self.pix_size))

        _, hmap, obj_mask = self.get_true_image(env)

        # Randomly sample an object pose within free-space pixels.
        free = np.ones(obj_mask.shape, dtype=np.uint8)
        for obj_ids in env.obj_ids.values():
            for obj_id in obj_ids:
                free[obj_mask == obj_id] = 0
        free[0, :], free[:, 0], free[-1, :], free[:, -1] = 0, 0, 0, 0
        free = cv2.erode(free, np.ones((erode_size, erode_size), np.uint8))

        # if np.sum(free) == 0:
        #     return None, None

        if np.sum(free) == 0:
            # avoid returning None, None
            # return None, None
            pix = (obj_mask.shape[0] // 2, obj_mask.shape[1] // 2)
        else:
            pix = utils.sample_distribution(np.float32(free))
        pos = utils.pix_to_xyz(pix, hmap, self.bounds, self.pix_size)
        pos = (pos[0], pos[1], obj_size[2] / 2)
        theta = np.random.rand() * 2 * np.pi
        rot = utils.eulerXYZ_to_quatXYZW((0, 0, theta))
        return pos, rot

    def get_lang_goal(self):
        if len(self.lang_goals) == 0:
            return self.task_completed_desc
        else:
            return self.lang_goals[0]

    def get_reward(self):
        return float(self._rewards)

    # -------------------------------------------------------------------------
    # Helper Functions
    # -------------------------------------------------------------------------

    def fill_template(self, template, replace):
        """Read a file and replace key strings."""
        full_template_path = os.path.join(self.assets_root, template)
        with open(full_template_path, 'r') as file:
            fdata = file.read()
        for field in replace:
            for i in range(len(replace[field])):
                fdata = fdata.replace(f'{field}{i}', str(replace[field][i]))
        alphabet = string.ascii_lowercase + string.digits
        rname = ''.join(random.choices(alphabet, k=16))
        tmpdir = tempfile.gettempdir()
        template_filename = os.path.split(template)[-1]
        fname = os.path.join(tmpdir, f'{template_filename}.{rname}')
        with open(fname, 'w') as file:
            file.write(fdata)
        return fname

    def get_random_size(self, min_x, max_x, min_y, max_y, min_z, max_z):
        """Get random box size."""
        size = np.random.rand(3)
        size[0] = size[0] * (max_x - min_x) + min_x
        size[1] = size[1] * (max_y - min_y) + min_y
        size[2] = size[2] * (max_z - min_z) + min_z
        return tuple(size)

    def color_random_brown(self, obj):
        shade = np.random.rand() + 0.5
        color = np.float32([shade * 156, shade * 117, shade * 95, 255]) / 255
        p.changeVisualShape(obj, -1, rgbaColor=color)

  """""
  
  # Environment Class
  def add_object(self, urdf, pose, category='rigid'):
    """List of (fixed, rigid, or deformable) objects in env."""
    fixed_base = 1 if category == 'fixed' else 0
    obj_id = pybullet_utils.load_urdf(
        p,
        os.path.join(self.assets_root, urdf),
        pose[0],
        pose[1],
        useFixedBase=fixed_base)
    self.obj_ids[category].append(obj_id)
    return obj_id
"""

=========
Note that the objects need to obey physics and not collide with each other, and the object goal poses need to be above the table with lower bound x=0.25, y=-0.5 and upper bound x=0.75, y=0.5. When there are multiple objects for a multi-step pick-and-place task, there are often multiple subgoals. Once the task and environment are generated, an agent with a pick and place primitive will follow the defined goal to accomplish the tasks. 

Additionally, make sure you understand and summarize the ``self.goals`` variables, which has a list of 8-tuple with (objs, matches, targ_poses, replace, rotations, metric, params, step_max_reward, symmetries).
- objs (List of obj_id): object ID.
- matches (Binary Matrix): a binary matrix that denotes which object is matched with which target. This matrix has dimension len(objs) x len(targs).
- targ_poses (List of Poses [(translation, rotation)] ): a list of target poses of tuple (translation, rotation). 
- replace (Boolean): whether each object can match with one unique target. This is important if we have one target and multiple objects. If it's set to be false, then any object matching with the target will satisfy.
- rotations (Boolean): whether the placement action has a rotation degree of freedom. 
- metric (`pose` or `zone`): `pose` or `zone` that the object needs to be transported to. Example: `pose`. 
- params (List of (zone_target, zone_size)): a list of (zone_target, zone_size) for each zone if the metric is `zone`. 
- step_max_reward (float): the total reward of matching all the objects with all the target poses. It is not dependent on the number of objects but dependent on the number of goals. 
- symmetries: the radians that the object is symmetric around z axis.
- language_goal: the low-level language instructions that denote the goal of this step.
 


>>> Answer: 
Yes, I understand the provided APIs and their intended usage. Here's a summary of my understanding:

**Task Class:**

The `Task` class defines the base structure and functionality for a manipulation task. It handles aspects like:

* **End-Effector:**  Uses a suction-based end-effector (`self.ee = Suction`).
* **Mode:**  Operates in either 'train' or 'eval' mode (`self.mode`).
* **Pick and Place Primitive:** Uses a `PickPlace` primitive for actions (`self.primitive`).
* **Oracle:**  Includes an oracle agent for demonstration generation.
* **Evaluation Metrics:** Defines position and rotation tolerances for evaluating pose matching (`self.pos_eps`, `self.rot_eps`).
* **Workspace and Zone Bounds:** Specifies the workspace boundaries and a zone within it (`self.bounds`, `self.zone_bounds`).
* **Goals:** Stores a list of goals, each represented by an 8-tuple (explained below).
* **Language Goals:** Stores corresponding language descriptions for each goal.
* **Reward Calculation:** Implements a `reward()` function to calculate rewards based on goal completion.
* **Task Completion:**  Provides a `done()` function to check if the task is finished.
* **Helper Functions:** Includes various helper functions for pose generation, template filling, size randomization, and collision checking.

**Environment Interaction:**

The `add_object` function within the environment class allows adding objects (fixed, rigid, or deformable) to the simulation environment, specifying their URDF, initial pose, and category.

**`self.goals` Structure:**

The `self.goals` variable is crucial. Each element is an 8-tuple representing a subgoal:

1. **`objs`:** A list of object IDs involved in the subgoal.
2. **`matches`:** A binary matrix indicating which object should be matched with which target pose.  Rows correspond to objects, columns to target poses. A '1' at `matches[i, j]` means object `i` should be placed at target pose `j`.
3. **`targ_poses`:** A list of target poses, each a tuple of (position, orientation quaternion).
4. **`replace`:** A boolean flag. If `False`, each object can only match with one unique target. If `True`, multiple objects can be placed at the same target.
5. **`rotations`:** A boolean flag. If `True`, the placement action considers the end-effector's rotation. If `False`, rotation is ignored.
6. **`metric`:** A string indicating the reward metric ('pose' or 'zone').  'pose' checks if object poses match target poses. 'zone' checks if objects are within a specified zone.
7. **`params`:**  If `metric` is 'zone', this contains a list of (zone_pose, zone_size) tuples defining the target zones.
8. **`step_max_reward`:** The maximum reward achievable for this subgoal.

**Key Considerations for Code Implementation:**

* **Physics and Collision Avoidance:**  Ensure that objects interact realistically with physics and avoid collisions, both with each other and the environment.
* **Goal Pose Constraints:**  Target poses should be above the table within the specified x and y bounds.
* **Multi-Step Tasks:**  Handle multiple subgoals sequentially, updating `self.goals` as subgoals are completed.
* **Pick and Place Primitive:**  Utilize the `PickPlace` primitive effectively for actions.
* **Reward Function:**  Implement the `reward()` function correctly to reflect the chosen metric ('pose' or 'zone').
* **Task Completion:**  The `done()` function should accurately signal task completion.


By adhering to these guidelines and understanding the provided APIs, you can effectively implement the "stack-balls-on-cylinder" task.  The clear definition of goals, metrics, and helper functions provides a solid foundation for developing a robust and efficient solution.


================= Error Book Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-on-cylinder". Here are some runtime errors that you do not want to make. Please confirm that you understand these runtime errors.

"""
- environment.py, line 338, in info
    pos, rot = p.getBasePositionAndOrientation(obj_id)
TypeError: an integer is required (got type NoneType)

- task.py, line 118, in act
    objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]
IndexError: list index out of range

- task.py, line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
TypeError: 'float' object is not subscriptable

- task.py", line 315, in is_match
  rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]

- utils.py", line 280, in quatXYZW_to_eulerXYZ
  quaternion_wxyz = np.array([q[3], q[0], q[1], q[2]])
IndexError: tuple index out of range

- pallet_pose = self.get_random_pose(env, pallet_size)
pallet_surface_height = pallet_pose[0][2]
TypeError: 'NoneType' object is not subscriptable

- No such file or directory: './cliport/environments/assets/circle/circle-template.urdf'

- No such file or directory: './cliport/environments/assets/block/block-template.urdf'

- task.py", line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
IndexError: invalid index to scalar variable.

-TypeError: get_random_size() missing 4 required positional arguments: 'min_y', 'max_y', 'min_z', and 'max_z' 

- task.py", line 195, in reward
    obj_pts, zones = params
TypeError: cannot unpack non-iterable NoneType object

-  environment.py", line 230, in step
    reward, info = self.task.reward() if action is not None else (0, {})
  File "task.py", line 200, in reward
    pts = obj_pts[obj_id]
IndexError: arrays used as indices must be of integer (or boolean) type

- generated_task.py", line 41, in reset
    utils.COLORS['green'], utils.COLORS['blue'], utils.COLORS['light blue'],
KeyError: 'light blue'

- environment.py", line 195, in reset
    self.task.reset(self)
  File "<string>", line 38, in reset
TypeError: can only concatenate str (not "list") to str

- environment.py", line 195, in reset
  object_shape = np.random.choice(object_shapes)
  in numpy.random.mtrand.RandomState.choice
ValueError: a must be 1-dimensional

- No such file or directory: 'assets/box-template/box-template.urdf'

- line 38, in reset.py
{'HALF': box_size / 2}
TypeError: unsupported operand type(s) for /: 'tuple' and 'int'. box_size is a tuple not a float.

- line 38, in reset.py
IndexError: tuple index out of range
box_pose = (pallet_pose[0], pallet_pose[1], pallet_pose[2] + np.sum(box_sizes[:i+1]))

- task.py", line 338, in fill_template
    for i in range(len(replace[field])):
TypeError: object of type 'float' has no len().

- task.py", line 325, in get_random_pose
    pos = (pos[0], pos[1], obj_size[2] / 2)
IndexError: tuple index out of range

- task.py", line 206, in reward
    for zone_idx, (zone_pose, zone_size) in enumerate(zones):
TypeError: 'NoneType' object is not iterable

- task.py",
ball_pose = self.get_random_pose(env, ball_size)
ball_pose[0][2] += 0.02
TypeError: 'tuple' object does not support item assignment
"""


You do not want to make mistakes such as
- using assets (urdfs) that do not exist
- use ambiguous language descriptions as goals. For instance, "place the colored blocks into the matching colored bowls" with one goal and sparse reward as the task instead of adding subgoal "place blue block into blue bowl" and give continuous reward. 
- `matches` in the goal has wrong dimensions. It should have the same dimensions as number of objects (N) multiplied by the number of goal poses (M). Usually it is N by M.
- have vector dimension problem such as `np.random.choice(box_size)` or `box_size / 2` where `box_size` is a tuple and not an int
- make too large an object for stacking or make the task objects invisible for picking. 
- accessing index out of bound `pallet_pose[2]` for `pallet_pose`.  `pallet_pose=get_random_pose` returns a tuple (translation, rotation). It does not have 3rd component. Similarly accessing `container_pose[2]` or `box_pose[2]` would cause errors as well. Since it's a tuple, try to modify it in-place will also trigger errors.
- forget to replace str using `fill_template()` for urdfs with template such as `cylinder-template.urdf`. `ball-template.urdf`, `line-template.urf`. 
- use `self.ee = Spatula()` as a function when doing pushing tasks, which is incorrect. It should be `self.ee = Spatula`.
- forget to compute target poses `targ_poses` for matching. Do not use object IDs for poses.
- change colors of complex objects such as `zone`. You can only change color of teomplate primitive such as `cylinder-template`.
- mistakenly use `random_pose` for target pose. Design target poses based on task objectives.
- add only one or fewer language goals which causes language-motion inconsistentcy. Note that the language goals usually are the same number as the pick and place goals.


>>> Answer: 
Yes, I understand the runtime errors listed and the additional points you've made about avoiding mistakes in task generation. I will be mindful of these issues when writing the code for the "stack-balls-on-cylinder" task.  I will pay particular attention to:

* **File Paths and Existence:** Verify that all URDF files exist in the correct locations.
* **Clear Language Goals:**  Provide specific and unambiguous language descriptions for each sub-goal, avoiding vague phrasing.
* **Matches Dimensions:** Ensure the `matches` array has the correct dimensions (N x M), reflecting the number of objects and target poses.
* **Vector Operations:**  Handle vector and scalar operations correctly, paying attention to the dimensions of variables like `box_size`.  Avoid operations like division or random choice on tuples directly.
* **Object Sizes and Visibility:** Keep object sizes reasonable for stacking and ensure they are visible for picking.
* **Pose Indexing:** Access pose components correctly, remembering that `get_random_pose` returns a (position, rotation) tuple. Avoid invalid indexing like `pallet_pose[2]` and in-place modification of tuples.
* **Template Filling:** Use `fill_template()` to replace placeholders in URDF files with specific values.
* **Spatula Initialization:** Initialize the spatula correctly using `self.ee = Spatula`, not `self.ee = Spatula()`.
* **Target Pose Calculation:** Explicitly calculate target poses (`targ_poses`) based on the task objectives, not object IDs.
* **Color Changes:** Only change colors of primitive template objects, not complex objects like zones.
* **Random Poses vs. Designed Poses:** Use `random_pose` appropriately and design specific target poses for matching.
* **Sufficient Language Goals:** Provide enough language goals to match the number of pick-and-place actions, ensuring language-motion consistency.


By addressing these points, I aim to avoid the listed runtime errors and create a robust and functional "stack-balls-on-cylinder" task.


================= Code Generation!

>>> Prompt: 
Now I will provide you some reference code and you can write the code for the task "stack-balls-on-cylinder".


"""
import os

import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils


class PackingShapes(Task):
    """pick up randomly sized shapes and place them tightly into a container."""

    def __init__(self):
        super().__init__()
        self.max_steps = 1
        self.homogeneous = False

        self.lang_template = "pack the {obj} in the brown box"
        self.task_completed_desc = "done packing shapes."
        self.additional_reset()


    def reset(self, env):
        super().reset(env)

        # Shape Names:
        shapes = utils.assembling_kit_shapes

        n_objects = 5
        if self.mode == 'train':
            obj_shapes = np.random.choice(self.train_set, n_objects, replace=False)
        else:
            if self.homogeneous:
                obj_shapes = [np.random.choice(self.test_set, replace=False)] * n_objects
            else:
                obj_shapes = np.random.choice(self.test_set, n_objects, replace=False)

        # Shuffle colors to avoid always picking an object of the same color
        colors, color_names = utils.get_colors(mode=self.mode)

        # Add container box.
        zone_size = self.get_random_size(0.1, 0.15, 0.1, 0.15, 0.05, 0.05)
        zone_pose = self.get_random_pose(env, zone_size)
        container_template = 'container/container-template.urdf'
        replace = {'DIM': zone_size, 'HALF': (zone_size[0] / 2, zone_size[1] / 2, zone_size[2] / 2)}
        # IMPORTANT: REPLACE THE TEMPLATE URDF with `fill_template`
        container_urdf = self.fill_template(container_template, replace)
        env.add_object(container_urdf, zone_pose, 'fixed')

        # Add objects.
        objects = []
        template = 'kitting/object-template.urdf'
        for i in range(n_objects):
            shape = obj_shapes[i]

            # x, y, z dimensions for the asset size
            size = (0.08, 0.08, 0.02)
            pose= self.get_random_pose(env, size)
            fname = f'{shape:02d}.obj'
            fname = os.path.join(self.assets_root, 'kitting', fname)
            scale = [0.003, 0.003, 0.001]  # .0005
            replace = {'FNAME': (fname,),
                       'SCALE': scale,
                       'COLOR': colors[i]}

            # IMPORTANT: REPLACE THE TEMPLATE URDF
            urdf = self.fill_template(template, replace)
            block_id = env.add_object(urdf, pose)
            objects.append(block_id)

        # Pick the first shape.
        num_objects_to_pick = 1
        for i in range(num_objects_to_pick):
            # IMPORTANT: Specify (obj_pts, [(zone_pose, zone_size)]) for target `zone`. obj_pts is a dict
            language_goal = self.lang_template.format(obj=shapes[obj_shapes[i]])
            self.add_goal(objs=[objects[i]], matches=np.int32([[1]]), targ_poses=[zone_pose], replace=False,
                rotations=True, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1 / num_objects_to_pick,
                language_goal=language_goal)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p


class PlaceRedInGreen(Task):
    """pick up the red blocks and place them into the green bowls amidst other objects."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "put the red blocks in a green bowl"
        self.task_completed_desc = "done placing blocks in bowls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)
        n_bowls = np.random.randint(1, 4)
        n_blocks = np.random.randint(1, n_bowls + 1)

        # Add bowls.
        # x, y, z dimensions for the asset size
        bowl_size = (0.12, 0.12, 0)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_poses = []
        for _ in range(n_bowls):
            bowl_pose = self.get_random_pose(env, obj_size=bowl_size)
            env.add_object(urdf=bowl_urdf, pose=bowl_pose, category='fixed')
            bowl_poses.append(bowl_pose)

        # Add blocks.
        # x, y, z dimensions for the asset size
        blocks = []
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'
        for _ in range(n_blocks):
            block_pose = self.get_random_pose(env, obj_size=block_size)
            block_id = env.add_object(block_urdf, block_pose)
            blocks.append(block_id)

        # Goal: each red block is in a different green bowl.
        self.add_goal(objs=blocks, matches=np.ones((len(blocks), len(bowl_poses))), targ_poses=bowl_poses, replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1, language_goal=self.lang_template)

        # Colors of distractor objects.
        bowl_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'green']
        block_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'red']

        # Add distractors.
        n_distractors = 0
        while n_distractors < 6:
            is_block = np.random.rand() > 0.5
            urdf = block_urdf if is_block else bowl_urdf
            size = block_size if is_block else bowl_size
            colors = block_colors if is_block else bowl_colors
            pose = self.get_random_pose(env, obj_size=size)
            color = colors[n_distractors % len(colors)]

            obj_id = env.add_object(urdf, pose, color=color)
            n_distractors += 1
"""
"""
import numpy as np
from cliport.tasks import primitives
from cliport.tasks.grippers import Spatula
from cliport.tasks.task import Task
from cliport.utils import utils


class SweepingPiles(Task):
    """Push piles of small objects into a target goal zone marked on the tabletop."""

    def __init__(self):
        super().__init__()
        self.max_steps = 20
        self.lang_template = "push the pile of blocks into the green square"
        self.task_completed_desc = "done sweeping."
        self.primitive = primitives.push
        self.ee = Spatula
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add goal zone.
        zone_size = (0.12, 0.12, 0)
        zone_pose = self.get_random_pose(env, zone_size)
        env.add_object('zone/zone.urdf', zone_pose, 'fixed')

        # Add pile of small blocks with `make_piles` function
        obj_ids = self.make_piles(env)

        # Add goal
        self.add_goal(objs=obj_ids, matches=np.ones((50, 1)), targ_poses=[zone_pose], replace=True,
                rotations=False, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1, language_goal=self.lang_template)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p

class StackBlockPyramid(Task):
    """Build a pyramid of colored blocks in a color sequence"""

    def __init__(self):
        super().__init__()
        self.max_steps = 12
        self.lang_template = "make the {row} row with {blocks}"
        self.task_completed_desc = "done stacking block pyramid."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add base.
        base_size = (0.05, 0.15, 0.005)
        base_urdf = 'stacking/stand.urdf'
        base_pose = self.get_random_pose(env, base_size)
        env.add_object(base_urdf, base_pose, category='fixed')

        # Block colors.
        colors = [
            utils.COLORS['purple'], utils.COLORS['blue'], utils.COLORS['green'],
            utils.COLORS['yellow'], utils.COLORS['orange'], utils.COLORS['red']
        ]

        # Add blocks.
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'

        objs = []
        for i in range(6):
            block_pose = self.get_random_pose(env, block_size)
            block_id = env.add_object(block_urdf, block_pose, color=colors[i])
            objs.append(block_id)

        # IMPORTANT Associate placement locations for goals.
        place_pos = [(0, -0.05, 0.03), (0, 0, 0.03),
                     (0, 0.05, 0.03), (0, -0.025, 0.08),
                     (0, 0.025, 0.08), (0, 0, 0.13)]
        targs = [(utils.apply(base_pose, i), base_pose[1]) for i in place_pos]

        # Goal: blocks are stacked in a pyramid (bottom row: green, blue, purple).
        language_goal = self.lang_template.format(blocks="the green, blue and purple blocks", row="bottom")
        self.add_goal(objs=objs[:3], matches=np.ones((3, 3)), targ_poses=targs[:3], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 2, symmetries=[np.pi/2]*3, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (middle row: yellow, orange).
        language_goal = self.lang_template.format(blocks="the yellow and orange blocks", row="middle")      
        self.add_goal(objs=objs[3:5], matches=np.ones((2, 2)), targ_poses=targs[3:5], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 3, symmetries=[np.pi/2]*2, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (top row: red).
        language_goal = self.lang_template.format(blocks="the red block", row="top")
        self.add_goal(objs=objs[5:], matches=np.ones((1, 1)), targ_poses=targs[5:], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 6, symmetries=[np.pi/2]*1, language_goal=language_goal)
"""



Do not use libraries, functions, and assets that you don't know. For each object, try to describe its color, size, category in the task first before you write the code. You do not need extra helper functions. Comment the code liberally to explain what each piece does and why it's written that way. If you have only one goal, `step_max_reward` in `add_goal` should be 1. Use functions `make_piles` and `make_ropes` for creating piles and cables. To use spatula together with the push primitives, import the libraries 
"""
from cliport.tasks import primitives;
from cliport.tasks.grippers import Spatula
"""
and then use `self.primitive = primitives.push` and `self.ee = Spatula`.
Note that the number of language goals usually match the number of motion goals, since they should correspond to each other.

Now write the code for the task "stack-balls-on-cylinder" in python code block starting with ```python.  Reminder: {'task-name': 'stack-balls-on-cylinder', 'task-description': 'Stack three different colored balls (red, green, and blue) vertically on top of a upright cylinder.', 'assets-used': ['ball/ball-template.urdf', 'cylinder/cylinder-template.urdf']} 


>>> Answer: 
```python
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils

class StackBallsOnCylinder(Task):
    """Stack three different colored balls (red, green, and blue) vertically on top of a upright cylinder."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "stack the {color} ball on the {other_color} ball"
        self.task_completed_desc = "done stacking balls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Cylinder: Gray, radius=0.03, height=0.1
        cylinder_size = (0.03, 0.1)  # radius, height
        cylinder_pose = self.get_random_pose(env, cylinder_size)
        cylinder_urdf = 'cylinder/cylinder-template.urdf'
        cylinder_id = env.add_object(cylinder_urdf, cylinder_pose, color=utils.COLORS['gray'])

        # Balls: red, green, blue, radius=0.03
        ball_size = (0.03,) # radius
        ball_urdf = 'ball/ball-template.urdf'
        colors = ['red', 'green', 'blue']
        ball_ids = []
        for color in colors:
            ball_pose = self.get_random_pose(env, ball_size)
            ball_id = env.add_object(ball_urdf, ball_pose, color=utils.COLORS[color])
            ball_ids.append(ball_id)

        # Target poses for the balls on the cylinder.
        targ_poses = []
        z_offset = 0.1  # Cylinder height
        for i in range(3):
            targ_pose = (cylinder_pose[0], cylinder_pose[1] + np.array([0, 0, z_offset + i * 2 * ball_size[0]])) # position, rotation
            targ_poses.append(targ_pose)

        # Goal 1: Place the red ball on the cylinder.
        language_goal = "place the red ball on the cylinder"
        self.add_goal(objs=[ball_ids[0]], matches=np.ones((1, 1)), targ_poses=[targ_poses[0]], replace=False,
                      rotations=True, metric='pose', params=None, step_max_reward=1/3, language_goal=language_goal)

        # Goal 2: Place the green ball on the red ball.
        language_goal = self.lang_template.format(color="green", other_color="red")
        self.add_goal(objs=[ball_ids[1]], matches=np.ones((1, 1)), targ_poses=[targ_poses[1]], replace=False,
                      rotations=True, metric='pose', params=None, step_max_reward=1/3, language_goal=language_goal)

        # Goal 3: Place the blue ball on the green ball.
        language_goal = self.lang_template.format(color="blue", other_color="green")
        self.add_goal(objs=[ball_ids[2]], matches=np.ones((1, 1)), targ_poses=[targ_poses[2]], replace=False,
                      rotations=True, metric='pose', params=None, step_max_reward=1/3, language_goal=language_goal)

```


================= TRIAL: 2

================= Task and Asset Design!

>>> Prompt: 
You are an AI in robot simulation code and task design. I will provide you some example tasks, code implementation, and some guidelines for how to generate tasks and then you will help me generate a new task. My goal is to design diverse and feasible tasks for tabletop manipulation. I will first ask you to describe the task in natural languages and then will let you write the code for it. 

=========
Here are all the assets. Use only these assets in the task and code design. 
"""
insertion/:
ell.urdf  fixture.urdf

bowl/:
bowl.urdf

box/:
box-template.urdf

stacking/:
block.urdf  stand.urdf

zone/:
zone.obj  zone.urdf

pallet/:
pallet.obj  pallet.urdf

ball/:
ball-template.urdf

cylinder/:
cylinder-template.urdf

bowl/:
bowl.urdf

# assets not for picking
corner/:
corner-template.urdf

line/:
single-green-line-template.urdf

container/:
container-template.urdf
"""
 
=========
Here are some examples of good tasks. Try to learn from these structures but avoid overlapping wiht them.

{"assets-used": ["zone/zone.urdf", "block/small.urdf"],
 "task-description": "Push piles of small objects into a target goal zone marked on the tabletop.",
 "task-name": "sweeping-piles"}

{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "Place all blocks of a specified color in a bowl of specified color.",
 "task-name": "put-block-in-bowl"}
 
{"assets-used": ["insertion/ell.urdf", "insertion/fixture.urdf"],
 "task-description": "pick up the L-shaped red block and place it into the L-shaped fixture.",
 "task-name": "block-insertion"}
 
{"assets-used": ["kitting/kit.urdf", "kitting/object-template.urdf"],
 "task-description": "pick up different objects and arrange them on a board marked with corresponding silhouettes.",
 "task-name": "assembling-kits"}
 
{"assets-used": ["pallet/pallet.urdf", "box/box-template.urdf"],
 "task-description": "pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.",
 "task-name": "palletizing-boxes"}
 
{"assets-used": ["stacking/stand.urdf", "stacking/block.urdf"],
 "task-description": "sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.",
 "task-name": "stack-block-pyramid"}
 
{"assets-used": ["container/container-template.urdf", "box/box-template.urdf"],
 "task-description": "pick up randomly sized boxes and place them tightly into a container.",
 "task-name": "packing-boxes"}
 
{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "pick up the red blocks and place them into the green bowls amidst other objects.",
 "task-name": "place-red-in-green"}
 
{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

=========
Here are some tasks that you have come up with before. Try to learn from these structures but avoid overlapping with these tasks. For instance, `bowl_ball_placement` and `sort_balls_in_bowls` are the same task. `pile_boxes_in_corner` and `stack_blocks_into_pallet` are similar tasks, `align-cylinder-in-corner` and `align-cylinder-corner` are similar.
- sweeping-piles: {'assets-used': ['zone/zone.urdf', 'block/small.urdf'], 'task-description': 'push piles of small objects into a target goal zone marked on the tabletop.', 'task-name': 'sweeping-piles'}
- place-red-in-green: {'assets-used': ['bowl/bowl.urdf', 'stacking/block.urdf'], 'task-description': 'pick up the red blocks and place them into the green bowls amidst other objects.', 'task-name': 'place-red-in-green'}
- align-box-corner: {'assets-used': ['box/box-template.urdf', 'corner/corner-template.urdf'], 'task-description': 'pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..', 'task-name': 'align-box-corner'}
- stack-block-pyramid: {'assets-used': ['stacking/stand.urdf', 'stacking/block.urdf'], 'task-description': 'sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.', 'task-name': 'stack-block-pyramid'}
- palletizing-boxes: {'assets-used': ['pallet/pallet.urdf', 'box/box-template.urdf'], 'task-description': 'pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.', 'task-name': 'palletizing-boxes'}
- assembling-kits: {'assets-used': ['kitting/kit.urdf', 'kitting/object-template.urdf'], 'task-description': 'pick up different objects and arrange them on a board marked with corresponding silhouettes.', 'task-name': 'assembling-kits'}
- packing-boxes: {'assets-used': ['container/container-template.urdf', 'box/box-template.urdf'], 'task-description': 'pick up randomly sized boxes and place them tightly into a container.', 'task-name': 'packing-boxes'}
- manipulating-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'rearrange a deformable rope such that it connects the two endpoints of a 3-sided square.', 'task-name': 'manipulating-rope'}
- align-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'manipulate a deformable rope to connect its end-points between two corners of a 3-sided square.', 'task-name': 'align-rope'}





=========
Here are some bad example task instances with explanations.
{
    "task_name": "sort-color-blocks",
    "task_descriptions": "Pick up differently colored blocks and place them into separate bowls of matching color."
    "assets-used": ["bowl.urdf", "box/box-template.urdf],
}
reasons: not interesting because it overlaps with the current task `put-block-in-bowl`.

{
    "task-name": "guided-ball-maze",
    "task-description": "Navigate a small ball through a maze by tilting the maze board to reach the target zone.",
    "assets-used": ["zone-template.urdf", "square-template.urdf", "ball.urdf", "maze.urdf"],
}
reasons: the language descriptions are too ambiguous. Navigation is also hard to complete. Also maze.urf does not exist.

{
    "task-name": "insert_cylinder_in_sphere",
    "task-description": "Pick up the cylinder and insert it into the sphere with an opening on top.",
    "assets-used": ["cylinder/cylinder-template.urdf", "sphere/sphere-template.urdf"],
}
reasons: this task does not make sense. The sphere does not have an opening on top, and you cannot insert a cylinder into a sphere. Similarly tasks like `insert-ball-into-cylinder` and `cylinder-box-insertion` are invalid.

{
    "task-name": "ball-box-obstacle-course",
    "task-description": "Navigate a ball through an obstacle course created by randomly placed boxes and finally place it inside a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: Navigate the ball is not related to tabletop manipulation tasks.

{
    "task-name": "ball-in-box",
    "task-description": "Use a cable to guide a ball into an open box.",
    "assets-used": ["cable/cable.urdf", "ball/ball-template.urdf", "box/box-template.urdf"]
}
reasons: This task is too hard since it involves interaction of the cable and the ball and cannot be easily completed.

{
    "task-name": "ball-in-container",
    "task-description": "Use the spatula to lift a ball over a wall of boxes and drop it into a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: The only action primitives as pick and place. One cannot use a spatula to lift an object.

{
    "task-name": "line-ball-sorting",
    "task-description": "Move balls of different colors along a single green line, placing each ball in a designated colored box at the end of the line. The challenge includes precision in maintaining the ball on the line and the correct identification of the box color corresponding to each ball.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "line/single-green-line-template.urdf"]
}
reasons: Piling or stacking balls are physically infeasible in the simulation.



=========
Now please describe the new task in natural languages and explain its novelty and challenges. Format the answer in a python dictionary with keys "task-name" and value type string, "task-description" (one specific sentence) and value type string, and "assets-used" and value type list of strings. Note that

- Do not use assets that are not in the list above. 
- Tasks that have more colors and shapes are interesting.
- Be as specific as possible about the number, shape, and color of each asset in the task descriptions. 
- The task need to obey physics and remain feasible.





>>> Answer: 
```python
{
    "task-name": "stack-balls-in-bowls",
    "task-description": "Pick up three different colored balls (red, green, and blue) and stack them inside three correspondingly colored bowls (red, green, and blue).",
    "assets-used": ["ball/ball-template.urdf", "bowl/bowl.urdf"]
}
```

**Novelty and Challenges:**

This task introduces the challenge of stacking balls, which are unstable, within the concavity of bowls. While placing objects in bowls has been explored (e.g., `put-block-in-bowl`), stacking balls introduces instability and requires precise placement to prevent the balls from rolling out. The color matching adds a further layer of complexity, requiring the robot to differentiate and correctly place the balls in their corresponding bowls.  It combines aspects of stacking and color sorting, making it different from previous examples.  It is different from placing blocks in bowls because the round shape of the balls makes them harder to grasp and stack stably, especially inside the curved surface of a bowl.


================= API Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-in-bowls". Here are some APIs that are defined. Please confirm that you understand these APIs.

"""
class Task():
    """Base Task class."""

    def __init__(self):
        self.ee = Suction
        self.mode = 'train'
        self.sixdof = False
        self.primitive = primitives.PickPlace()
        self.oracle_cams = cameras.Oracle.CONFIG

        # Evaluation epsilons (for pose evaluation metric).
        self.pos_eps = 0.01
        self.rot_eps = np.deg2rad(15)

        # Workspace bounds.
        self.pix_size = 0.003125
        self.bounds = np.array([[0.25, 0.75], [-0.5, 0.5], [0, 0.3]])
        self.zone_bounds = np.copy(self.bounds)

        self.goals = []
        self.lang_goals = []
        self.task_completed_desc = "task completed."
        self.progress = 0
        self._rewards = 0
        self.assets_root = None

    def reset(self, env):
        if not self.assets_root:
            raise ValueError('assets_root must be set for task, '
                             'call set_assets_root().')
        self.goals = []
        self.lang_goals = []
        self.progress = 0  # Task progression metric in range [0, 1].
        self._rewards = 0  # Cumulative returned rewards.

    # -------------------------------------------------------------------------
    # Oracle Agent
    # -------------------------------------------------------------------------

    def oracle(self, env):
        """Oracle agent."""
        OracleAgent = collections.namedtuple('OracleAgent', ['act'])

        def act(obs, info):
            """Calculate action."""

            # Oracle uses perfect RGB-D orthographic images and segmentation masks.
            _, hmap, obj_mask = self.get_true_image(env)

            # Unpack next goal step.
            objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]

            # Match objects to targets without replacement.
            if not replace:

                # Modify a copy of the match matrix.
                matches = matches.copy()

                # Ignore already matched objects.
                for i in range(len(objs)):
                    object_id, (symmetry, _) = objs[i]
                    pose = p.getBasePositionAndOrientation(object_id)
                    targets_i = np.argwhere(matches[i, :]).reshape(-1)
                    for j in targets_i:
                        if self.is_match(pose, targs[j], symmetry):
                            matches[i, :] = 0
                            matches[:, j] = 0

            # Get objects to be picked (prioritize farthest from nearest neighbor).
            nn_dists = []
            nn_targets = []
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                xyz, _ = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                if len(targets_i) > 0:
                    targets_xyz = np.float32([targs[j][0] for j in targets_i])
                    dists = np.linalg.norm(
                        targets_xyz - np.float32(xyz).reshape(1, 3), axis=1)
                    nn = np.argmin(dists)
                    nn_dists.append(dists[nn])
                    nn_targets.append(targets_i[nn])

                # Handle ignored objects.
                else:
                    nn_dists.append(0)
                    nn_targets.append(-1)
            order = np.argsort(nn_dists)[::-1]

            # Filter out matched objects.
            order = [i for i in order if nn_dists[i] > 0]

            pick_mask = None
            for pick_i in order:
                pick_mask = np.uint8(obj_mask == objs[pick_i][0])

                # Erode to avoid picking on edges.
                # pick_mask = cv2.erode(pick_mask, np.ones((3, 3), np.uint8))

                if np.sum(pick_mask) > 0:
                    break

            # Trigger task reset if no object is visible.
            if pick_mask is None or np.sum(pick_mask) == 0:
                self.goals = []
                self.lang_goals = []
                print('Object for pick is not visible. Skipping demonstration.')
                return

            # Get picking pose.
            pick_prob = np.float32(pick_mask)
            pick_pix = utils.sample_distribution(pick_prob)
            # For "deterministic" demonstrations on insertion-easy, use this:
            # pick_pix = (160,80)
            pick_pos = utils.pix_to_xyz(pick_pix, hmap,
                                        self.bounds, self.pix_size)
            pick_pose = (np.asarray(pick_pos), np.asarray((0, 0, 0, 1)))

            # Get placing pose.
            targ_pose = targs[nn_targets[pick_i]]
            obj_pose = p.getBasePositionAndOrientation(objs[pick_i][0])
            if not self.sixdof:
                obj_euler = utils.quatXYZW_to_eulerXYZ(obj_pose[1])
                obj_quat = utils.eulerXYZ_to_quatXYZW((0, 0, obj_euler[2]))
                obj_pose = (obj_pose[0], obj_quat)
            world_to_pick = utils.invert(pick_pose)
            obj_to_pick = utils.multiply(world_to_pick, obj_pose)
            pick_to_obj = utils.invert(obj_to_pick)
            place_pose = utils.multiply(targ_pose, pick_to_obj)

            # Rotate end effector?
            if not rotations:
                place_pose = (place_pose[0], (0, 0, 0, 1))

            place_pose = (np.asarray(place_pose[0]), np.asarray(place_pose[1]))

            return {'pose0': pick_pose, 'pose1': place_pose}

        return OracleAgent(act)

    # -------------------------------------------------------------------------
    # Reward Function and Task Completion Metrics
    # -------------------------------------------------------------------------

    def reward(self):
        """Get delta rewards for current timestep.

        Returns:
          A tuple consisting of the scalar (delta) reward, plus `extras`
            dict which has extra task-dependent info from the process of
            computing rewards that gives us finer-grained details. Use
            `extras` for further data analysis.
        """
        reward, info = 0, {}

        # Unpack next goal step.
        objs, matches, targs, _, _, metric, params, max_reward = self.goals[0]

        # Evaluate by matching object poses.
        if metric == 'pose':
            step_reward = 0
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                pose = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                for j in targets_i:
                    target_pose = targs[j]
                    if self.is_match(pose, target_pose, symmetry):
                        step_reward += max_reward / len(objs)
                        print(f"object {i} match with target {j} rew: {step_reward}")
                        break

        # Evaluate by measuring object intersection with zone.
        elif metric == 'zone':
            zone_pts, total_pts = 0, 0
            obj_pts, zones = params
            for zone_idx, (zone_pose, zone_size) in enumerate(zones):

                # Count valid points in zone.
                for obj_idx, obj_id in enumerate(obj_pts):
                    pts = obj_pts[obj_id]
                    obj_pose = p.getBasePositionAndOrientation(obj_id)
                    world_to_zone = utils.invert(zone_pose)
                    obj_to_zone = utils.multiply(world_to_zone, obj_pose)
                    pts = np.float32(utils.apply(obj_to_zone, pts))
                    if len(zone_size) > 1:
                        valid_pts = np.logical_and.reduce([
                            pts[0, :] > -zone_size[0] / 2, pts[0, :] < zone_size[0] / 2,
                            pts[1, :] > -zone_size[1] / 2, pts[1, :] < zone_size[1] / 2,
                            pts[2, :] < self.zone_bounds[2, 1]])

                    # if zone_idx == matches[obj_idx].argmax():
                    zone_pts += np.sum(np.float32(valid_pts))
                    total_pts += pts.shape[1]
            step_reward = max_reward * (zone_pts / total_pts)

        # Get cumulative rewards and return delta.
        reward = self.progress + step_reward - self._rewards
        self._rewards = self.progress + step_reward

        # Move to next goal step if current goal step is complete.
        if np.abs(max_reward - step_reward) < 0.01:
            self.progress += max_reward  # Update task progress.
            self.goals.pop(0)
            if len(self.lang_goals) > 0:
                self.lang_goals.pop(0)

        return reward, info

    def done(self):
        """Check if the task is done or has failed.

        Returns:
          True if the episode should be considered a success, which we
            use for measuring successes, which is particularly helpful for tasks
            where one may get successes on the very last time step, e.g., getting
            the cloth coverage threshold on the last alllowed action.
            However, for bag-items-easy and bag-items-hard (which use the
            'bag-items' metric), it may be necessary to filter out demos that did
            not attain sufficiently high reward in external code. Currently, this
            is done in `main.py` and its ignore_this_demo() method.
        """
        return (len(self.goals) == 0) or (self._rewards > 0.99)
        # return zone_done or defs_done or goal_done

    # -------------------------------------------------------------------------
    # Environment Helper Functions
    # -------------------------------------------------------------------------

    def is_match(self, pose0, pose1, symmetry):
        """Check if pose0 and pose1 match within a threshold."""

        # Get translational error.
        diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
        dist_pos = np.linalg.norm(diff_pos)

        # Get rotational error around z-axis (account for symmetries).
        diff_rot = 0
        if symmetry > 0:
            rot0 = np.array(utils.quatXYZW_to_eulerXYZ(pose0[1]))[2]
            rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]
            diff_rot = np.abs(rot0 - rot1) % symmetry
            if diff_rot > (symmetry / 2):
                diff_rot = symmetry - diff_rot

        return (dist_pos < self.pos_eps) and (diff_rot < self.rot_eps)

    def get_random_pose(self, env, obj_size):
        """Get random collision-free object pose within workspace bounds."""

        # Get erosion size of object in pixels.
        max_size = np.sqrt(obj_size[0] ** 2 + obj_size[1] ** 2)
        erode_size = int(np.round(max_size / self.pix_size))

        _, hmap, obj_mask = self.get_true_image(env)

        # Randomly sample an object pose within free-space pixels.
        free = np.ones(obj_mask.shape, dtype=np.uint8)
        for obj_ids in env.obj_ids.values():
            for obj_id in obj_ids:
                free[obj_mask == obj_id] = 0
        free[0, :], free[:, 0], free[-1, :], free[:, -1] = 0, 0, 0, 0
        free = cv2.erode(free, np.ones((erode_size, erode_size), np.uint8))

        # if np.sum(free) == 0:
        #     return None, None

        if np.sum(free) == 0:
            # avoid returning None, None
            # return None, None
            pix = (obj_mask.shape[0] // 2, obj_mask.shape[1] // 2)
        else:
            pix = utils.sample_distribution(np.float32(free))
        pos = utils.pix_to_xyz(pix, hmap, self.bounds, self.pix_size)
        pos = (pos[0], pos[1], obj_size[2] / 2)
        theta = np.random.rand() * 2 * np.pi
        rot = utils.eulerXYZ_to_quatXYZW((0, 0, theta))
        return pos, rot

    def get_lang_goal(self):
        if len(self.lang_goals) == 0:
            return self.task_completed_desc
        else:
            return self.lang_goals[0]

    def get_reward(self):
        return float(self._rewards)

    # -------------------------------------------------------------------------
    # Helper Functions
    # -------------------------------------------------------------------------

    def fill_template(self, template, replace):
        """Read a file and replace key strings."""
        full_template_path = os.path.join(self.assets_root, template)
        with open(full_template_path, 'r') as file:
            fdata = file.read()
        for field in replace:
            for i in range(len(replace[field])):
                fdata = fdata.replace(f'{field}{i}', str(replace[field][i]))
        alphabet = string.ascii_lowercase + string.digits
        rname = ''.join(random.choices(alphabet, k=16))
        tmpdir = tempfile.gettempdir()
        template_filename = os.path.split(template)[-1]
        fname = os.path.join(tmpdir, f'{template_filename}.{rname}')
        with open(fname, 'w') as file:
            file.write(fdata)
        return fname

    def get_random_size(self, min_x, max_x, min_y, max_y, min_z, max_z):
        """Get random box size."""
        size = np.random.rand(3)
        size[0] = size[0] * (max_x - min_x) + min_x
        size[1] = size[1] * (max_y - min_y) + min_y
        size[2] = size[2] * (max_z - min_z) + min_z
        return tuple(size)

    def color_random_brown(self, obj):
        shade = np.random.rand() + 0.5
        color = np.float32([shade * 156, shade * 117, shade * 95, 255]) / 255
        p.changeVisualShape(obj, -1, rgbaColor=color)

  """""
  
  # Environment Class
  def add_object(self, urdf, pose, category='rigid'):
    """List of (fixed, rigid, or deformable) objects in env."""
    fixed_base = 1 if category == 'fixed' else 0
    obj_id = pybullet_utils.load_urdf(
        p,
        os.path.join(self.assets_root, urdf),
        pose[0],
        pose[1],
        useFixedBase=fixed_base)
    self.obj_ids[category].append(obj_id)
    return obj_id
"""

=========
Note that the objects need to obey physics and not collide with each other, and the object goal poses need to be above the table with lower bound x=0.25, y=-0.5 and upper bound x=0.75, y=0.5. When there are multiple objects for a multi-step pick-and-place task, there are often multiple subgoals. Once the task and environment are generated, an agent with a pick and place primitive will follow the defined goal to accomplish the tasks. 

Additionally, make sure you understand and summarize the ``self.goals`` variables, which has a list of 8-tuple with (objs, matches, targ_poses, replace, rotations, metric, params, step_max_reward, symmetries).
- objs (List of obj_id): object ID.
- matches (Binary Matrix): a binary matrix that denotes which object is matched with which target. This matrix has dimension len(objs) x len(targs).
- targ_poses (List of Poses [(translation, rotation)] ): a list of target poses of tuple (translation, rotation). 
- replace (Boolean): whether each object can match with one unique target. This is important if we have one target and multiple objects. If it's set to be false, then any object matching with the target will satisfy.
- rotations (Boolean): whether the placement action has a rotation degree of freedom. 
- metric (`pose` or `zone`): `pose` or `zone` that the object needs to be transported to. Example: `pose`. 
- params (List of (zone_target, zone_size)): a list of (zone_target, zone_size) for each zone if the metric is `zone`. 
- step_max_reward (float): the total reward of matching all the objects with all the target poses. It is not dependent on the number of objects but dependent on the number of goals. 
- symmetries: the radians that the object is symmetric around z axis.
- language_goal: the low-level language instructions that denote the goal of this step.
 


>>> Answer: 
Yes, I understand the provided APIs and their intended usage. Here's a summary of my understanding:

**Task Class:**

The `Task` class defines the base structure and functionality for a manipulation task within a simulated environment (likely PyBullet). It handles aspects like:

* **Action Primitive:** Uses a `PickPlace` primitive, suggesting tasks involve picking up and placing objects.
* **Oracle Agent:** Provides an `oracle` method that demonstrates perfect execution of the task, useful for generating expert demonstrations.  The oracle agent uses ground truth information (segmentation masks and depth maps) to select pick and place locations.
* **Reward Function:**  The `reward` method calculates rewards based on either `pose` matching (how close the object's pose is to the target pose) or `zone` placement (how much of the object is within a designated zone).  It tracks progress towards completing subgoals and the overall task.
* **Task Completion:** The `done` method checks if the task is finished (all goals achieved) or if a sufficient reward threshold has been reached.
* **Helper Functions:** Includes utility functions for pose matching (`is_match`), generating random poses (`get_random_pose`), processing language goals (`get_lang_goal`), accessing cumulative rewards (`get_reward`), file templating (`fill_template`), generating random sizes (`get_random_size`), and coloring objects (`color_random_brown`).
* **Environment Interaction:**  The `reset` method initializes the task state, and other methods interact with the environment (e.g., getting images, checking object poses).
* **Goal Representation:** The `self.goals` list stores the subgoals of the task.

**Environment Class (Partial):**

The provided snippet of the environment class shows the `add_object` method, which loads objects into the simulation.  It allows specifying the object's URDF file, pose, and whether it's fixed, rigid, or deformable.

**Understanding `self.goals`:**

The `self.goals` variable is crucial. Each element in this list represents a subgoal and is an 8-tuple:

1. **`objs`:** A list of object IDs involved in the current subgoal.
2. **`matches`:** A binary matrix indicating which object should be matched with which target pose.  Rows correspond to objects, columns to target poses. A '1' at `matches[i, j]` means object `i` should be placed at target pose `j`.
3. **`targ_poses`:** A list of target poses, each represented as a (position, orientation) tuple.
4. **`replace`:** A boolean flag. If `False`, each object can only be matched with one unique target. If `True`, multiple objects can be matched to the same target.
5. **`rotations`:** A boolean flag indicating whether the orientation of the placed object matters for achieving the subgoal.
6. **`metric`:**  A string, either `'pose'` or `'zone'`, specifying how the reward is calculated for this subgoal.
7. **`params`:**  If `metric` is `'zone'`, this list contains tuples of (zone_target_pose, zone_size) defining the target zones.
8. **`step_max_reward`:** The maximum reward achievable for this subgoal.
9. **`symmetries`:** The rotational symmetry of the object around the z-axis, in radians. This is used in the `is_match` function to account for symmetries when comparing object poses.


**Key Considerations for Code Implementation:**

* **Physics and Collision Avoidance:**  Ensure that objects interact realistically within the simulated environment, obeying physics and avoiding collisions.
* **Workspace Bounds:** Respect the specified workspace boundaries when generating object and target poses.
* **Multi-Step Tasks:** Handle the sequencing of subgoals within `self.goals` correctly.
* **Pick and Place Primitive:** Utilize the `self.primitive` (PickPlace) effectively to manipulate objects.


By understanding these APIs and considerations, one can effectively implement the "stack-balls-in-bowls" task.


================= Error Book Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-in-bowls". Here are some runtime errors that you do not want to make. Please confirm that you understand these runtime errors.

"""
- environment.py, line 338, in info
    pos, rot = p.getBasePositionAndOrientation(obj_id)
TypeError: an integer is required (got type NoneType)

- task.py, line 118, in act
    objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]
IndexError: list index out of range

- task.py, line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
TypeError: 'float' object is not subscriptable

- task.py", line 315, in is_match
  rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]

- utils.py", line 280, in quatXYZW_to_eulerXYZ
  quaternion_wxyz = np.array([q[3], q[0], q[1], q[2]])
IndexError: tuple index out of range

- pallet_pose = self.get_random_pose(env, pallet_size)
pallet_surface_height = pallet_pose[0][2]
TypeError: 'NoneType' object is not subscriptable

- No such file or directory: './cliport/environments/assets/circle/circle-template.urdf'

- No such file or directory: './cliport/environments/assets/block/block-template.urdf'

- task.py", line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
IndexError: invalid index to scalar variable.

-TypeError: get_random_size() missing 4 required positional arguments: 'min_y', 'max_y', 'min_z', and 'max_z' 

- task.py", line 195, in reward
    obj_pts, zones = params
TypeError: cannot unpack non-iterable NoneType object

-  environment.py", line 230, in step
    reward, info = self.task.reward() if action is not None else (0, {})
  File "task.py", line 200, in reward
    pts = obj_pts[obj_id]
IndexError: arrays used as indices must be of integer (or boolean) type

- generated_task.py", line 41, in reset
    utils.COLORS['green'], utils.COLORS['blue'], utils.COLORS['light blue'],
KeyError: 'light blue'

- environment.py", line 195, in reset
    self.task.reset(self)
  File "<string>", line 38, in reset
TypeError: can only concatenate str (not "list") to str

- environment.py", line 195, in reset
  object_shape = np.random.choice(object_shapes)
  in numpy.random.mtrand.RandomState.choice
ValueError: a must be 1-dimensional

- No such file or directory: 'assets/box-template/box-template.urdf'

- line 38, in reset.py
{'HALF': box_size / 2}
TypeError: unsupported operand type(s) for /: 'tuple' and 'int'. box_size is a tuple not a float.

- line 38, in reset.py
IndexError: tuple index out of range
box_pose = (pallet_pose[0], pallet_pose[1], pallet_pose[2] + np.sum(box_sizes[:i+1]))

- task.py", line 338, in fill_template
    for i in range(len(replace[field])):
TypeError: object of type 'float' has no len().

- task.py", line 325, in get_random_pose
    pos = (pos[0], pos[1], obj_size[2] / 2)
IndexError: tuple index out of range

- task.py", line 206, in reward
    for zone_idx, (zone_pose, zone_size) in enumerate(zones):
TypeError: 'NoneType' object is not iterable

- task.py",
ball_pose = self.get_random_pose(env, ball_size)
ball_pose[0][2] += 0.02
TypeError: 'tuple' object does not support item assignment
"""


You do not want to make mistakes such as
- using assets (urdfs) that do not exist
- use ambiguous language descriptions as goals. For instance, "place the colored blocks into the matching colored bowls" with one goal and sparse reward as the task instead of adding subgoal "place blue block into blue bowl" and give continuous reward. 
- `matches` in the goal has wrong dimensions. It should have the same dimensions as number of objects (N) multiplied by the number of goal poses (M). Usually it is N by M.
- have vector dimension problem such as `np.random.choice(box_size)` or `box_size / 2` where `box_size` is a tuple and not an int
- make too large an object for stacking or make the task objects invisible for picking. 
- accessing index out of bound `pallet_pose[2]` for `pallet_pose`.  `pallet_pose=get_random_pose` returns a tuple (translation, rotation). It does not have 3rd component. Similarly accessing `container_pose[2]` or `box_pose[2]` would cause errors as well. Since it's a tuple, try to modify it in-place will also trigger errors.
- forget to replace str using `fill_template()` for urdfs with template such as `cylinder-template.urdf`. `ball-template.urdf`, `line-template.urf`. 
- use `self.ee = Spatula()` as a function when doing pushing tasks, which is incorrect. It should be `self.ee = Spatula`.
- forget to compute target poses `targ_poses` for matching. Do not use object IDs for poses.
- change colors of complex objects such as `zone`. You can only change color of teomplate primitive such as `cylinder-template`.
- mistakenly use `random_pose` for target pose. Design target poses based on task objectives.
- add only one or fewer language goals which causes language-motion inconsistentcy. Note that the language goals usually are the same number as the pick and place goals.


>>> Answer: 
Yes, I understand the runtime errors listed and the additional points you've made about avoiding mistakes in task generation. I will keep these in mind when writing the code for the "stack-balls-in-bowls" task.  I will pay particular attention to:

* **File Existence:** Verify that all URDF files exist before using them.
* **Clear Language Goals:**  Use specific and unambiguous language descriptions for goals, breaking down complex tasks into subgoals with appropriate rewards.
* **Matches Dimensions:** Ensure the `matches` array has the correct dimensions (N x M), reflecting the number of objects and target poses.
* **Vector Dimensions:** Be mindful of vector operations and avoid issues with tuples vs. ints/floats, using indexing and slicing correctly.
* **Object Sizes and Visibility:**  Keep object sizes reasonable for the task and ensure they are visible for manipulation.
* **Pose Indexing:** Access pose tuples (translation, rotation) correctly, avoiding out-of-bounds errors and in-place modification attempts.
* **Template Filling:**  Use `fill_template()` to replace placeholders in URDFs with specific values.
* **Spatula Initialization:**  Initialize the spatula correctly (`self.ee = Spatula`) for pushing tasks.
* **Target Pose Computation:** Calculate `targ_poses` explicitly based on task requirements, not object IDs.
* **Color Changes:** Only change colors of template primitives, not complex objects.
* **Random Poses vs. Designed Poses:** Use random poses appropriately and design target poses based on task objectives.
* **Sufficient Language Goals:** Provide enough language goals to match the pick-and-place actions, ensuring language-motion consistency.


By addressing these points, I aim to avoid the listed runtime errors and create a robust and functional "stack-balls-in-bowls" task.


================= Code Generation!

>>> Prompt: 
Now I will provide you some reference code and you can write the code for the task "stack-balls-in-bowls".


"""
import os

import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils


class PackingShapes(Task):
    """pick up randomly sized shapes and place them tightly into a container."""

    def __init__(self):
        super().__init__()
        self.max_steps = 1
        self.homogeneous = False

        self.lang_template = "pack the {obj} in the brown box"
        self.task_completed_desc = "done packing shapes."
        self.additional_reset()


    def reset(self, env):
        super().reset(env)

        # Shape Names:
        shapes = utils.assembling_kit_shapes

        n_objects = 5
        if self.mode == 'train':
            obj_shapes = np.random.choice(self.train_set, n_objects, replace=False)
        else:
            if self.homogeneous:
                obj_shapes = [np.random.choice(self.test_set, replace=False)] * n_objects
            else:
                obj_shapes = np.random.choice(self.test_set, n_objects, replace=False)

        # Shuffle colors to avoid always picking an object of the same color
        colors, color_names = utils.get_colors(mode=self.mode)

        # Add container box.
        zone_size = self.get_random_size(0.1, 0.15, 0.1, 0.15, 0.05, 0.05)
        zone_pose = self.get_random_pose(env, zone_size)
        container_template = 'container/container-template.urdf'
        replace = {'DIM': zone_size, 'HALF': (zone_size[0] / 2, zone_size[1] / 2, zone_size[2] / 2)}
        # IMPORTANT: REPLACE THE TEMPLATE URDF with `fill_template`
        container_urdf = self.fill_template(container_template, replace)
        env.add_object(container_urdf, zone_pose, 'fixed')

        # Add objects.
        objects = []
        template = 'kitting/object-template.urdf'
        for i in range(n_objects):
            shape = obj_shapes[i]

            # x, y, z dimensions for the asset size
            size = (0.08, 0.08, 0.02)
            pose= self.get_random_pose(env, size)
            fname = f'{shape:02d}.obj'
            fname = os.path.join(self.assets_root, 'kitting', fname)
            scale = [0.003, 0.003, 0.001]  # .0005
            replace = {'FNAME': (fname,),
                       'SCALE': scale,
                       'COLOR': colors[i]}

            # IMPORTANT: REPLACE THE TEMPLATE URDF
            urdf = self.fill_template(template, replace)
            block_id = env.add_object(urdf, pose)
            objects.append(block_id)

        # Pick the first shape.
        num_objects_to_pick = 1
        for i in range(num_objects_to_pick):
            # IMPORTANT: Specify (obj_pts, [(zone_pose, zone_size)]) for target `zone`. obj_pts is a dict
            language_goal = self.lang_template.format(obj=shapes[obj_shapes[i]])
            self.add_goal(objs=[objects[i]], matches=np.int32([[1]]), targ_poses=[zone_pose], replace=False,
                rotations=True, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1 / num_objects_to_pick,
                language_goal=language_goal)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p


class PlaceRedInGreen(Task):
    """pick up the red blocks and place them into the green bowls amidst other objects."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "put the red blocks in a green bowl"
        self.task_completed_desc = "done placing blocks in bowls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)
        n_bowls = np.random.randint(1, 4)
        n_blocks = np.random.randint(1, n_bowls + 1)

        # Add bowls.
        # x, y, z dimensions for the asset size
        bowl_size = (0.12, 0.12, 0)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_poses = []
        for _ in range(n_bowls):
            bowl_pose = self.get_random_pose(env, obj_size=bowl_size)
            env.add_object(urdf=bowl_urdf, pose=bowl_pose, category='fixed')
            bowl_poses.append(bowl_pose)

        # Add blocks.
        # x, y, z dimensions for the asset size
        blocks = []
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'
        for _ in range(n_blocks):
            block_pose = self.get_random_pose(env, obj_size=block_size)
            block_id = env.add_object(block_urdf, block_pose)
            blocks.append(block_id)

        # Goal: each red block is in a different green bowl.
        self.add_goal(objs=blocks, matches=np.ones((len(blocks), len(bowl_poses))), targ_poses=bowl_poses, replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1, language_goal=self.lang_template)

        # Colors of distractor objects.
        bowl_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'green']
        block_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'red']

        # Add distractors.
        n_distractors = 0
        while n_distractors < 6:
            is_block = np.random.rand() > 0.5
            urdf = block_urdf if is_block else bowl_urdf
            size = block_size if is_block else bowl_size
            colors = block_colors if is_block else bowl_colors
            pose = self.get_random_pose(env, obj_size=size)
            color = colors[n_distractors % len(colors)]

            obj_id = env.add_object(urdf, pose, color=color)
            n_distractors += 1
"""
"""
import numpy as np
from cliport.tasks import primitives
from cliport.tasks.grippers import Spatula
from cliport.tasks.task import Task
from cliport.utils import utils


class SweepingPiles(Task):
    """Push piles of small objects into a target goal zone marked on the tabletop."""

    def __init__(self):
        super().__init__()
        self.max_steps = 20
        self.lang_template = "push the pile of blocks into the green square"
        self.task_completed_desc = "done sweeping."
        self.primitive = primitives.push
        self.ee = Spatula
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add goal zone.
        zone_size = (0.12, 0.12, 0)
        zone_pose = self.get_random_pose(env, zone_size)
        env.add_object('zone/zone.urdf', zone_pose, 'fixed')

        # Add pile of small blocks with `make_piles` function
        obj_ids = self.make_piles(env)

        # Add goal
        self.add_goal(objs=obj_ids, matches=np.ones((50, 1)), targ_poses=[zone_pose], replace=True,
                rotations=False, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1, language_goal=self.lang_template)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p

class StackBlockPyramid(Task):
    """Build a pyramid of colored blocks in a color sequence"""

    def __init__(self):
        super().__init__()
        self.max_steps = 12
        self.lang_template = "make the {row} row with {blocks}"
        self.task_completed_desc = "done stacking block pyramid."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add base.
        base_size = (0.05, 0.15, 0.005)
        base_urdf = 'stacking/stand.urdf'
        base_pose = self.get_random_pose(env, base_size)
        env.add_object(base_urdf, base_pose, category='fixed')

        # Block colors.
        colors = [
            utils.COLORS['purple'], utils.COLORS['blue'], utils.COLORS['green'],
            utils.COLORS['yellow'], utils.COLORS['orange'], utils.COLORS['red']
        ]

        # Add blocks.
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'

        objs = []
        for i in range(6):
            block_pose = self.get_random_pose(env, block_size)
            block_id = env.add_object(block_urdf, block_pose, color=colors[i])
            objs.append(block_id)

        # IMPORTANT Associate placement locations for goals.
        place_pos = [(0, -0.05, 0.03), (0, 0, 0.03),
                     (0, 0.05, 0.03), (0, -0.025, 0.08),
                     (0, 0.025, 0.08), (0, 0, 0.13)]
        targs = [(utils.apply(base_pose, i), base_pose[1]) for i in place_pos]

        # Goal: blocks are stacked in a pyramid (bottom row: green, blue, purple).
        language_goal = self.lang_template.format(blocks="the green, blue and purple blocks", row="bottom")
        self.add_goal(objs=objs[:3], matches=np.ones((3, 3)), targ_poses=targs[:3], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 2, symmetries=[np.pi/2]*3, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (middle row: yellow, orange).
        language_goal = self.lang_template.format(blocks="the yellow and orange blocks", row="middle")      
        self.add_goal(objs=objs[3:5], matches=np.ones((2, 2)), targ_poses=targs[3:5], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 3, symmetries=[np.pi/2]*2, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (top row: red).
        language_goal = self.lang_template.format(blocks="the red block", row="top")
        self.add_goal(objs=objs[5:], matches=np.ones((1, 1)), targ_poses=targs[5:], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 6, symmetries=[np.pi/2]*1, language_goal=language_goal)
"""



Do not use libraries, functions, and assets that you don't know. For each object, try to describe its color, size, category in the task first before you write the code. You do not need extra helper functions. Comment the code liberally to explain what each piece does and why it's written that way. If you have only one goal, `step_max_reward` in `add_goal` should be 1. Use functions `make_piles` and `make_ropes` for creating piles and cables. To use spatula together with the push primitives, import the libraries 
"""
from cliport.tasks import primitives;
from cliport.tasks.grippers import Spatula
"""
and then use `self.primitive = primitives.push` and `self.ee = Spatula`.
Note that the number of language goals usually match the number of motion goals, since they should correspond to each other.

Now write the code for the task "stack-balls-in-bowls" in python code block starting with ```python.  Reminder: {'task-name': 'stack-balls-in-bowls', 'task-description': 'Pick up three different colored balls (red, green, and blue) and stack them inside three correspondingly colored bowls (red, green, and blue).', 'assets-used': ['ball/ball-template.urdf', 'bowl/bowl.urdf']} 


>>> Answer: 
```python
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils

class StackBallsInBowls(Task):
    """Stack three different colored balls (red, green, and blue) inside three correspondingly colored bowls (red, green, and blue)."""

    def __init__(self):
        super().__init__()
        self.max_steps = 6
        self.lang_template = "place the {color} ball in the {color} bowl"
        self.task_completed_desc = "done stacking balls in bowls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Define colors and corresponding language descriptions
        colors = ['red', 'green', 'blue']

        # Bowl size and urdf
        bowl_size = (0.12, 0.12, 0.02)  # Slightly larger height for stacking
        bowl_urdf = 'bowl/bowl.urdf'

        # Ball size and urdf template
        ball_size = (0.04, 0.04, 0.04)
        ball_urdf_template = 'ball/ball-template.urdf'

        # Initialize lists to store object IDs and target poses
        balls = []
        bowls = []
        targ_poses = []

        # Add bowls and balls with matching colors
        for color in colors:
            # Bowl pose
            bowl_pose = self.get_random_pose(env, bowl_size)
            bowl_id = env.add_object(bowl_urdf, bowl_pose, color=utils.COLORS[color])
            bowls.append(bowl_id)
            
            # Calculate target pose for the ball inside the bowl
            targ_pose = (bowl_pose[0], bowl_pose[1], bowl_pose[2] + 0.06) # Adjust height for stacking
            targ_poses.append(targ_pose)

            # Ball pose
            ball_pose = self.get_random_pose(env, ball_size)
            
            # Use template to create colored ball urdf
            replace = {'COLOR': utils.COLORS[color]}
            ball_urdf = self.fill_template(ball_urdf_template, replace)
            ball_id = env.add_object(ball_urdf, ball_pose)
            balls.append(ball_id)

        # Add goals for each ball-bowl pair
        for i in range(len(colors)):
            language_goal = self.lang_template.format(color=colors[i])
            self.add_goal(objs=[balls[i]], matches=np.ones((1, 1)), targ_poses=[targ_poses[i]], 
                          replace=False, rotations=True, metric='pose', params=None,
                          step_max_reward=1/len(colors), language_goal=language_goal) # step_max_reward is 1/3 since there are 3 goals

```

================= TRIAL: 3

================= Task and Asset Design!

>>> Prompt: 
You are an AI in robot simulation code and task design. I will provide you some example tasks, code implementation, and some guidelines for how to generate tasks and then you will help me generate a new task. My goal is to design diverse and feasible tasks for tabletop manipulation. I will first ask you to describe the task in natural languages and then will let you write the code for it. 

=========
Here are all the assets. Use only these assets in the task and code design. 
"""
insertion/:
ell.urdf  fixture.urdf

bowl/:
bowl.urdf

box/:
box-template.urdf

stacking/:
block.urdf  stand.urdf

zone/:
zone.obj  zone.urdf

pallet/:
pallet.obj  pallet.urdf

ball/:
ball-template.urdf

cylinder/:
cylinder-template.urdf

bowl/:
bowl.urdf

# assets not for picking
corner/:
corner-template.urdf

line/:
single-green-line-template.urdf

container/:
container-template.urdf
"""
 
=========
Here are some examples of good tasks. Try to learn from these structures but avoid overlapping wiht them.

{"assets-used": ["zone/zone.urdf", "block/small.urdf"],
 "task-description": "Push piles of small objects into a target goal zone marked on the tabletop.",
 "task-name": "sweeping-piles"}

{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "Place all blocks of a specified color in a bowl of specified color.",
 "task-name": "put-block-in-bowl"}
 
{"assets-used": ["insertion/ell.urdf", "insertion/fixture.urdf"],
 "task-description": "pick up the L-shaped red block and place it into the L-shaped fixture.",
 "task-name": "block-insertion"}
 
{"assets-used": ["kitting/kit.urdf", "kitting/object-template.urdf"],
 "task-description": "pick up different objects and arrange them on a board marked with corresponding silhouettes.",
 "task-name": "assembling-kits"}
 
{"assets-used": ["pallet/pallet.urdf", "box/box-template.urdf"],
 "task-description": "pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.",
 "task-name": "palletizing-boxes"}
 
{"assets-used": ["stacking/stand.urdf", "stacking/block.urdf"],
 "task-description": "sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.",
 "task-name": "stack-block-pyramid"}
 
{"assets-used": ["container/container-template.urdf", "box/box-template.urdf"],
 "task-description": "pick up randomly sized boxes and place them tightly into a container.",
 "task-name": "packing-boxes"}
 
{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "pick up the red blocks and place them into the green bowls amidst other objects.",
 "task-name": "place-red-in-green"}
 
{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

=========
Here are some tasks that you have come up with before. Try to learn from these structures but avoid overlapping with these tasks. For instance, `bowl_ball_placement` and `sort_balls_in_bowls` are the same task. `pile_boxes_in_corner` and `stack_blocks_into_pallet` are similar tasks, `align-cylinder-in-corner` and `align-cylinder-corner` are similar.
- sweeping-piles: {'assets-used': ['zone/zone.urdf', 'block/small.urdf'], 'task-description': 'push piles of small objects into a target goal zone marked on the tabletop.', 'task-name': 'sweeping-piles'}
- place-red-in-green: {'assets-used': ['bowl/bowl.urdf', 'stacking/block.urdf'], 'task-description': 'pick up the red blocks and place them into the green bowls amidst other objects.', 'task-name': 'place-red-in-green'}
- align-box-corner: {'assets-used': ['box/box-template.urdf', 'corner/corner-template.urdf'], 'task-description': 'pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..', 'task-name': 'align-box-corner'}
- stack-block-pyramid: {'assets-used': ['stacking/stand.urdf', 'stacking/block.urdf'], 'task-description': 'sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.', 'task-name': 'stack-block-pyramid'}
- palletizing-boxes: {'assets-used': ['pallet/pallet.urdf', 'box/box-template.urdf'], 'task-description': 'pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.', 'task-name': 'palletizing-boxes'}
- assembling-kits: {'assets-used': ['kitting/kit.urdf', 'kitting/object-template.urdf'], 'task-description': 'pick up different objects and arrange them on a board marked with corresponding silhouettes.', 'task-name': 'assembling-kits'}
- packing-boxes: {'assets-used': ['container/container-template.urdf', 'box/box-template.urdf'], 'task-description': 'pick up randomly sized boxes and place them tightly into a container.', 'task-name': 'packing-boxes'}
- manipulating-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'rearrange a deformable rope such that it connects the two endpoints of a 3-sided square.', 'task-name': 'manipulating-rope'}
- align-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'manipulate a deformable rope to connect its end-points between two corners of a 3-sided square.', 'task-name': 'align-rope'}





=========
Here are some bad example task instances with explanations.
{
    "task_name": "sort-color-blocks",
    "task_descriptions": "Pick up differently colored blocks and place them into separate bowls of matching color."
    "assets-used": ["bowl.urdf", "box/box-template.urdf],
}
reasons: not interesting because it overlaps with the current task `put-block-in-bowl`.

{
    "task-name": "guided-ball-maze",
    "task-description": "Navigate a small ball through a maze by tilting the maze board to reach the target zone.",
    "assets-used": ["zone-template.urdf", "square-template.urdf", "ball.urdf", "maze.urdf"],
}
reasons: the language descriptions are too ambiguous. Navigation is also hard to complete. Also maze.urf does not exist.

{
    "task-name": "insert_cylinder_in_sphere",
    "task-description": "Pick up the cylinder and insert it into the sphere with an opening on top.",
    "assets-used": ["cylinder/cylinder-template.urdf", "sphere/sphere-template.urdf"],
}
reasons: this task does not make sense. The sphere does not have an opening on top, and you cannot insert a cylinder into a sphere. Similarly tasks like `insert-ball-into-cylinder` and `cylinder-box-insertion` are invalid.

{
    "task-name": "ball-box-obstacle-course",
    "task-description": "Navigate a ball through an obstacle course created by randomly placed boxes and finally place it inside a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: Navigate the ball is not related to tabletop manipulation tasks.

{
    "task-name": "ball-in-box",
    "task-description": "Use a cable to guide a ball into an open box.",
    "assets-used": ["cable/cable.urdf", "ball/ball-template.urdf", "box/box-template.urdf"]
}
reasons: This task is too hard since it involves interaction of the cable and the ball and cannot be easily completed.

{
    "task-name": "ball-in-container",
    "task-description": "Use the spatula to lift a ball over a wall of boxes and drop it into a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: The only action primitives as pick and place. One cannot use a spatula to lift an object.

{
    "task-name": "line-ball-sorting",
    "task-description": "Move balls of different colors along a single green line, placing each ball in a designated colored box at the end of the line. The challenge includes precision in maintaining the ball on the line and the correct identification of the box color corresponding to each ball.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "line/single-green-line-template.urdf"]
}
reasons: Piling or stacking balls are physically infeasible in the simulation.



=========
Now please describe the new task in natural languages and explain its novelty and challenges. Format the answer in a python dictionary with keys "task-name" and value type string, "task-description" (one specific sentence) and value type string, and "assets-used" and value type list of strings. Note that

- Do not use assets that are not in the list above. 
- Tasks that have more colors and shapes are interesting.
- Be as specific as possible about the number, shape, and color of each asset in the task descriptions. 
- The task need to obey physics and remain feasible.





>>> Answer: 
```python
{
    "task-name": "stack-balls-on-cylinder",
    "task-description": "Stack three different colored balls (red, green, blue) on top of a vertically placed cylinder.",
    "assets-used": ["ball/ball-template.urdf", "cylinder/cylinder-template.urdf"],
}
```

**Novelty:** This task introduces the challenge of stacking rounded objects, which is inherently less stable than stacking blocks.  It combines balancing with precise placement. While stacking blocks is common, stacking balls on a cylinder requires a different approach to grasping and manipulation due to the round shapes and instability.

**Challenges:**
* **Instability:**  Balancing balls on a cylinder requires precise placement and control. Slight deviations can cause the balls to roll off.
* **Grasping:** Picking up and placing the balls requires a robust grasping strategy due to their smooth surface.
* **Precision:**  Successfully stacking requires accurate positioning of each ball on top of the previous one and on the cylinder.  The robot needs to find stable equilibrium points for the balls. 
* **Color differentiation:** Although not strictly necessary for solving the task, the different colors add a potential element of complexity if the task is extended to require a specific stacking order based on color.


================= API Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-on-cylinder". Here are some APIs that are defined. Please confirm that you understand these APIs.

"""
class Task():
    """Base Task class."""

    def __init__(self):
        self.ee = Suction
        self.mode = 'train'
        self.sixdof = False
        self.primitive = primitives.PickPlace()
        self.oracle_cams = cameras.Oracle.CONFIG

        # Evaluation epsilons (for pose evaluation metric).
        self.pos_eps = 0.01
        self.rot_eps = np.deg2rad(15)

        # Workspace bounds.
        self.pix_size = 0.003125
        self.bounds = np.array([[0.25, 0.75], [-0.5, 0.5], [0, 0.3]])
        self.zone_bounds = np.copy(self.bounds)

        self.goals = []
        self.lang_goals = []
        self.task_completed_desc = "task completed."
        self.progress = 0
        self._rewards = 0
        self.assets_root = None

    def reset(self, env):
        if not self.assets_root:
            raise ValueError('assets_root must be set for task, '
                             'call set_assets_root().')
        self.goals = []
        self.lang_goals = []
        self.progress = 0  # Task progression metric in range [0, 1].
        self._rewards = 0  # Cumulative returned rewards.

    # -------------------------------------------------------------------------
    # Oracle Agent
    # -------------------------------------------------------------------------

    def oracle(self, env):
        """Oracle agent."""
        OracleAgent = collections.namedtuple('OracleAgent', ['act'])

        def act(obs, info):
            """Calculate action."""

            # Oracle uses perfect RGB-D orthographic images and segmentation masks.
            _, hmap, obj_mask = self.get_true_image(env)

            # Unpack next goal step.
            objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]

            # Match objects to targets without replacement.
            if not replace:

                # Modify a copy of the match matrix.
                matches = matches.copy()

                # Ignore already matched objects.
                for i in range(len(objs)):
                    object_id, (symmetry, _) = objs[i]
                    pose = p.getBasePositionAndOrientation(object_id)
                    targets_i = np.argwhere(matches[i, :]).reshape(-1)
                    for j in targets_i:
                        if self.is_match(pose, targs[j], symmetry):
                            matches[i, :] = 0
                            matches[:, j] = 0

            # Get objects to be picked (prioritize farthest from nearest neighbor).
            nn_dists = []
            nn_targets = []
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                xyz, _ = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                if len(targets_i) > 0:
                    targets_xyz = np.float32([targs[j][0] for j in targets_i])
                    dists = np.linalg.norm(
                        targets_xyz - np.float32(xyz).reshape(1, 3), axis=1)
                    nn = np.argmin(dists)
                    nn_dists.append(dists[nn])
                    nn_targets.append(targets_i[nn])

                # Handle ignored objects.
                else:
                    nn_dists.append(0)
                    nn_targets.append(-1)
            order = np.argsort(nn_dists)[::-1]

            # Filter out matched objects.
            order = [i for i in order if nn_dists[i] > 0]

            pick_mask = None
            for pick_i in order:
                pick_mask = np.uint8(obj_mask == objs[pick_i][0])

                # Erode to avoid picking on edges.
                # pick_mask = cv2.erode(pick_mask, np.ones((3, 3), np.uint8))

                if np.sum(pick_mask) > 0:
                    break

            # Trigger task reset if no object is visible.
            if pick_mask is None or np.sum(pick_mask) == 0:
                self.goals = []
                self.lang_goals = []
                print('Object for pick is not visible. Skipping demonstration.')
                return

            # Get picking pose.
            pick_prob = np.float32(pick_mask)
            pick_pix = utils.sample_distribution(pick_prob)
            # For "deterministic" demonstrations on insertion-easy, use this:
            # pick_pix = (160,80)
            pick_pos = utils.pix_to_xyz(pick_pix, hmap,
                                        self.bounds, self.pix_size)
            pick_pose = (np.asarray(pick_pos), np.asarray((0, 0, 0, 1)))

            # Get placing pose.
            targ_pose = targs[nn_targets[pick_i]]
            obj_pose = p.getBasePositionAndOrientation(objs[pick_i][0])
            if not self.sixdof:
                obj_euler = utils.quatXYZW_to_eulerXYZ(obj_pose[1])
                obj_quat = utils.eulerXYZ_to_quatXYZW((0, 0, obj_euler[2]))
                obj_pose = (obj_pose[0], obj_quat)
            world_to_pick = utils.invert(pick_pose)
            obj_to_pick = utils.multiply(world_to_pick, obj_pose)
            pick_to_obj = utils.invert(obj_to_pick)
            place_pose = utils.multiply(targ_pose, pick_to_obj)

            # Rotate end effector?
            if not rotations:
                place_pose = (place_pose[0], (0, 0, 0, 1))

            place_pose = (np.asarray(place_pose[0]), np.asarray(place_pose[1]))

            return {'pose0': pick_pose, 'pose1': place_pose}

        return OracleAgent(act)

    # -------------------------------------------------------------------------
    # Reward Function and Task Completion Metrics
    # -------------------------------------------------------------------------

    def reward(self):
        """Get delta rewards for current timestep.

        Returns:
          A tuple consisting of the scalar (delta) reward, plus `extras`
            dict which has extra task-dependent info from the process of
            computing rewards that gives us finer-grained details. Use
            `extras` for further data analysis.
        """
        reward, info = 0, {}

        # Unpack next goal step.
        objs, matches, targs, _, _, metric, params, max_reward = self.goals[0]

        # Evaluate by matching object poses.
        if metric == 'pose':
            step_reward = 0
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                pose = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                for j in targets_i:
                    target_pose = targs[j]
                    if self.is_match(pose, target_pose, symmetry):
                        step_reward += max_reward / len(objs)
                        print(f"object {i} match with target {j} rew: {step_reward}")
                        break

        # Evaluate by measuring object intersection with zone.
        elif metric == 'zone':
            zone_pts, total_pts = 0, 0
            obj_pts, zones = params
            for zone_idx, (zone_pose, zone_size) in enumerate(zones):

                # Count valid points in zone.
                for obj_idx, obj_id in enumerate(obj_pts):
                    pts = obj_pts[obj_id]
                    obj_pose = p.getBasePositionAndOrientation(obj_id)
                    world_to_zone = utils.invert(zone_pose)
                    obj_to_zone = utils.multiply(world_to_zone, obj_pose)
                    pts = np.float32(utils.apply(obj_to_zone, pts))
                    if len(zone_size) > 1:
                        valid_pts = np.logical_and.reduce([
                            pts[0, :] > -zone_size[0] / 2, pts[0, :] < zone_size[0] / 2,
                            pts[1, :] > -zone_size[1] / 2, pts[1, :] < zone_size[1] / 2,
                            pts[2, :] < self.zone_bounds[2, 1]])

                    # if zone_idx == matches[obj_idx].argmax():
                    zone_pts += np.sum(np.float32(valid_pts))
                    total_pts += pts.shape[1]
            step_reward = max_reward * (zone_pts / total_pts)

        # Get cumulative rewards and return delta.
        reward = self.progress + step_reward - self._rewards
        self._rewards = self.progress + step_reward

        # Move to next goal step if current goal step is complete.
        if np.abs(max_reward - step_reward) < 0.01:
            self.progress += max_reward  # Update task progress.
            self.goals.pop(0)
            if len(self.lang_goals) > 0:
                self.lang_goals.pop(0)

        return reward, info

    def done(self):
        """Check if the task is done or has failed.

        Returns:
          True if the episode should be considered a success, which we
            use for measuring successes, which is particularly helpful for tasks
            where one may get successes on the very last time step, e.g., getting
            the cloth coverage threshold on the last alllowed action.
            However, for bag-items-easy and bag-items-hard (which use the
            'bag-items' metric), it may be necessary to filter out demos that did
            not attain sufficiently high reward in external code. Currently, this
            is done in `main.py` and its ignore_this_demo() method.
        """
        return (len(self.goals) == 0) or (self._rewards > 0.99)
        # return zone_done or defs_done or goal_done

    # -------------------------------------------------------------------------
    # Environment Helper Functions
    # -------------------------------------------------------------------------

    def is_match(self, pose0, pose1, symmetry):
        """Check if pose0 and pose1 match within a threshold."""

        # Get translational error.
        diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
        dist_pos = np.linalg.norm(diff_pos)

        # Get rotational error around z-axis (account for symmetries).
        diff_rot = 0
        if symmetry > 0:
            rot0 = np.array(utils.quatXYZW_to_eulerXYZ(pose0[1]))[2]
            rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]
            diff_rot = np.abs(rot0 - rot1) % symmetry
            if diff_rot > (symmetry / 2):
                diff_rot = symmetry - diff_rot

        return (dist_pos < self.pos_eps) and (diff_rot < self.rot_eps)

    def get_random_pose(self, env, obj_size):
        """Get random collision-free object pose within workspace bounds."""

        # Get erosion size of object in pixels.
        max_size = np.sqrt(obj_size[0] ** 2 + obj_size[1] ** 2)
        erode_size = int(np.round(max_size / self.pix_size))

        _, hmap, obj_mask = self.get_true_image(env)

        # Randomly sample an object pose within free-space pixels.
        free = np.ones(obj_mask.shape, dtype=np.uint8)
        for obj_ids in env.obj_ids.values():
            for obj_id in obj_ids:
                free[obj_mask == obj_id] = 0
        free[0, :], free[:, 0], free[-1, :], free[:, -1] = 0, 0, 0, 0
        free = cv2.erode(free, np.ones((erode_size, erode_size), np.uint8))

        # if np.sum(free) == 0:
        #     return None, None

        if np.sum(free) == 0:
            # avoid returning None, None
            # return None, None
            pix = (obj_mask.shape[0] // 2, obj_mask.shape[1] // 2)
        else:
            pix = utils.sample_distribution(np.float32(free))
        pos = utils.pix_to_xyz(pix, hmap, self.bounds, self.pix_size)
        pos = (pos[0], pos[1], obj_size[2] / 2)
        theta = np.random.rand() * 2 * np.pi
        rot = utils.eulerXYZ_to_quatXYZW((0, 0, theta))
        return pos, rot

    def get_lang_goal(self):
        if len(self.lang_goals) == 0:
            return self.task_completed_desc
        else:
            return self.lang_goals[0]

    def get_reward(self):
        return float(self._rewards)

    # -------------------------------------------------------------------------
    # Helper Functions
    # -------------------------------------------------------------------------

    def fill_template(self, template, replace):
        """Read a file and replace key strings."""
        full_template_path = os.path.join(self.assets_root, template)
        with open(full_template_path, 'r') as file:
            fdata = file.read()
        for field in replace:
            for i in range(len(replace[field])):
                fdata = fdata.replace(f'{field}{i}', str(replace[field][i]))
        alphabet = string.ascii_lowercase + string.digits
        rname = ''.join(random.choices(alphabet, k=16))
        tmpdir = tempfile.gettempdir()
        template_filename = os.path.split(template)[-1]
        fname = os.path.join(tmpdir, f'{template_filename}.{rname}')
        with open(fname, 'w') as file:
            file.write(fdata)
        return fname

    def get_random_size(self, min_x, max_x, min_y, max_y, min_z, max_z):
        """Get random box size."""
        size = np.random.rand(3)
        size[0] = size[0] * (max_x - min_x) + min_x
        size[1] = size[1] * (max_y - min_y) + min_y
        size[2] = size[2] * (max_z - min_z) + min_z
        return tuple(size)

    def color_random_brown(self, obj):
        shade = np.random.rand() + 0.5
        color = np.float32([shade * 156, shade * 117, shade * 95, 255]) / 255
        p.changeVisualShape(obj, -1, rgbaColor=color)

  """""
  
  # Environment Class
  def add_object(self, urdf, pose, category='rigid'):
    """List of (fixed, rigid, or deformable) objects in env."""
    fixed_base = 1 if category == 'fixed' else 0
    obj_id = pybullet_utils.load_urdf(
        p,
        os.path.join(self.assets_root, urdf),
        pose[0],
        pose[1],
        useFixedBase=fixed_base)
    self.obj_ids[category].append(obj_id)
    return obj_id
"""

=========
Note that the objects need to obey physics and not collide with each other, and the object goal poses need to be above the table with lower bound x=0.25, y=-0.5 and upper bound x=0.75, y=0.5. When there are multiple objects for a multi-step pick-and-place task, there are often multiple subgoals. Once the task and environment are generated, an agent with a pick and place primitive will follow the defined goal to accomplish the tasks. 

Additionally, make sure you understand and summarize the ``self.goals`` variables, which has a list of 8-tuple with (objs, matches, targ_poses, replace, rotations, metric, params, step_max_reward, symmetries).
- objs (List of obj_id): object ID.
- matches (Binary Matrix): a binary matrix that denotes which object is matched with which target. This matrix has dimension len(objs) x len(targs).
- targ_poses (List of Poses [(translation, rotation)] ): a list of target poses of tuple (translation, rotation). 
- replace (Boolean): whether each object can match with one unique target. This is important if we have one target and multiple objects. If it's set to be false, then any object matching with the target will satisfy.
- rotations (Boolean): whether the placement action has a rotation degree of freedom. 
- metric (`pose` or `zone`): `pose` or `zone` that the object needs to be transported to. Example: `pose`. 
- params (List of (zone_target, zone_size)): a list of (zone_target, zone_size) for each zone if the metric is `zone`. 
- step_max_reward (float): the total reward of matching all the objects with all the target poses. It is not dependent on the number of objects but dependent on the number of goals. 
- symmetries: the radians that the object is symmetric around z axis.
- language_goal: the low-level language instructions that denote the goal of this step.
 


>>> Answer: 
Yes, I understand the provided APIs and their intended usage. Here's a summary of my understanding:

**Task Class:**

The `Task` class defines the base structure and functionality for a manipulation task. It handles aspects like:

* **End-Effector:**  Uses a suction-based end-effector (`self.ee = Suction`).
* **Mode:**  Operates in either 'train' or 'eval' mode (`self.mode`).
* **Pick-and-Place Primitive:** Employs a `PickPlace` primitive for actions (`self.primitive`).
* **Oracle:**  Includes an oracle agent for demonstration generation, using perfect perception (`self.oracle()`).
* **Evaluation Metrics:** Defines position and rotation tolerances for pose matching (`self.pos_eps`, `self.rot_eps`).
* **Workspace and Zone Bounds:** Specifies the workspace limits and a zone within it (`self.bounds`, `self.zone_bounds`).
* **Goals and Language Goals:** Stores the task's goals as structured tuples and corresponding language descriptions (`self.goals`, `self.lang_goals`).
* **Reward Function:** Calculates rewards based on goal achievement (`self.reward()`).
* **Task Completion:** Determines when the task is finished or failed (`self.done()`).
* **Helper Functions:** Provides utility functions for pose generation, template filling, size randomization, and color manipulation.

**Environment Interaction (add_object):**

The `add_object` function within the environment class adds objects to the simulation. It takes the URDF path, pose, and category (fixed, rigid, or deformable) as input.

**Goals Representation (self.goals):**

The `self.goals` variable is crucial. Each element in this list represents a sub-goal and is an 8-tuple:

1. **`objs`:** A list of object IDs involved in the sub-goal.
2. **`matches`:** A binary matrix indicating object-target correspondences.  Rows correspond to objects, columns to targets. A '1' at `matches[i, j]` means object `i` should be placed at target `j`.
3. **`targs` (or `targ_poses`):** A list of target poses (position, orientation quaternions) for the objects in the sub-goal.
4. **`replace`:** A boolean flag. If `False`, each object can only match with one unique target. If `True`, multiple objects can be placed at the same target.
5. **`rotations`:** A boolean flag. If `True`, the orientation of the placed object is considered in the reward calculation. If `False`, only the position matters.
6. **`metric`:**  The metric used for evaluating the sub-goal.  Can be 'pose' (matching object pose to target pose) or 'zone' (object presence within a designated zone).
7. **`params`:** Additional parameters specific to the metric. For 'zone', it's a list of (zone_pose, zone_size) tuples.
8. **`step_max_reward`:** The maximum reward achievable for this sub-goal.

**Key Considerations:**

* **Physics and Collision Avoidance:** The simulation enforces physics and prevents object collisions.
* **Goal Pose Constraints:** Target poses must be above the table within the specified x and y bounds.
* **Multi-Step Tasks:**  Multiple sub-goals (entries in `self.goals`) create multi-step pick-and-place tasks.
* **Agent and Primitive:** An agent using the `PickPlace` primitive will attempt to achieve the defined goals.
* **Symmetries:** The `symmetries` parameter accounts for rotational symmetry of objects around the z-axis. This is important for determining if a placement is correct even if rotated.


I'm ready to proceed with coding the "stack-balls-on-cylinder" task based on this understanding.  I will ensure the generated goals respect the workspace boundaries and that the task logic aligns with the provided APIs.


================= Error Book Preview!

>>> Prompt: 
Before writing the code for the task "stack-balls-on-cylinder". Here are some runtime errors that you do not want to make. Please confirm that you understand these runtime errors.

"""
- environment.py, line 338, in info
    pos, rot = p.getBasePositionAndOrientation(obj_id)
TypeError: an integer is required (got type NoneType)

- task.py, line 118, in act
    objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]
IndexError: list index out of range

- task.py, line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
TypeError: 'float' object is not subscriptable

- task.py", line 315, in is_match
  rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]

- utils.py", line 280, in quatXYZW_to_eulerXYZ
  quaternion_wxyz = np.array([q[3], q[0], q[1], q[2]])
IndexError: tuple index out of range

- pallet_pose = self.get_random_pose(env, pallet_size)
pallet_surface_height = pallet_pose[0][2]
TypeError: 'NoneType' object is not subscriptable

- No such file or directory: './cliport/environments/assets/circle/circle-template.urdf'

- No such file or directory: './cliport/environments/assets/block/block-template.urdf'

- task.py", line 308, in is_match
    diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
IndexError: invalid index to scalar variable.

-TypeError: get_random_size() missing 4 required positional arguments: 'min_y', 'max_y', 'min_z', and 'max_z' 

- task.py", line 195, in reward
    obj_pts, zones = params
TypeError: cannot unpack non-iterable NoneType object

-  environment.py", line 230, in step
    reward, info = self.task.reward() if action is not None else (0, {})
  File "task.py", line 200, in reward
    pts = obj_pts[obj_id]
IndexError: arrays used as indices must be of integer (or boolean) type

- generated_task.py", line 41, in reset
    utils.COLORS['green'], utils.COLORS['blue'], utils.COLORS['light blue'],
KeyError: 'light blue'

- environment.py", line 195, in reset
    self.task.reset(self)
  File "<string>", line 38, in reset
TypeError: can only concatenate str (not "list") to str

- environment.py", line 195, in reset
  object_shape = np.random.choice(object_shapes)
  in numpy.random.mtrand.RandomState.choice
ValueError: a must be 1-dimensional

- No such file or directory: 'assets/box-template/box-template.urdf'

- line 38, in reset.py
{'HALF': box_size / 2}
TypeError: unsupported operand type(s) for /: 'tuple' and 'int'. box_size is a tuple not a float.

- line 38, in reset.py
IndexError: tuple index out of range
box_pose = (pallet_pose[0], pallet_pose[1], pallet_pose[2] + np.sum(box_sizes[:i+1]))

- task.py", line 338, in fill_template
    for i in range(len(replace[field])):
TypeError: object of type 'float' has no len().

- task.py", line 325, in get_random_pose
    pos = (pos[0], pos[1], obj_size[2] / 2)
IndexError: tuple index out of range

- task.py", line 206, in reward
    for zone_idx, (zone_pose, zone_size) in enumerate(zones):
TypeError: 'NoneType' object is not iterable

- task.py",
ball_pose = self.get_random_pose(env, ball_size)
ball_pose[0][2] += 0.02
TypeError: 'tuple' object does not support item assignment
"""


You do not want to make mistakes such as
- using assets (urdfs) that do not exist
- use ambiguous language descriptions as goals. For instance, "place the colored blocks into the matching colored bowls" with one goal and sparse reward as the task instead of adding subgoal "place blue block into blue bowl" and give continuous reward. 
- `matches` in the goal has wrong dimensions. It should have the same dimensions as number of objects (N) multiplied by the number of goal poses (M). Usually it is N by M.
- have vector dimension problem such as `np.random.choice(box_size)` or `box_size / 2` where `box_size` is a tuple and not an int
- make too large an object for stacking or make the task objects invisible for picking. 
- accessing index out of bound `pallet_pose[2]` for `pallet_pose`.  `pallet_pose=get_random_pose` returns a tuple (translation, rotation). It does not have 3rd component. Similarly accessing `container_pose[2]` or `box_pose[2]` would cause errors as well. Since it's a tuple, try to modify it in-place will also trigger errors.
- forget to replace str using `fill_template()` for urdfs with template such as `cylinder-template.urdf`. `ball-template.urdf`, `line-template.urf`. 
- use `self.ee = Spatula()` as a function when doing pushing tasks, which is incorrect. It should be `self.ee = Spatula`.
- forget to compute target poses `targ_poses` for matching. Do not use object IDs for poses.
- change colors of complex objects such as `zone`. You can only change color of teomplate primitive such as `cylinder-template`.
- mistakenly use `random_pose` for target pose. Design target poses based on task objectives.
- add only one or fewer language goals which causes language-motion inconsistentcy. Note that the language goals usually are the same number as the pick and place goals.


>>> Answer: 
Yes, I understand the runtime errors listed and the additional points you've made about avoiding mistakes in task generation. I will be mindful of these issues when writing the code for the "stack-balls-on-cylinder" task.  I will pay particular attention to:

* **File Paths and Existence:** Verify that all URDF files exist in the correct locations.
* **Clear Language Goals:**  Provide specific and unambiguous language descriptions for each subgoal, avoiding vague phrasing.
* **Matches Dimensions:** Ensure the `matches` array has the correct dimensions (N x M), reflecting the number of objects and target poses.
* **Vector Operations:**  Handle vector and scalar operations correctly, paying attention to the dimensions of variables like `box_size` and using appropriate functions for vector manipulation.
* **Object Sizes and Visibility:**  Keep object sizes reasonable for stacking and ensure they are visible for picking.
* **Pose Indexing:** Access pose components correctly, remembering that `get_random_pose` returns a tuple of (translation, rotation) and avoiding out-of-bounds access.  I understand that tuples are immutable and will create new tuples with modified values instead of trying to modify them in place.
* **Template Filling:** Use `fill_template()` to replace placeholders in URDF files with specific values.
* **Spatula Initialization:** Initialize the spatula correctly using `self.ee = Spatula`, not as a function call.
* **Target Pose Calculation:** Explicitly calculate target poses (`targ_poses`) based on task objectives, not object IDs.
* **Color Changes:** Only change colors of template primitives, not complex objects.
* **Random vs. Designed Poses:** Use `random_pose` appropriately and design target poses based on the task goals.
* **Sufficient Language Goals:** Provide enough language goals to match the number of pick-and-place actions, ensuring language-motion consistency.


By addressing these points, I aim to avoid the listed runtime errors and create a robust and functional task.


================= Code Generation!

>>> Prompt: 
Now I will provide you some reference code and you can write the code for the task "stack-balls-on-cylinder".


"""
import os

import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils


class PackingShapes(Task):
    """pick up randomly sized shapes and place them tightly into a container."""

    def __init__(self):
        super().__init__()
        self.max_steps = 1
        self.homogeneous = False

        self.lang_template = "pack the {obj} in the brown box"
        self.task_completed_desc = "done packing shapes."
        self.additional_reset()


    def reset(self, env):
        super().reset(env)

        # Shape Names:
        shapes = utils.assembling_kit_shapes

        n_objects = 5
        if self.mode == 'train':
            obj_shapes = np.random.choice(self.train_set, n_objects, replace=False)
        else:
            if self.homogeneous:
                obj_shapes = [np.random.choice(self.test_set, replace=False)] * n_objects
            else:
                obj_shapes = np.random.choice(self.test_set, n_objects, replace=False)

        # Shuffle colors to avoid always picking an object of the same color
        colors, color_names = utils.get_colors(mode=self.mode)

        # Add container box.
        zone_size = self.get_random_size(0.1, 0.15, 0.1, 0.15, 0.05, 0.05)
        zone_pose = self.get_random_pose(env, zone_size)
        container_template = 'container/container-template.urdf'
        replace = {'DIM': zone_size, 'HALF': (zone_size[0] / 2, zone_size[1] / 2, zone_size[2] / 2)}
        # IMPORTANT: REPLACE THE TEMPLATE URDF with `fill_template`
        container_urdf = self.fill_template(container_template, replace)
        env.add_object(container_urdf, zone_pose, 'fixed')

        # Add objects.
        objects = []
        template = 'kitting/object-template.urdf'
        for i in range(n_objects):
            shape = obj_shapes[i]

            # x, y, z dimensions for the asset size
            size = (0.08, 0.08, 0.02)
            pose= self.get_random_pose(env, size)
            fname = f'{shape:02d}.obj'
            fname = os.path.join(self.assets_root, 'kitting', fname)
            scale = [0.003, 0.003, 0.001]  # .0005
            replace = {'FNAME': (fname,),
                       'SCALE': scale,
                       'COLOR': colors[i]}

            # IMPORTANT: REPLACE THE TEMPLATE URDF
            urdf = self.fill_template(template, replace)
            block_id = env.add_object(urdf, pose)
            objects.append(block_id)

        # Pick the first shape.
        num_objects_to_pick = 1
        for i in range(num_objects_to_pick):
            # IMPORTANT: Specify (obj_pts, [(zone_pose, zone_size)]) for target `zone`. obj_pts is a dict
            language_goal = self.lang_template.format(obj=shapes[obj_shapes[i]])
            self.add_goal(objs=[objects[i]], matches=np.int32([[1]]), targ_poses=[zone_pose], replace=False,
                rotations=True, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1 / num_objects_to_pick,
                language_goal=language_goal)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p


class PlaceRedInGreen(Task):
    """pick up the red blocks and place them into the green bowls amidst other objects."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "put the red blocks in a green bowl"
        self.task_completed_desc = "done placing blocks in bowls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)
        n_bowls = np.random.randint(1, 4)
        n_blocks = np.random.randint(1, n_bowls + 1)

        # Add bowls.
        # x, y, z dimensions for the asset size
        bowl_size = (0.12, 0.12, 0)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_poses = []
        for _ in range(n_bowls):
            bowl_pose = self.get_random_pose(env, obj_size=bowl_size)
            env.add_object(urdf=bowl_urdf, pose=bowl_pose, category='fixed')
            bowl_poses.append(bowl_pose)

        # Add blocks.
        # x, y, z dimensions for the asset size
        blocks = []
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'
        for _ in range(n_blocks):
            block_pose = self.get_random_pose(env, obj_size=block_size)
            block_id = env.add_object(block_urdf, block_pose)
            blocks.append(block_id)

        # Goal: each red block is in a different green bowl.
        self.add_goal(objs=blocks, matches=np.ones((len(blocks), len(bowl_poses))), targ_poses=bowl_poses, replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1, language_goal=self.lang_template)

        # Colors of distractor objects.
        bowl_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'green']
        block_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'red']

        # Add distractors.
        n_distractors = 0
        while n_distractors < 6:
            is_block = np.random.rand() > 0.5
            urdf = block_urdf if is_block else bowl_urdf
            size = block_size if is_block else bowl_size
            colors = block_colors if is_block else bowl_colors
            pose = self.get_random_pose(env, obj_size=size)
            color = colors[n_distractors % len(colors)]

            obj_id = env.add_object(urdf, pose, color=color)
            n_distractors += 1
"""
"""
import numpy as np
from cliport.tasks import primitives
from cliport.tasks.grippers import Spatula
from cliport.tasks.task import Task
from cliport.utils import utils


class SweepingPiles(Task):
    """Push piles of small objects into a target goal zone marked on the tabletop."""

    def __init__(self):
        super().__init__()
        self.max_steps = 20
        self.lang_template = "push the pile of blocks into the green square"
        self.task_completed_desc = "done sweeping."
        self.primitive = primitives.push
        self.ee = Spatula
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add goal zone.
        zone_size = (0.12, 0.12, 0)
        zone_pose = self.get_random_pose(env, zone_size)
        env.add_object('zone/zone.urdf', zone_pose, 'fixed')

        # Add pile of small blocks with `make_piles` function
        obj_ids = self.make_piles(env)

        # Add goal
        self.add_goal(objs=obj_ids, matches=np.ones((50, 1)), targ_poses=[zone_pose], replace=True,
                rotations=False, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1, language_goal=self.lang_template)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p

class StackBlockPyramid(Task):
    """Build a pyramid of colored blocks in a color sequence"""

    def __init__(self):
        super().__init__()
        self.max_steps = 12
        self.lang_template = "make the {row} row with {blocks}"
        self.task_completed_desc = "done stacking block pyramid."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add base.
        base_size = (0.05, 0.15, 0.005)
        base_urdf = 'stacking/stand.urdf'
        base_pose = self.get_random_pose(env, base_size)
        env.add_object(base_urdf, base_pose, category='fixed')

        # Block colors.
        colors = [
            utils.COLORS['purple'], utils.COLORS['blue'], utils.COLORS['green'],
            utils.COLORS['yellow'], utils.COLORS['orange'], utils.COLORS['red']
        ]

        # Add blocks.
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'

        objs = []
        for i in range(6):
            block_pose = self.get_random_pose(env, block_size)
            block_id = env.add_object(block_urdf, block_pose, color=colors[i])
            objs.append(block_id)

        # IMPORTANT Associate placement locations for goals.
        place_pos = [(0, -0.05, 0.03), (0, 0, 0.03),
                     (0, 0.05, 0.03), (0, -0.025, 0.08),
                     (0, 0.025, 0.08), (0, 0, 0.13)]
        targs = [(utils.apply(base_pose, i), base_pose[1]) for i in place_pos]

        # Goal: blocks are stacked in a pyramid (bottom row: green, blue, purple).
        language_goal = self.lang_template.format(blocks="the green, blue and purple blocks", row="bottom")
        self.add_goal(objs=objs[:3], matches=np.ones((3, 3)), targ_poses=targs[:3], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 2, symmetries=[np.pi/2]*3, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (middle row: yellow, orange).
        language_goal = self.lang_template.format(blocks="the yellow and orange blocks", row="middle")      
        self.add_goal(objs=objs[3:5], matches=np.ones((2, 2)), targ_poses=targs[3:5], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 3, symmetries=[np.pi/2]*2, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (top row: red).
        language_goal = self.lang_template.format(blocks="the red block", row="top")
        self.add_goal(objs=objs[5:], matches=np.ones((1, 1)), targ_poses=targs[5:], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 6, symmetries=[np.pi/2]*1, language_goal=language_goal)
"""



Do not use libraries, functions, and assets that you don't know. For each object, try to describe its color, size, category in the task first before you write the code. You do not need extra helper functions. Comment the code liberally to explain what each piece does and why it's written that way. If you have only one goal, `step_max_reward` in `add_goal` should be 1. Use functions `make_piles` and `make_ropes` for creating piles and cables. To use spatula together with the push primitives, import the libraries 
"""
from cliport.tasks import primitives;
from cliport.tasks.grippers import Spatula
"""
and then use `self.primitive = primitives.push` and `self.ee = Spatula`.
Note that the number of language goals usually match the number of motion goals, since they should correspond to each other.

Now write the code for the task "stack-balls-on-cylinder" in python code block starting with ```python.  Reminder: {'task-name': 'stack-balls-on-cylinder', 'task-description': 'Stack three different colored balls (red, green, blue) on top of a vertically placed cylinder.', 'assets-used': ['ball/ball-template.urdf', 'cylinder/cylinder-template.urdf']} 


>>> Answer: 
```python
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils

class StackBallsOnCylinder(Task):
    """Stack three different colored balls (red, green, blue) on top of a vertically placed cylinder."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "stack the {color} ball on the cylinder"
        self.task_completed_desc = "done stacking balls on cylinder."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Cylinder: gray, size (0.05, 0.05, 0.1), fixed
        cylinder_size = (0.05, 0.05, 0.1)
        cylinder_urdf = 'cylinder/cylinder-template.urdf'
        cylinder_pose = self.get_random_pose(env, cylinder_size)
        env.add_object(cylinder_urdf, cylinder_pose, 'fixed')

        # Balls: red, green, blue, size (0.04, 0.04, 0.04)
        ball_size = (0.04, 0.04, 0.04)
        ball_urdf = 'ball/ball-template.urdf'
        colors = [utils.COLORS['red'], utils.COLORS['green'], utils.COLORS['blue']]
        ball_ids = []

        ball_poses = []
        for i in range(3):
            ball_pose = self.get_random_pose(env, ball_size)
            ball_id = env.add_object(ball_urdf, ball_pose, color=colors[i])
            ball_ids.append(ball_id)
            ball_poses.append(ball_pose)


        # Target poses for the balls on the cylinder.
        target_z = cylinder_pose[0][2] + cylinder_size[2] / 2  # Top of the cylinder
        target_poses = [
            (cylinder_pose[0][:2] + (target_z + 0.04,), cylinder_pose[1]), # red ball
            (cylinder_pose[0][:2] + (target_z + 2 * 0.04,), cylinder_pose[1]), # green ball
            (cylinder_pose[0][:2] + (target_z + 3 * 0.04,), cylinder_pose[1]), # blue ball
        ]

        # Goal: stack the red ball on the cylinder.
        language_goal = self.lang_template.format(color="red")
        self.add_goal(objs=[ball_ids[0]], matches=np.ones((1, 1)), targ_poses=[target_poses[0]], replace=False,
                      rotations=True, metric='pose', params=None, step_max_reward=1/3, language_goal=language_goal)

        # Goal: stack the green ball on the red ball.
        language_goal = self.lang_template.format(color="green")
        self.add_goal(objs=[ball_ids[1]], matches=np.ones((1, 1)), targ_poses=[target_poses[1]], replace=False,
                      rotations=True, metric='pose', params=None, step_max_reward=1/3, language_goal=language_goal)

        # Goal: stack the blue ball on the green ball.
        language_goal = self.lang_template.format(color="blue")
        self.add_goal(objs=[ball_ids[2]], matches=np.ones((1, 1)), targ_poses=[target_poses[2]], replace=False,
                      rotations=True, metric='pose', params=None, step_max_reward=1/3, language_goal=language_goal)

```

================= TRIAL: 4